<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[对于基础排序算法的简要总结]]></title>
    <url>%2F2017%2F04%2F24%2F%E5%AF%B9%E4%BA%8E%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E7%9A%84%E7%AE%80%E8%A6%81%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[本文主要分析排序算法中的选择排序、插入排序、希尔排序、归并排序、快速排序和堆排序，以及其部分优化方式，部分代码示例。当然快速排序算法是最快的通用排序算法，这使得其在java中的地位非凡，通常的ArrayList.sort()函数就是使用的快速排序。 在这之前，我们先声明两个方法：分别为比较大小与数据交换的方法。 123456789final static boolean less(Comparable i, Comparable j) &#123; return i.compareTo(j) &lt; 0;&#125;final static void exch(Comparable[] a, int i, int j) &#123; Comparable t = a[i]; a[i] = a[j]; a[j] = t;&#125; 在排序中我们使用Comparable[]的数组进行排序，以便兼容其他类型的数组。 选择排序快速排序是的思维是依次找到最小或最大的值，将这个值与我们所比较的值中的第一个或进行交换。这种算法的特点是：1、运行时间与输入无关，就算是输入有序运行时间也是差不多的；2、数据的移动是所有算法中最少的。 1234567891011public static void selectionSort(Comparable[] a) &#123; int N = a.length; for (int i = 0; i &lt; N; i++) &#123; int min = i; for (int j = i+1; j &lt; N; j++) &#123; if (less(a[j], a[min])) min = j; exch(a, i, min); &#125; &#125; &#125; 插入排序插入排序的基本思路是在循环中将下标i之前的元素进行比较交换（这儿是不符合比较小或比较大的条件则交换）。这种算法对于有序或者比较有序的数组时效率较高。 123456789101112131415public static void insertSort(Comparable[] a) &#123; int n = a.length; for (int i = 1; i &lt; n; i++) &#123; Comparable mi = a[i]; boolean f = false; int j = i; for (; j &gt; 0 &amp;&amp; less(mi, a[j - 1]); j--) &#123; a[j] = a[j - 1]; f = true; &#125; if (f) &#123; a[j] = mi; &#125; &#125; &#125; 在上述插入排序代码示例中，并没有每次比较交换相邻的两个元素，而是将较大的元素都向右移，也是每次循环中将比循环比较的最后一个元素的值大的元素都作右移操作，从而减少访问数组的次数。对于减少访问数组的次数，这点需要详细说明一下：对于普通的插入排序，是每次获取相邻两个元素的值进行比较交换，即每次循环都会获取2*i次数据，总的访问数组（即获取数组元素）的次数就是n*(n-1)次（n为数组的长度）；而对于优化后的插入排序，每次循环访问数组i+1次，总的访问数组(n-1)*(n+2)/2次，大约减少了一半的访问数组的次数。 而对于插入排序与选择排序的比较，主要是在数组有序或部分有序时，减少了交换的次数，从而对于部分有序或有序的数组较高。 希尔排序希尔排序的思想是使数组中的任意间隔为h的元素都是有序的。相对于插入排序改变了原来的插入的顺序。从原来的相邻的两个元素交换改成现在相邻两个增量交换的排序（增量即间隔）。通过增量递减的方式重复排序，直到增量为1，使得原数组有序。（增量序列为一组递减的且最后一个元素为1的数组。） 12345678910public static void shellSort(Comparable[] a) &#123; int N = a.length; for (int h = N / 2; h &gt;= 1; h = h / 2) &#123; for (int i = h; i &lt; N; i++) &#123; for (int j = i; j &gt;= h &amp;&amp; less(a[j], a[j - h]); j -= h) &#123; exch(a, j, j - h); &#125; &#125; &#125; &#125; 在示例中我是将增量/2得到之后的增量；当然这种增量序列不是最优的。在张连堂与张博的《希尔排序最佳增量序列研究》中做了一些分析并得到一种最优的增量序列：… 2^k -1, … 15, 7, 3, 1。 希尔排序对于之前的排序算法是对于平方级的突破，权衡了子数组的规模与有序性使得其更加高效。 归并排序归并排序分为原地归并、自顶向下、自底向上三种归并方式。但是最主要的思维也是归并，归并是将前后两端进行比较，将小的放上去，需要注意越界。而自顶向下是采用分治的思想，使用递归的方式进行归并。自底向上是采用相邻两个归并，在到相邻两组归并，刚好与自顶向下相反。 123456789101112131415161718192021222324252627282930313233343536373839404142public static class Merge &#123; private static Comparable[] aux; /*归并*/ public static void merge(Comparable[] a, int lo, int mid, int hi) &#123; int i = lo, j = mid + 1; for (int k = lo; k &lt;= hi; k++) &#123; aux[k] = a[k]; &#125; for (int k = lo; k &lt;= hi; k++) &#123; if (i &gt; mid) a[k] = aux[j++]; else if (j &gt; hi) a[k] = aux[i++]; else if (less(aux[j], aux[i])) a[k] = aux[j++]; else a[k] = aux[i++]; &#125; &#125; /*自顶向下*/ public static void mergeTopSort(Comparable[] a) &#123; aux = new Comparable[a.length]; sort(a, 0, a.length-1); &#125; private static void sort(Comparable[] a, int lo, int hi) &#123; if (hi &lt;= lo) return; int mid = lo + (hi - lo)/2; sort(a, lo, mid); sort(a, mid+1, hi); merge(a, lo, mid, hi); &#125; /*自底向上*/ public static void sort(Comparable[] a) &#123; int N = a.length; aux = new Comparable[N]; for (int sz = 1; sz &lt; N; sz = sz+sz) &#123; for (int lo = 0; lo &lt; N -sz; lo += sz+sz) &#123; merge(a, lo, lo+sz+1, Math.min(lo+sz+sz-1, N-1)); &#125; &#125; &#125; &#125; 快速排序快速排序是最常用的排序算法，采用分治的思想。将一个数组分为两个数组再排序。 切分（partition）是使用交换等方法将某个值放确切的位置，再将其左右排序切分。这个确切的值满足其左边都小于它，右边都大于它，使得在其确定后，在整个排序过程中都不会对其产生影响，其位置不会再作变化。 12345678910111213141516final static int partition(Comparable[] a, int lo, int hi) &#123; int i = lo, j = hi + 1; Comparable v = a[lo]; while (true) &#123; while (less(a[++i], v)) &#123; if (i == hi) break; &#125; while (less(v, a[--j])) &#123; if (j == lo) break; &#125; if (i &gt;= j) break; exch(a, i, j); &#125; exch(a, lo, j); return j; &#125; 而排序算法就是使用递归的方式去调用切分的方法。 123456public static void quickSort(Comparable[] a, int lo, int hi) &#123; if (hi &lt;= lo) return; int j = partition(a, lo, hi); quickSort(a, lo, j - 1); quickSort(a, j + 1, hi); &#125; 上述为标准快速排序，其在很多地方依然具有缺陷，如在切分不平衡时可能使得排序十分低效，如将{6, 5, 4, 3, 2, 1}转换成由小到大排序时就十分低效。 当然对于快速排序，先辈们依然做了许多优化的方法：1、快速排序对于小数组的排序特别慢，因此使用在数组小时以及分治到较小是采用插入排序优化；2、使用三取样切分，来解决具有大量重复数据情况。三取样切分的快速排序算法示例如下： 1234567891011121314151617public static void quick3waySort(Comparable[] a, int lo, int hi) &#123; if (hi &lt;= lo) return; int lt = lo, i = lo + 1, gt = hi; Comparable v = a[lo]; while (i &lt;= gt) &#123; int cmp = a[i].compareTo(v); if (cmp &lt; 0) &#123; exch(a, lt++, i++); &#125; else if (cmp &gt; 0) &#123; exch(a, i, gt--); &#125; else &#123; i++; &#125; &#125; quick3waySort(a, lo, lt - 1); quick3waySort(a, gt + 1, hi); &#125; 优先队列以及堆排序顾名思义，是具有优先级的队列，即对于这个队列中的数据是有序的。实现方式有很多，基于数组、链表、堆都可以实现。这儿主要介绍一下基于二叉堆的优先队列的实现，下述代码中已经十分清晰。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public static class MaxPQ&lt;Key extends Comparable&lt;Key&gt;&gt; &#123; private Key[] pq; private int N = 0; public MaxPQ(int maxN) &#123; pq = (Key[]) new Comparable[maxN + 1]; &#125; public boolean isEmpty() &#123; return N == 0; &#125; public int size() &#123; return N; &#125; private boolean less(int i, int j) &#123; return pq[i].compareTo(pq[j]) &lt; 0; &#125; private void exch(int i, int j) &#123; Key t = pq[i]; pq[i] = pq[j]; pq[j] = t; &#125; private void swim(int k) &#123; while (k &gt; 1 &amp;&amp; less(k / 2, k)) &#123; exch(k / 2, k); k /= 2; &#125; &#125; private void sink(int k) &#123; while (2 * k &lt;= N) &#123; int j = 2 * k; if (j &lt; N &amp;&amp; less(j, j + 1)) &#123; j++; &#125; if (!less(k, j)) &#123; break; &#125; exch(k, j); k = j; &#125; &#125; public void insert(Key v) &#123; pq[++N] = v; swim(N); &#125; public Key delMax() &#123; Key max = pq[1]; exch(1, N--); pq[N + 1] = null; sink(1); return max; &#125; &#125; 需要注意的是上浮swim()和下沉sink()函数，是分别在插入与删除的时候被调用使得二叉堆平衡。 而堆排序算法如下： 12345678910public static void heapSort(Comparable[] a) &#123; int n = a.length; for (int k = n/2; k &gt;= 1; k--) &#123; sink(a, k, n); &#125; while (n &gt; 1) &#123; exch(a, 1, n--); sink(a, 1, n); &#125; &#125; 这儿的sink(i,j,N)也是下沉函数，是将从j为顶开始下沉操作，使得平衡，具体实现类似于之前的优先队列的sink函数。这儿的思想是得到最大数与最后一个数交换再对前面的数组进行下沉操作，以此类推。 总结对于排序算法，我们需要分析其稳定性。在排序算法中保留重复元素的相对位置，则该算法是稳定的。对于目前的排序算法中，插入与归并排序是稳定的；而选择、希尔、快速、堆排序不是稳定的。 算法 是否稳定 是否原地排序 时间复杂度 空间复杂度 备注 选择排序 否 是 N^2 1 插入排序 是 是 介于N和N^2之间 1 取决于输入元素的排列情况 希尔排序 否 是 1 快速排序 否 是 N*logN lgN 运行效率由概率提供保证 三切分快速排序 否 是 介于N和N*logN之间 lgN 运行效率由概率提供保证，同时取决于输入元素的分布情况 归并排序 是 否 N*logN N 堆排序 否 是 N*logN 1 附本文并没有涉及所有的排序算法，还有如冒泡排序、基数排序等，需要的可以找找资料学习。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap 源码分析]]></title>
    <url>%2F2017%2F04%2F03%2FHashMap-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[HashMap是非常常用的键值对类型。本文主要讲述了HashMap的思维以及其重要或者常用的put，get，remove以及resize函数。 首先Java定义了java.util.Map的接口，而常用的实现类型主要有HashMap、ConcurrentHashMap、LinkedHashMap和TreeMap。对于原来常用HashTable在不强调线程安全性时可以用HashMap替代（也就是说HashMap是线程不安全的），而在线程安全的情况下用ConcurrentHashMap替代。 总体结构首先HashMap在Java1.8之后修改了其部分实现方式，将原来“数组+链表”的实现方式改为现在的“数组+链表+红黑树”的实现方式，采用红黑树的实现方式，增强了对于数据查找、删除、修改等性能，对于增加来说，应该是减慢了，但是个人觉得对于增加影响非常小。 红黑树，RBTree，平衡二叉查找树的一种，具有良好的查找性能。他有五点要求：1、任何一个节点都有颜色，黑色或者红色；2、根结点是黑色的；3、父子节点之间不能出现两个连续的红节点；4、任何一个节点向下遍历到其子孙的叶子节点，所经过的黑节点个数必须相等；5、空节点被认为是黑色的。其实现方式比较复杂，若有时间我看完其源码再做分析。 冲突的含义：是指当两个不同的键值对（key不相同）在put的时候hash(key)所得的值是相同的，他们会放到哈希桶数组的同一下标位置，形成链表或者红黑树，这种情况就是冲突。当然，在HashMap中我们要尽量的选取比较好的哈希函数来避免冲突，但是大多数情况冲突是不能完全避免的，所以要引入链表和红黑树来解决冲突。 节点首先，HashMap类中包含了多个内部类，如Node、KeySet、Values、EntrySet等，在此就不一一列举。Node是HashMap中非常重要的类型，它代表每个节点，包含（hash，key，value，next）等属性，源码如下： 123456789101112131415161718192021222324252627282930313233343536373839static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + &quot;=&quot; + value; &#125; public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125;&#125; 先来说说Node每个属性的含义，1、hash：代表存储是的哈希值，一般由hash(key)函数得出；2、key；3、value：这两个就是键和值；4、next：是指指向下一个节点的指针。 HashMap重要字段1、transient Node[] table; table表示哈希桶数组，transient表示其不参与序列化，即修饰的变量不是该对象持久化的部分。这个修饰符需要注意两点：1、只能修饰变量，本地变量不能被修饰（本地变量：局部变量）；2、静态变量（static修饰）不管有没有被修饰都不能序列化。 2、transient int size; size是指当前存储的键值对数目。 3、int threshold; threshold表示最大容纳的键值对个数，一般为threshold=length*loadFactor；length是指哈希桶数组长度，在当前键值对数目超过这个值时，哈希桶数组会扩容。 4、final float loadFactor; loadFactor，负载因子（默认或缺省为0.75）。 构造函数HashMap有4个构造函数，其一示例如下：123456789101112public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(&quot;Illegal initial capacity: &quot; + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(&quot;Illegal load factor: &quot; + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity);&#125; 其他几个构造函数是将loadFactor缺省或者将参数全部缺省，以及其拷贝构造函数。注意的是对于上述构造函数中将参数loadFactor赋值给负载因子，并将参数initialCapacity通过tableSizeFor函数操作后传给threshold，由上面所述，threshold是最大容纳的键值对个数，而initialCapacity理论上应该是初始化容量，即哈希桶数组初始化长度，而且这儿并没有初始化哈希桶数组长度，因此这儿赋值是跟其思维上不符合的，那么我们的threshold最终究竟是多少，以及在哪儿初始化了哈希桶数组长度呢？这一点，我会在后面分析put方法时讲到。 很好奇tableSizeFor函数是做了什么操作？他是在函数里面进行了一系列的移位操作，保证初始化容量为2的n次方。例如，我们new一个HashMap(11)传入的参数为11，按照之前的观点，初始化哈希桶长度应该是11，但是其进行一系列移位操作后，使得初始化容量为16。关于tableSizeFor源码如下： 123456789static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; get操作这儿的思路是非常简单的，就是通过hash(key)&amp;(table.length-1)得到对应的哈希桶数组位置，再去对应的位置查找，当然现在对应的位置可能是链表类型，也可能是RBTree类型，对于Java1.7时，是只有链表类型，因此遍历链表类型可以查找出对于的字段；而对于Java1.8添加了红黑树结构之后，就需要判断当前对应的table[j]的node是不是TreeNode，如果是则通过红黑树去查找，不是则通过链表查找。 1234567891011121314151617181920212223public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125;final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; put操作这部分相对于get操作就复杂了许多，需要注意的一点是put操作会有返回值，当该key有对应的值时，put操作会返回原来的值（至于覆盖与否，我接下来分析putVal函数参数时会讲到），当对应key不存在时则返回null。接下来，我们分为几种情况讨论put操作： 1、table为空或者table.length为0的时候。这种情况会出现在两个时候，分别是刚刚new了一个HashMap和前面操作将table删掉的情况（删除操作在后面的章节会做另外的讨论）。我们前面构造函数部分提到过，在构造的时候只是初始化了负载因子loadFactor，和将初始化哈希桶长度赋值给了最大容纳的键值对个数threshold。并没有对于哈希桶数组table做初始化，因此在这儿table是空NULL，就触发了扩容，在扩容的时候就会将threshold赋值给table的长度length，而真正的threshold在这儿赋值成length*loadFactor。这里解决了我们之前对于table在哪儿赋值以及threshold最终值的疑问。 2、一般情况。就是将key转换成对应的哈希值从而找到对应的数组下标位置，再判断该位置是否存储有数据，该数据的key是否就是我们需要put的数据的key，存储的是链表还是红黑树，将数据插入就好，当然这儿就有一个情况——当插入之后，该链表的长度（即节点数）刚好超过8，那么根据我们一般的猜想就是转换为红黑树RBTree，其实不然。这儿分为两种情况，第一种（也是最特殊的一种），当链表长度超过8的时候，但是总的哈希表容量size并没有达到MIN_TREEIFY_CAPACITY=64，这时候会出发扩容的情况（扩容一般上会降低同一点的冲突，具体情况我会在扩容一章resize的时候讲到；第二种情况就是size达到或超过64，大家众所周知的转为红黑树。 既然有链表转化为红黑树的操作，那么想必有红黑树转化为链表的操作，这个函数就是untreeify，他会在红黑树的节点数减少到6的时候（即小于等于6）将红黑树转化为链表。 123456789101112131415161718192021222324252627282930313233343536373839404142434445public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125;final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125; 注意putVal函数中后面有两个参数onlyIfAbsent和evict。onlyIfAbsent为ture的时候表示仅当该key缺省（即不存在）时才将该键值对加入HashMap。evict表示是否覆盖旧值，一般情况下evict是ture，表示你在后面put一个跟原来key一样的值时会覆盖掉原来的值，而如果是false时，则保留原来的值，也就是不覆盖，相当于put相同key的值没效果吧。 1234567891011121314151617181920final void treeifyBin(Node&lt;K,V&gt;[] tab, int hash) &#123; int n, index; Node&lt;K,V&gt; e; if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY) resize(); else if ((e = tab[index = (n - 1) &amp; hash]) != null) &#123; TreeNode&lt;K,V&gt; hd = null, tl = null; do &#123; TreeNode&lt;K,V&gt; p = replacementTreeNode(e, null); if (tl == null) hd = p; else &#123; p.prev = tl; tl.next = p; &#125; tl = p; &#125; while ((e = e.next) != null); if ((tab[index] = hd) != null) hd.treeify(tab); &#125;&#125; 这儿有个instanceof函数表示判断前者是否是后者的一个实例。例如，Result = object instanceof class; 判断object是不是class的一个实例，如果是则返回ture。 TreeNode，树节点，他是继承自Node节点的，也就是说TreeNode形成的实例既有Node的key，value等属性，重要的是他有next属性指向下一个节点，而有有TreeNode的parent，left，rigth等属性，这儿在TreeNode里面增加了pre属性来指向前一个节点，只能够在红黑树中使用。在查找HashMap中是否包含某个value的时候将所有都当作链表节点来使用，将父类与本身的属性发挥的非常不错，比如在ContainsValue函数中就没有区分是否是红黑树去查找而是直接使用其父类的next函数查找下一个依次遍历。 3、putMapEntries这个函数就是将，一个Map的所有值加入当前Map，当然需要指定evict参数。 12345678910111213141516171819final void putMapEntries(Map&lt;? extends K, ? extends V&gt; m, boolean evict) &#123; int s = m.size(); if (s &gt; 0) &#123; if (table == null) &#123; // pre-size float ft = ((float)s / loadFactor) + 1.0F; int t = ((ft &lt; (float)MAXIMUM_CAPACITY) ? (int)ft : MAXIMUM_CAPACITY); if (t &gt; threshold) threshold = tableSizeFor(t); &#125; else if (s &gt; threshold) resize(); for (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) &#123; K key = e.getKey(); V value = e.getValue(); putVal(hash(key), key, value, false, evict); &#125; &#125;&#125; 类似的有putAll函数，他就是引用了一下putMapEntries函数，区别就是默认了evict为true而已。 123public void putAll(Map&lt;? extends K, ? extends V&gt; m) &#123; putMapEntries(m, true);&#125; resize函数这部分非常重要，时HashMap重要思维的体现之处之一。首先扩容会在两种情况发生，第一种，在链表转化为红黑树的时候阐述过链表长度大于8且哈希桶数组的长度size&lt;64时会出发扩容；第二种，size&gt;threshold的时候会触发扩容（threshold=length*loadFactor）。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;&quot;rawtypes&quot;,&quot;unchecked&quot;&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; 从代码中可以看出resize函数是返回一个新的哈希桶数组，那么为什么要返回一个新的哈希桶数组呢？这点要从数组讲起，众所周知数组的长度是固定的，不能变长，那么我们怎么在HashMap中产生一个是原来长度两倍的数组呢？这儿就只能够创建一个新的数组来代替老的数组，需要将原来数组里面的变量一一填充到新的数组里面来。在Java1.7以及之前是一次将原来HashMap中的所有节点通过hash算法依次定位到新的Map中来。在Java1.8中对于老的数组同意位置的链表或红黑树中的节点填充到新的Map中做了很大的优化，使得扩容的速度快了许多。当然虽然优化了很多，但是这也是非常消耗时间成本的，因此我们在创建HashMap的时候就需要提前估计其能达到的最大容量，尽量一次性分配足够的空间，减少扩容情况。 在Java1.8中对于HashMap扩容时数据转移做了很大的优化，这儿需要讲到hash获取数组下标的方法(n-1)&amp;hash(key)。对于hash(key)方法我不做过多阐述，想要学习的看看源码再自己测试一下就明白了。而对于按位与&amp;这儿需要说明一下，比如我们的数组长度n=4，那么呢n-1就是二进制的0011，举个例子当hash(key)为2和6的二进制分别时0010和0110，（前面的一些0就不做过多书写了），他们对于n-1的&amp;后得到的0011是相同的，也就是产生冲突，就会形成链表或者红黑树。而扩容之后，n’为8，n’-1二进制为0111，hash(key)进行&amp;操作后就是0010和0110，刚好是原来下标位置和原位置下标加上原来数组长度后作为下标的位置。这儿就可以直接用原来数组长度n的二进制0100与两个hash(key)进行&amp;操作，来判断是否需要将下标位置加上n了，如果是1则加。这样就不需要对于每个节点依次去进行一次重新定位操作。 remove函数当然，跟之前的分析一样，我们都需要关注返回值，这儿返回的是value或者null，那么value是哪个value呢？就是原来我们移除的那个节点的value，当无这个节点时，那么返回null。其实这儿跟put函数一样，都是对于其基础函数的封装，这里remove函数是对于removeNode函数的封装。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public V remove(Object key) &#123; Node&lt;K,V&gt; e; return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value;&#125;final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) &#123; Node&lt;K,V&gt; node = null, e; K k; V v; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) node = p; else if ((e = p.next) != null) &#123; if (p instanceof TreeNode) node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); else &#123; do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; node = e; break; &#125; p = e; &#125; while ((e = e.next) != null); &#125; &#125; if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) &#123; if (node instanceof TreeNode) ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); else if (node == p) tab[index] = node.next; else p.next = node.next; ++modCount; --size; afterNodeRemoval(node); return node; &#125; &#125; return null;&#125; 从上面removeNode函数可以看出其返回的是一个Node类型，即返回移除的节点，除了没有对应节点时返回null，这儿有两个比较特殊的参数matchValue和movable，matchValue表示是否匹配value的值，而moveable表示是否可以移除，对于这点我有点想不太明白。在remove函数中这部分都是和value一起以默认值传出。在removeNode函数里面又有判断当为红黑树时的removeTreeNode函数，对于这个函数我不作过多分析，需要的可以自己去看一下源码。 附对于其他函数等操作等，我就不具体分析，比如contains一系列，clear函数以及一系列Set等，以及其迭代器iterator等。这些如果需要学习可以仔细看一下其源码分析。最后推荐下美团点评技术团队的《Java 8系列之重新认识HashMap》。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>map</tag>
      </tags>
  </entry>
</search>
