<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[基于github与hexo的博客搭建]]></title>
    <url>%2F2019%2F02%2F24%2F%E5%9F%BA%E4%BA%8Egithub%E4%B8%8Ehexo%E7%9A%84%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[安装npm进入这个网站（镜像），下载需要的最新的pkg：http://npm.taobao.org/mirrors/node/latest/。然后将这个文件解压，放到一个位置。配置export PATH=$PATH:/Users/feiyu/node-v11.7.0-darwin-x64/bin。创建github仓库仓库的名字必须是我们自己的github用户名，这样github会识别当前仓库的某个分支来创建GitHub Pages，默认选用master分支。然后我们需要在本地创建一个对应的的项目，并进入这个项目文件夹。需要注意的是，上面默认选中了master分支作为基础创建GitHub Pages，那么本地的源代码就不能再直接git push到该分支，该分支只能用来发布博客页面。安装hexo首先，需要在我们的博客项目文件夹中。输入下面命令开始安装。1npm install hexo -g安装完成后，则初始化博客项目。1hexo init输入npm install，安装所需要的组件。需要讲解几个重要的命令：hexo new &quot;&quot; 创建源md文件；hexo g 生成网页；hexo s 本地起服务，然后浏览器输入http://localhost:4000 ，就可以访问本地博客项目；hexo d 将生成的页面发送到github，github检测到master分支更新后会自动构建页面，这其中有一点延迟，需要稍微等一下。在_config.yml中配置一下Site基础信息12345678title: feiyboxsubtitle: do moredescription: 小浊微清的博客author: feiyboxlanguage: zh-Hansurl: https://feiybox.github.io/root: /...当然还有许多变量可以去配置。在hexo生成后会默认有一个页面，因此可以尝试上面hexo g等命令查看该项目构建是否成功。当hexo d发布后，就可以进入https://your_github_id.github.io/ ，就可以访问你的博客网页了，如果有构建错误或者异常等，github会通过邮件发送提醒。文章源md每个文章的源md文件都分为两个部分，文章部分就是常用的md语法，而头部分示例如下，主要有文章名、时间、标签、分类等。123456title: HashMap 源码分析date: 2017.04.03 20:08tags: - Java - mapcategories: tech这个部分许多都是直接在hexo new的时候就生成出来了，然后修改。当然也可以修改scaffolds/post.md文件就可以直接修改new生成出来的模版了。增加图片支持到目前为止，博客已经支持基础的发文操作了，接下来就是完善与优化了。1npm install hexo-asset-image --save在当前文件夹下输入上诉命令，就可以支持markdown命令![logo](logo.jpg)来支持相对路径。并且使用hexo new命令时，会创建一个对应文章的文件夹，将图片放在这个文件夹中，然后在文章中使用相对路径就可以使用了。next主题为啥使用next主题？因为够简洁呀。还有一个原因，这个博客主题中支持了许多差距，因此不需要我们去修改模版页面了，只需要修改一个配置就行了。如何安装呢，直接将next主题直接下载到themes文件夹下，然后将_config.yml中的theme修改为theme: next就可以了。使用git下载如下（前提在当前项目根目录下）1git clone https://github.com/iissnan/hexo-theme-next themes/next头像与网页缩略图这是一个代表自己网页特异性的地方。修改themes/next文件夹下的_config.yml文件中的配置如下。1234567favicon: # 缩略图 small: /images/f.png medium: /images/f.png apple_touch_icon: /images/f.png safari_pinned_tab: /images/f.png ...avatar: /images/head.png # 头像所有的图片都是next/source为根文件夹，一般放在该文件夹的images文件夹下，后续构建时，会自动生成在对应的位置。数据统计与页面阅读量展示百度统计数据统计部分，推荐使用百度统计，在百度统计上注册并新增了网站，获得一个百度统计的key，如下图位置。然后将修改themes/next/_config.yml的baidu_analytics值为我们获得的key。12# Baidu Analytics IDbaidu_analytics:然后项目构建后就可以进入百度统计查看网站的访问信息了。不蒜子统计直接修改themes/next/_config.yml的busuanzi_count的enable值为true。1234567891011busuanzi_count: enable: true site_uv: true site_uv_header: &lt;i class=&quot;fa fa-user&quot;&gt;&lt;/i&gt; site_uv_footer: site_pv: true site_pv_header: &lt;i class=&quot;fa fa-eye&quot;&gt;&lt;/i&gt; site_pv_footer: page_pv: true page_pv_header: &lt;i class=&quot;fa fa-file-o&quot;&gt;&lt;/i&gt; page_pv_footer:由于不蒜子的域名已经修改，官方有说明。因此需要修改不蒜子的域名，打开themes\next\layout_third-party\analytics\busuanzi-counter.swig文件，将dn-lbstatics.qbox.me替换成busuanzi.ibruce.info即可。喜欢与评论这个主要使用的是Gitment，其中评论主要是作为某个repo的issue存在，因此可以直接绑定自己的博客项目，也可以新建一个repo来存储评论。具体怎么做呢，按照接下来的步骤。首先在项目根目录中安装Gitment。1npm i --save gitment然后新建一个OAuth application。新建完成会生成一个Client ID与Client Secret。其中需要说明一下的是Homepage URL是指你的博客根目录地址，比如我的是https://feiybox.github.io/，然后是Authorization callback URL，这个是指用户在你的页面登录github账号后的回调链接，一般也是Homepage URL。（这儿我有一个疑问，这儿可以返回用户的登录页面吗？）然后修改theme/next/_config.yml中的gitment配置。12345678910111213gitment: enable: true mint: true count: true lazy: false cleanly: true language: github_user: feiybox github_repo: client_id: client_secret: proxy_gateway: redirect_protocol:其中比较重要的有几个enable、github_user、github_repo、client_id、client_secret，这个几个都是必须填或修改的。需要注意的一点是github_repo是指评论的存储项目的项目名称，不是git仓库。需要我们上线后，自己登录并对每篇文章开通评价（都在每篇文章的最后）。然后上线并用自己账户开通评论时，可能会出现问题。Error: Validation Failed这个问题是因为issue的Label有长度限制，在中文博客中经常超过限制。因此可以将themes/next/layout/_third-party/comments/gitment.swig的window.location.pathname替换为&#39;&#39;。这样每个issue都是基于文章的date构建的，因此需要保证没有同时发布文章，一般也不会出现这种情况。分享支持分享使用needmoreshare212rm -rf themes/next/source/lib/needsharebuttongit clone https://github.com/theme-next/theme-next-needmoreshare2 themes/next/source/lib/needsharebutton然后在themes/next/_config.yml中配置needmoreshare2。先将enable设置为true，然后可以配置分享按钮的样式等。12345678910111213141516needmoreshare2: enable: true postbottom: enable: false options: iconStyle: box boxForm: horizontal position: bottomCenter networks: Wechat,Douban,QQZone,Weibo,Twitter,Facebook float: enable: true options: iconStyle: default boxForm: vertical position: middleRight networks: Wechat,Douban,QQZone,Weibo,Twitter,Facebook系统优化搜索将theme/next/_config.yml中的local_search的enable设置为true，就可以提供搜索了。菜单123456789menu: home: / || home archives: /archives/ || archive categories: /categories/ || th tags: /tags/ || tags #about: /about/ || user #schedule: /schedule/ || calendar #sitemap: /sitemap.xml || sitemap #commonweal: /404/ || heartbeat加上需要的菜单，然后新增对应的页面。如下，新增categories页面。1hexo n page categories然后在source/categories/index.md中的type加上categories就好了。首页文章缩略themes/next/_config.yml文件中修改auto_excerpt。123auto_excerpt: enable: true length: 10压缩静态资源1npm install hexo-neat --save然后在_config.yml添加配置12345678910111213141516171819202122#静态资源压缩优化 hexo-neatneat_enable: true # 启用neat# html优化neat_html: enable: true exclude:# css优化neat_css: enable: true exclude: - &apos;*.min.css&apos;# js优化neat_js: enable: true mangle: true output: compress: exclude: - &apos;*.min.js&apos;参考还有许多配置点，这位博主写得很好：hexo博客优化–Next主题]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>github</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读《傲慢与偏见》]]></title>
    <url>%2F2019%2F01%2F31%2F%E8%AF%BB%E3%80%8A%E5%82%B2%E6%85%A2%E4%B8%8E%E5%81%8F%E8%A7%81%E3%80%8B%2F</url>
    <content type="text"><![CDATA[很喜欢《傲慢与偏见》这种故事，和《简·爱》的故事一样，都是美满的结局，全程没有一点压抑，或许有一些人物出现的不完美，但是都终归走向那个人的向往的结局。或许我本身开始对悲剧的胆怯而导致对喜剧的期待了，人终究是期待美满的。书里一直持续着两条大的线，一条是班纳特姐妹的爱情到婚姻的故事，另一条是达西的傲慢与伊丽莎白的偏见。或者说在班纳特小姐们的爱情中着重叙述了伊丽莎白的故事。书中有两点非常有趣。第一点是彬格莱与吉英的恋爱中的一段。当彬格莱刚开始在尼日斐花园时，对吉英表现了自己对于其的倾慕。但吉英虽然也喜欢彬格莱，却没有表现出喜欢，以至于后来的懊悔。对于自己的喜欢，不要刻意去压抑，喜欢的本身是很美的东西。第二点就是本书中的中心。达西的傲慢的形象，导致了伊丽莎白对于其的偏见。其中有两点很重要，一是我们也需要像达西后来一样，不能有那种十分傲慢、自以为是的态度；二是不能因为自己对于别人的偏见而否定别人。人非圣人，傲慢与偏见是或多或少都有些的。养好自己的心智才是最重要的。]]></content>
      <categories>
        <category>read</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[例行总结——2018版]]></title>
    <url>%2F2018%2F12%2F30%2F%E4%BE%8B%E8%A1%8C%E6%80%BB%E7%BB%93%E2%80%94%E2%80%942018%E7%89%88%2F</url>
    <content type="text"><![CDATA[前言：去年年终总结——《17曲终，18伊始》。18年，当然，我似乎也做了不少事。17年年末开始北漂，在北京开启新的一年；从学校毕业了，自我感觉似乎毕业很久了；现在又离职了，进入了失业状态。这一年有点不平凡。年初时，刚来北京，我去天安门上稍微挥了挥手——《【燕京景】京城第一弹——天安门、故宫》 。再后来，在北京经历了一场新雪——《下雪了》。毕业后，于高铁上写了《那些年的室友，祝安好》，从此我们毕业了。这一年里，我见证了币圈的疯狂，经历了币价的悬崖式大跌。这一年里，我稍微了解了一些区块链比特币。最终还是离开了币圈。这一年里，我明白了人所恐怖的不是不会，而是未知，因为未知所以恐惧，当迎难而上度过了那个点，便不会再害怕了。终究算来，这一年里我读了12本书，读后感写了8篇，自建了公众号“青纸”，虽然写得不怎么好，但自娱自乐是满足了。这一年里，在简书更新了46篇文章，分别为随笔类35篇，技术及工具使用类11篇。这一年里，百词斩实现第160天打卡，上班日子里每天背半个小时的单词。从上总结说，这一年里，读的书主要都在下半年，而且读的书籍还不够多，对于技术的研究学习还不够。这一年里还挺有趣，经历了跑路的理发店，因为地震延迟一个多小时的高铁，凌晨且晚点的航班，回龙观的大水，北方易上天的风。这一年里，我长到了60kg，却没有长身高。来年里，我不能再读这么少的书了，继续坚持简书的不定时更新，继续坚持读后感或者影评的写作。来年里，我需要找到一份工作，做好并做久一份工作。闲来时，继续不定时做一些leetcode题目。继续完成我后续的个人项目。2018，我将归于何处？不减丝毫心气，我仍是少年。]]></content>
      <categories>
        <category>other</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[做出改变——读《谁动了我的奶酪》]]></title>
    <url>%2F2018%2F12%2F16%2F%E5%81%9A%E5%87%BA%E6%94%B9%E5%8F%98%E2%80%94%E2%80%94%E8%AF%BB%E3%80%8A%E8%B0%81%E5%8A%A8%E4%BA%86%E6%88%91%E7%9A%84%E5%A5%B6%E9%85%AA%E3%80%8B%2F</url>
    <content type="text"><![CDATA[谁动了我的奶酪？我不知道。那么奶酪被动了，该怎么办呢？每个人都有自己面对问题的方式，那么哪种方式会是最优解呢？本书中有很重要一点，随着变化而变化，并通过衍生，每个人都可以得到自己的结论。先介绍一下故事中的出场人物。嗅嗅：能够极早地嗅出变化气息；匆匆：能够快速开始行动；哼哼：因为害怕变化而否认和拒绝变化；唧唧：当看到变化会使事情变得更好时，能够及时地调整自己去适应变化。在故事中，嗅嗅和匆匆合作，不停的寻找奶酪，每当当前找到的奶酪没有后，又重新开始寻找奶酪，也不思考规律或者奶酪变化等。虽然效率很低，但是从没有出现没有奶酪的困境。而哼哼和唧唧则使用聪明才智，找到寻找奶酪的最好方式，快速找到奶酪；但是却在找到大量奶酪后，不再寻找，也不再关心奶酪越来越少，奶酪发生变化等。等到奶酪没有后，哼哼和唧唧都开始在原地等待、迷惘。后来唧唧开始寻求改变，出去寻找奶酪，并劝说哼哼。并且在寻找过程不断反思和总结。后来唧唧找到了新的奶酪，并时刻注意奶酪的变化，并准备着面对变化，时常熟悉当前奶酪的附近环境。做出改变，似乎是只面对问题时或者安乐时，对自己做出变化。最为重要的是指，当面对变化时，可以从容对自己做出改变。书中明确提到了有几点值得我们去学习：学会观察当前安乐的环境，准备应对一些突出其来的变化；对于当前所得出的结论，应该快速将其付诸于实践；对于变化，应该学会快速适应，从心理上的适应。这点上类似与大学学习的迎难而上，学会如何去解决问题一样。面对困难时，首先应该想的是如何去解决困难，解决后去想为什么会出现这种问题，准备好下次问题发生时的解决。其实从这之中可以扩展开来，在每个环境中都有各色的人可以匹配这四种角色，每个人都有自己的“奶酪”，每个人对自己奶酪发生变化的应对方案可能解决方案也是这四种。像我之前，有时觉得不是自己的问题，就不用关心了，其实每一个特殊情况的发生，都有可能引发接下来的变化，我们需要学会对于变化的敏感性，学会去应对变化。奶酪是指什么？对于奶酪，我有两种认识。第一种，奶酪是指当前我们所经历的环境，比如工作生活等，这些中都蕴藏这一些变化，如何去应对变化，了解变化，学习变化。第二种，奶酪是指我们面对安乐时的心境。我们面对变化时，是否像哼哼面对变化时一样，因为害怕变化而否认和拒绝变化。其实在我看来，不管如何去准备面对变化，都不会是完全充分的，依然会在某些情况下，都会有一些疏漏。因此拥有一个时刻准备面对变化，迎难而上的心境非常重要了。其实总的来说，类似与中国古谚：“生于忧患，死于安乐”。准备好做出改变了吗？]]></content>
      <categories>
        <category>read</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[寻找悲惨里的崇高，做一个苦行者——读《悲惨世界》]]></title>
    <url>%2F2018%2F12%2F13%2F%E5%AF%BB%E6%89%BE%E6%82%B2%E6%83%A8%E9%87%8C%E7%9A%84%E5%B4%87%E9%AB%98%EF%BC%8C%E5%81%9A%E4%B8%80%E4%B8%AA%E8%8B%A6%E8%A1%8C%E8%80%85%E2%80%94%E2%80%94%E8%AF%BB%E3%80%8A%E6%82%B2%E6%83%A8%E4%B8%96%E7%95%8C%E3%80%8B%2F</url>
    <content type="text"><![CDATA[读《悲惨世界》以来，一直断断续续，没有一次从开始到结尾的读。终究还是读完了这书，悲惨中寻找崇高，活着悲惨里始终如一的善良，那是一种何等的崇高。当读到“我不知道把烛台送给我的那一位，在天上对我是否满意。我已经尽力而为了。”，我已经满眼含泪，一个人只是为了某一个信仰，一生行善，却从抱怨，或许抱怨过，但从没有对生活与世界失去信心，这一种坚持，这一种善心。在这本书中，我所感触最深的有两点。第一点，沙威的自杀。当一个人到头来明白，自己信任并坚持的信仰，却发现是错误的，那人会如何选择。当发现这一辈子中主要的事都是错事，那是一种何等的悲伤，沙威便是无法承受这一新的变化，这一种新的信仰，推翻了自己坚持的信仰。第二点，因为主教的感化，冉阿让从开始对社会有一定的敌意到后续的一直行善。一个人的启发，可以改变某个人或者某些人的一生。我原来多次谈到信仰，在此也是，主教的信仰，行善。“信仰，人所必需。毫无信仰的人实在不幸！”，冉阿让的信仰也是行善。他们都用尽一生去行善，对自己经历过的悲伤，却从不抱怨。“一个人有了痛处，对他最好的怜悯，不就是绝不触碰吗？”主教大人，在这方面是做到了极致，他坚持对每个人善良，对每个人都好。从不去批评和批判某个人的某一点。就是因为主教的善良，才让一颗干涸的心又有了血。书中又一段形容从牢狱里出来的冉阿让——“年复一年，这颗心逐渐干涸，缓慢地，确是不可避免地。心灵干涸，眼睛也干涸。直到出狱，十九年他没有流一滴眼泪”。而主教的善良确认这个干涸的人，心灵流了泪。冉阿让一生没有谈论过政治，没有谈论过时事，他从开始就是一个平凡的人，如果到达死去却不来回顾他的一生，从不会决定这个人的伟大。冉阿让明白自己做了小偷，这个是自己的罪过，不管是多小的罪，罪过依然是罪过，从没有为自己的罪过做过一点辩白。因为一块面包，而经历了19年的牢狱之灾，从此背负着苦刑犯的头衔。这真正说明了这个悲惨的世界。在这么一个悲惨的世界里，有很多像德纳第的人一样，为了生活不折手段一样生存下来的人，也有很多像割风一样老老实实活下来的人。在这个世界里，有很多人起来反抗，有很多人各种行恶，有很多流浪者。其实可以想象得出，这个世界的冷漠，悲伤。我从来相信，每个人都有自己独立的立场。像在街垒的战斗中，防御者和攻击者，哪一个不认为自己在为自己的信仰奋斗，或者哪一个不认为自己在行善积德呢？然而如果这其中的一种立场崩塌，人就会受不住，如同沙威一样。在我看来，沙威也是一个悲惨的人，一生之中自己尽职尽责，却追逐了一个善人的逃犯，仇恶的自己却发现自己却似乎在行恶，最终心中的矛盾无法化解。“人不只是一个中心的圆圈，而是有两个中心的椭圆形。一个中心点是事实，另一个中心点是思想。”这点上我是十分认同的，我信任存在即合理，所以虽然人的思想在某些方面里脱离了事实，但并非在行动上跃出了轨迹，如果思想和事实分离得太远，人就会分裂，我认为双重人格或许就是由此而来吧。对冉阿让而言，事实再清楚也不过了，而思想确是自己选择的，自己不断的善行，自己的信仰。有人说，《悲惨世界》在于告诉我们，再悲惨的世界里，依然会有崇高，依然会有善。在于劝谏人们去追逐那一种善。这点上我是有一些同意的。冉阿让从囚牢里出来，再到了市长。后来领养了珂赛特，并一直伴随着珂赛特的成长到最后完美婚姻的结局。《悲伤世界》是悲多还是喜多些呢？从主人公冉阿让的一生来说，终究是悲伤多了许多。对珂赛特而言，自然而言，是喜多一些，从遇到冉阿让以来，人生都是幸福的，然而我们无法想象，如果珂赛特没有遇到冉阿让，那将会是一种什么样的人生，我们无法想象，或许应该说我们不敢想象。在其中，还展示了另一中影响，爱情的影响。爱潘妮对马修斯的爱，正因为这种爱，爱潘妮选择了奋不顾身。这种爱有一定的私心，却显得十分崇高。一个伟大的苦行者形象，一个令人敬佩的苦行者。也是一个凡人，一个想拥有家庭，想拥有幸福的普通人。而这一种伟大与平凡，能够像主教大人一样，去感染世间人。我也能否，做一个苦行者，尽行善事。]]></content>
      <categories>
        <category>read</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ThreadPoolExecutor源码分析]]></title>
    <url>%2F2018%2F11%2F18%2FThreadPoolExecutor%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[首先，为什么需要读这段源码呢？其实主要就一点，“知其然，知其所以然”。当理解其中的实现方式，就更加明白该如何去使用。为什么需要使用线程池？其原因正如像众所周知的，当我们需要不断的执行各种小型的任务时，而创建与销毁线程所带来的成本将影响系统的性能，因此使用线程池来减少线程的创建、销毁。状态在此，状态是指线程池的状态。其中状态转换如下图当然，在程序中，每个状态都会有一个值来代替。RUNNING：-1；SHUTDOWN：0；STOP：1；TIDYING：2；TERMINATED：3并将所有的值左移29位。在程序中用ctl来表示当前线程池的状态。1private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));ctl是一个原子变量，后续的每一个操作都会使用CAS来进行原子操作。当然我们还需要记录当前线程池中启动的线程数，这个线程数也是通过ctl来记录的。这儿有一个巧妙的设计方式，将ctl的32位比特位分开，将其中前3位用来表示线程池的状态，而后面的29位用来记录当前线程池的线程数。其中每次获取线程数或者获取线程的状态的操作都使用位操作来获得。构造方法123456789101112131415161718192021222324public ThreadPoolExecutor(int corePoolSize,//核心线程上限数量 int maximumPoolSize,//最大线程数 long keepAliveTime,//允许线程空闲等待时间（允许setKeepAliveTime()修改） TimeUnit unit,//时间单位 BlockingQueue&lt;Runnable&gt; workQueue,//任务等待队列 ThreadFactory threadFactory,//线程构造工厂 RejectedExecutionHandler handler) &#123;//任务拒绝方案 if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0)//校验参数 throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.acc = System.getSecurityManager() == null ? null : AccessController.getContext();//初始化上下文 this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler;&#125;其中需要注意的有两点。第一点，最大线程数代表的是在线程池中执行任务所允许的最大线程数。在线程池中，分为两种线程，一种是“固定工作人员”线程，另一种是“临时工”，只是在线程池有压力的情况下才会请用“临时工”。而最大线程数代表的是所有允许工作的线程数，核心线程上限数量为最多允许的“固定工作人员”线程数。第二点，在构造方法中，有允许默认线程构造方式，以及默认拒绝方案等。默认拒绝方案是接受任务时，不做处理，直接抛出异常。拒绝方案总共：CallerRunsPolicy、AbortPolicy、DiscardPolicy、DiscardOldestPolicy。CallerRunsPolicy：默认创建线程执行任务，除非执行器关闭AbortPolicy：默认执行方案；不执行任务，直接抛出异常DiscardPolicy：什么也不做。Does nothingDiscardOldestPolicy：将任务队列的队头任务丢弃，再执行尝试加入队列。除非执行器关闭executeexecute方法为线程池接收任务的方式。12345678910111213141516171819public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); int c = ctl.get(); if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; else if (!addWorker(command, false)) reject(command);&#125;其中整体思路也是比较简单的明了的。1、首先，校验运行线程数小于核心数，尝试增加新的核心线程直接运行任务，结束；2、如果线程池在运行状态，尝试加入等待队列；加入成功后再次校验运行状态：非运行状态则移除任务并拒绝任务（拒绝任务时会执行拒绝方式）；如果线程池没有运行的线程，则加入一个新的非核心线程（运行任务将从队列中去获取）；3、对于上一点开始的判断不满足，则再次尝试加入一个非核心线程运行当前任务，失败则拒绝任务。在第2点中为什么需要再次校验线程池中没有线程，并加入线程呢？其中在于并发情况下，当我在加入任务到等待队列时，刚好前面运行的线程都执行完任务，并队列为空，如果没有等待时间或者等待时间很短，那么这些线程都会消亡，那么在加入任务到线程池等待队列后，线程池没有消费任务的线程。为什么添加“非核心”线程呢？如果添加的是核心线程会有什么不一样吗？其实换个角度想就明白了。核心线程与非核心线程在线程池中有明显的区分吗？并没有。只是有表示核心线程数上限与总线程数上限。加入线程时判断是否加入核心线程，只是判断当前线程总数是否到达核心线程数的限制。而这儿，线程总数是空的，因此加入一个新的线程，不管核心与否都行，但是必须要传这个参数。当然有一种情况，如果在此处加入非核心线程的前，其他允许核心数的线程加入线程，那么当前线程的加入没有达到最大线程数限制则不会失败，在我看来这儿传true/false本质上是相同的，ThreadPoolExecutor本身具有一定的自适应调节能力。重点是必须要传一个参数。123456...int wc = workerCountOf(c);if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false;...在第3点中，如果任务加入队列失败且创建了一个新的非核心线程。这种情况代表着当前情况下，目前的生产者的生产数量大于消费者数量，需要增加消费者的数量，等到不需要时，再释放临时工。其中addWorker函数，参数firstTask代表初始化任务，core代表创建的线程是否核心线程，而返回结果true/false分别代表新建线程加入并启动成功/失败。shutdownshutdown函数逻辑如下：1、先获得自旋锁，并加锁2、对每个worker检查是否有修改线程权限（需要加锁）3、循环尝试修改执行状态为SHUTDOWN4、尝试阻塞每个线程（修改阻塞标志）5、关闭锁后并调用tryTerminate()函数12345678910111213public void shutdown() &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; checkShutdownAccess(); advanceRunState(SHUTDOWN); interruptIdleWorkers(); onShutdown(); // hook for ScheduledThreadPoolExecutor &#125; finally &#123; mainLock.unlock(); &#125; tryTerminate();&#125;tryTerminate方法将在循环中执行下叙流程：1、判断线程池状态，运行中，TIDYING，或者SHUTDOWN同时等待队列不为空则结束；2、判断当前线程执行数不为0，阻塞一个线程，结束（只是标识为阻塞）；3、获取锁并加锁；4、尝试状态位设置为按位或上TIDYING；5、执行terminated，预留可被重载；6、状态位设置为按位或上TERMINATED；7、signalAll，唤醒此lock上等待的所有线程；8、关闭锁；shutdownNowshutdownNow()函数与shutdown()函数的主要区别是，shutdownNow会马上停止线程池，而shutdown不会马上停止线程池，会待目前线程池中的任务执行完成后再停止线程池。在代码上体现为三点区别：shutdownNow修改线程池的状态为STOP状态；shutdownNow调用阻塞线程是调用的是interruptWorkers()方法，而shutdown调用的是interruptIdleWorkers()方法。这两个线程方法具有本质的区别，interruptWorkers会直接将循环所有的线程进行阻塞线程，而interruptIdleWorkers会阻塞没有运行的任务的线程，其中在于后者会拿到Worker的的锁后再调用阻塞；shutdownNow会直接清空任务队列里没有运行的任务，并返回。Worker::run首先，Worker是对于线程的一个封装，其中有当前线程，初始化任务，完成任务数等信息。1234567891011121314151617181920212223242526272829303132333435363738final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); Runnable task = w.firstTask; w.firstTask = null; w.unlock(); // allow interrupts boolean completedAbruptly = true; try &#123; while (task != null || (task = getTask()) != null) &#123; w.lock(); if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try &#123; beforeExecute(wt, task); Throwable thrown = null; try &#123; task.run(); &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; afterExecute(task, thrown); &#125; &#125; finally &#123; task = null; w.completedTasks++; w.unlock(); &#125; &#125; completedAbruptly = false; &#125; finally &#123; processWorkerExit(w, completedAbruptly); &#125;&#125;其中逻辑如下：1、尝试从队列中拿出一个任务；（初始化时任务可能为空，后续将在此不断循环）2、加锁；3、判断线程池是否停止，如果停止则中断线程；4、执行任务；5、task置空，并将当前线程完成任务数自增，并关闭锁；6、清理。在清理中，会判断当前执行任务异常而导致线程结束，则将worker数减1，并执行一些清理性的工作。getTask在本处也是一个很有趣的方法。其实也很简单，就是循环尝试从任务队列中拿出一个新的任务，如果拿出了就返回，这是一个消费者。1、如果当前线程池的状态是STOP或者将STOP，则将worker数减1并结束；2、计算是否有存活时间，以及线程数是否大于允许核心数；3、根据2的计算结果判断线程是够需要结束，尝试将线程数减1；4、尝试从队列中拿出任务，poll方法可以超时，并返回（会阻塞等待）；5、没有拿出任务则把timeOut置为true；其实在这儿就可以明白，keepAliveTime所代表的当线程为空时，线程死亡前的等待时间，其实是设置为线程等待任务队列中拿到任务的超时时间。总结在ThreadPoolExecutor通过充分的利用锁以及CAS操作，保证了线程安全性，并且也不会有性能上的限制。并且使用一个变量来直接代表两个意义的使用方式挺惊艳。以及在核心线程与非核心线程上的区分都设计得恰到好处。整体设计方案值得学习。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ConcurrentHashMap 源码分析（Java version 1.8）]]></title>
    <url>%2F2018%2F10%2F06%2FConcurrentHashMap-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%EF%BC%88Java-version-1-8%EF%BC%89%2F</url>
    <content type="text"><![CDATA[在我之前的文章《HashMap 源码分析》中分析了HashMap的源码，众所周知，ConcurrentHashMap是线程安全的Map，在Java 1.7及以前版本使用分段加锁机制，而1.8版本开始使用CAS操作，抛弃了segment，并只对哈希桶数组的的单个元素加锁。相对于HashTable对于每个方法都使用synchronized，效率提升了非常大。本文所解读的ConcurrentHashMap是基于Java 1.8 版本。部分代码过于繁琐，因此建议对照源码。总体结构从总体上，ConcurrentHashMap与HashMap的结构是相同的，是基于哈希桶数组加链表以及红黑树构成的。红黑树，是平衡查找树的一种，使用这种结构，可以加速查找。CAS操作，是一种乐观锁技术，直接CPU支持，通过不断的尝试，获取值并进行比较操作，这种操作相比较锁来说，减少了不少的消耗以及等待等。&lt;&lt;：左移，相当于乘以2>&gt;：右移：相当于除以2>&gt;&gt;：无符号右移，空位补0节点在节点上，也是基本与HashMap相同，有Node，并通过继承等，得到TreeNode、TreeBin、ForwardingNode等类。ForwardingNode用来标示当前节点在扩容的时候已经迁移到新的哈希桶数组中了，当前的hash为-1，而TreeNode是构建红黑树的元素，而在哈希桶数组中存储的却不是TreeNode，当红黑树时，使用TreeBin封装TreeNode后放入哈希桶数组，这点与HashMap不同。1234567static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; volatile V val; volatile Node&lt;K,V&gt; next; ...&#125;而ForwardingNode相对与Node来说，多了一个nextTable属性，创建该Node时，除了将hash设置为-1外，还需要将nextTable设置成指向扩容后哈希桶数组的引用。12345678static final class ForwardingNode&lt;K,V&gt; extends Node&lt;K,V&gt; &#123; final Node&lt;K,V&gt;[] nextTable; ForwardingNode(Node&lt;K,V&gt;[] tab) &#123; super(MOVED, null, null, null); this.nextTable = tab; &#125; ...&#125;TreeNode中继承了Node的属性，也实现了指向父节点，左右节点，以及前一个节点的引用。而在TreeBin中，需要关注的是first，是指向红黑树根节点的的引用，而用lockState来对红黑树加读写锁。12345678910111213static final class TreeNode&lt;K,V&gt; extends Node&lt;K,V&gt; &#123; TreeNode&lt;K,V&gt; parent; // red-black tree links TreeNode&lt;K,V&gt; left; TreeNode&lt;K,V&gt; right; TreeNode&lt;K,V&gt; prev; // needed to unlink next upon deletion boolean red; TreeNode(int hash, K key, V val, Node&lt;K,V&gt; next, TreeNode&lt;K,V&gt; parent) &#123; super(hash, key, val, next); this.parent = parent; &#125; ...&#125;构造函数在构造函数中，与HashMap比较相似，只是初始化一些变量的值，如初始化容量、负载因子等，以及concurrencyLevel，这个在1.8版本中已经不重要了，初始化容量可能会受这个元素影响。123456789public ConcurrentHashMap(int initialCapacity, float loadFactor, int concurrencyLevel) &#123; if (!(loadFactor &gt; 0.0f) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0) throw new IllegalArgumentException(); if (initialCapacity &lt; concurrencyLevel) // Use at least as many bins initialCapacity = concurrencyLevel; // as estimated threads long size = (long)(1.0 + (long)initialCapacity / loadFactor); int cap = (size &gt;= (long)MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : tableSizeFor((int)size); this.sizeCtl = cap;&#125;当然，这个与HashMap中非常相似，在初始化哈希桶数组容量时，会使用tableSizeFor()将数组长度初始化为2的n次方的长度。而负载因子是指在符合一定条件下，当目前的元素总数达到负载因子乘上容量时，将进行扩容操作。get在说明get方法前，需要注意在ConcurrentHashMap中，所有传入的key、value等都不能为null，否则会抛出NullPointException。首先，对应HashMap中的hash()函数的speed函数，相对于来说增加了按位与上0x7fffffff，这个为2进制中从右到左31个1。保证了hash值一定大于0，这个因为在ConcurrentHashMap中，为负数的部分hash是有特殊含义的，这个在后面会有提到。123static final int spread(int h) &#123; return (h ^ (h &gt;&gt;&gt; 16)) &amp; HASH_BITS;&#125;在get中，首先根据key计算hash，然后使用哈希桶数组长度n得到的n-1值按位与上hash，得到定位到哈希桶数组中的位置；然后使用原子操作，取得这个位置的Node；如果当前的hash值相等，并且key相等，直接返回val；如果当前值的哈希小于0，则表示当前的Node要么是TreeBin，或者ForwardingNode，然后调用其find()函数查找。其他情况下，即链表情况，遍历链表返回结果。1234567891011121314151617public V get(Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek; int h = spread(key.hashCode()); if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (e = tabAt(tab, (n - 1) &amp; h)) != null) &#123; if ((eh = e.hash) == h) &#123; if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) return e.val; &#125; else if (eh &lt; 0) return (p = e.find(h, key)) != null ? p.val : null; while ((e = e.next) != null) &#123; if (e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) return e.val; &#125; &#125; return null;&#125;其中find会根据Node不同调用各自的find函数。首先是ForwardingNode的find函数，首先，在这个Node的情况下，表示当前Node的值已经迁移到了新的哈希桶数组中，因此在查找时，也需要进入新的哈希桶数组中查找。循环尝试nextTale中定位hash位置。通过Node或者TreeBin查找节点。具体代码如下，其中保证了扩容后的哈希桶数组又出现扩容等情况，通过不停对于每个数组尝试操作。1234567891011121314151617181920212223Node&lt;K,V&gt; find(int h, Object k) &#123; // loop to avoid arbitrarily deep recursion on forwarding nodes outer: for (Node&lt;K,V&gt;[] tab = nextTable;;) &#123; Node&lt;K,V&gt; e; int n; if (k == null || tab == null || (n = tab.length) == 0 || (e = tabAt(tab, (n - 1) &amp; h)) == null) return null; for (;;) &#123; int eh; K ek; if ((eh = e.hash) == h &amp;&amp; ((ek = e.key) == k || (ek != null &amp;&amp; k.equals(ek)))) return e; if (eh &lt; 0) &#123; if (e instanceof ForwardingNode) &#123; tab = ((ForwardingNode&lt;K,V&gt;)e).nextTable; continue outer; &#125; else return e.find(h, k); &#125; if ((e = e.next) == null) return null; &#125; &#125;&#125;而对于TreeBin的find，在每次循环中，先判断当前是否已经进入写锁（即存在写的线程或者等待写的线程），如果是，则判断当前节点的hash以及key相等，则直接返回当前节点，否则则进入下一个节点（在TreeNode中也又Node的元素，因此每个节点依然有指向下一个节点的引用）；当前没有写锁的情况下，使用CAS操作给TreeBin加上读锁，并查找Node，并在finally中，判断如果将读锁去掉一个读锁后，不存在正在写的线程，则唤醒正在等待写的线程。12345678910111213141516171819202122232425final Node&lt;K,V&gt; find(int h, Object k) &#123; if (k != null) &#123; for (Node&lt;K,V&gt; e = first; e != null; ) &#123; int s; K ek; if (((s = lockState) &amp; (WAITER|WRITER)) != 0) &#123; if (e.hash == h &amp;&amp; ((ek = e.key) == k || (ek != null &amp;&amp; k.equals(ek)))) return e; e = e.next; &#125; else if (U.compareAndSwapInt(this, LOCKSTATE, s, s + READER)) &#123; TreeNode&lt;K,V&gt; r, p; try &#123; p = ((r = root) == null ? null : r.findTreeNode(h, k, null)); &#125; finally &#123; Thread w; if (U.getAndAddInt(this, LOCKSTATE, -READER) ==(READER|WAITER) &amp;&amp; (w = waiter) != null)//判断如果将读锁去掉一个读锁后，不存在正在写的线程 LockSupport.unpark(w); &#125; return p; &#125; &#125; &#125; return null;&#125;putput操作中，与HashMap有所不同，此处不支持value为null。整个put操作分为几个部分，计算位置，判断哈希桶状态是否需要加入帮助扩容，放入节点，判断是否需要红黑树化。首先计算哈希值以及一些准备状态，比较简单。需要说明的是binCount在这儿代表着的是当前链表的长度，当已经是红黑树时，直接赋值2。然后进入循环尝试put操作中。1、当哈希桶数组不存在时，初始化数组当进入初始化函数后，将会去循环尝试，循环里先判断sizeCtl是否已经小于0，表示已经有其他线程进入了初始化的环节了，因此自旋等待；其他情况则尝试将sizeCtl置为-1，然后初始化一个哈希桶数组，最后将sizeCtl置为数组长度乘上负载因子。需要注意的是，Thread.yield();是将当前线程从运行态放入就绪状态的队列，一旦抢到cpu就可以继续执行。并且这里是循环里执行的，只要没有进入put完成，就会一只循环去尝试put。2、当hash值散列到数组上位置为空时，尝试cas操作去直接put，成功则退出。3、当哈希桶数组对应位置上的值已经迁移到新的哈希桶数组时，即hash为-1，则帮助扩容。扩容相关后续详解。4、其他情况，表示当前节点有值，形成链表或者红黑树。首先在该节点上加锁，并再次校验hash对应的是该数组位置。当为链表时，直接将Node放了进去，注意重复key存在的情况会根据onlyIfAbsent判断是否更新，并且循环链表时，需要给binCount自增。如果是红黑树的情况，直接将binCount设置成2，使用putTreeVal函数放入新节点或者拿到老节点，同样根据onlyIfAbsent更新新的val。在加锁结束后根据binCount是否大于等于8来判断是否需要进行红黑树化。同样的，进行红黑树化时，也需要对数组中的该节点进行加锁操作。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758final V putVal(K key, V value, boolean onlyIfAbsent) &#123; if (key == null || value == null) throw new NullPointerException(); int hash = spread(key.hashCode()); int binCount = 0; for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; if (tab == null || (n = tab.length) == 0) tab = initTable(); else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin &#125; else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else &#123; V oldVal = null; synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; if (fh &gt;= 0) &#123; binCount = 1; for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; if ((e = e.next) == null) &#123; pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; else if (f instanceof TreeBin) &#123; Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; if (binCount != 0) &#123; if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125; &#125; addCount(1L, binCount); return null;&#125;当然，在最后循环尝试结束后，将总数加1。在增加数量时，会有根据check来判断是否需要扩容，@param check if &lt;0, don&#39;t check resize, if &lt;= 1 only check if uncontended。addCount的基本逻辑如下。1、尝试使用cas修改baseCount。2、如果修改失败，则随机取CounterCell数组的一个元素更新数据。3、如果数组为空或者更新失败则调用fullAddCount函数，进行循环插入插入数据。此处包括对应CounterCell数组的一系列扩容操作。4、如果需要check，则调用sumCount函数计算总数，根据情况扩容。当然分别有扩容的初始化数组主线程以及帮助扩容的其他线程，根据sizeCtl的值进行判断。sumCount的计算，是将baseCount的值与数组中的所有值累计。扩容扩容是ConcurrentHashMap中非常重要的操作，类似在HashMap中相同，扩容的基本操作都是将哈希桶数组的长度扩展成两倍，然后将当前桶中的节点依次迁移到新的桶的。同样的，在迁移的时候，只需要将节点迁移到新的哈希桶的数组中的相对位置以及右移当前数组长度的位置。首先，在什么时候可以进入扩容操作呢？1、当在每次put的addCount时，map的节点数量达到扩容的负载的限制时，则进行扩容；2、当put时候判断已经进行扩容的时候，则进入帮助扩容；3、当进行清除的时候，正在扩容也进入帮助扩容；当在替换节点时，（删除记做替换节点为null）的情况下，如果哈希桶数组在扩容也进入帮助扩容。1、扩容开始时，首先计算每个线程需要迁移的哈希桶数组的元素，最少16，此处充分利用了cpu的并发粒度，计算同时并发时每个线程需要负责的数目。2、当扩容后的迁移哈希桶数组不存在的时候，尝试创建哈希桶数组。3、构建ForwardingNode指向新的哈希桶数组。4、循环中去申请扩容负责的部分，以及进行扩容。在这里面advance代表是否进入迁移下一个节点，而finishing代表是否以及完成了当前分配负责区域的迁移。5、循环尝试使用cas操作分配迁移的的数组的索引下标，advance设置成true，进入迁移操作。6、判断分配阈值超过范围。根据finishing判断结束，则更新一些变量（此处对于一次扩容只会执行一次）；其他情况，则将sizeCtl减1成功，表示有新的线程完成了扩容操作，然后通过(sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT筛选出最后一个线程设置finishing为true进入扩容的最后操作，即上述说的进行变量更新操作（这儿保证了只有一个线程进行该操作）。最后一个线程将循环哈希桶数组进行再次校验所有的节点已将迁移完成。7、如果当前需要迁移的数组元素为null，则直接使用cas设置为ForwardingNode，设置成功则前进。8、如果当前正在迁移，即hash为-1，则直接前进。9、当前哈希桶数组元素存储的是链表或者红黑树。对node进行加锁并再次校验。在这种情况下，当然依然需要对链表、红黑树进行分别的处理。首先是链表的情况，这种情况下，拆分成两个链表也不会出发红黑树化的操作。先得到迁移相对位置或者偏移位置的某一种情况的最后一个节点，即最后一个与前一节点迁移位置不同的节点，即在这个节点之后的节点都会迁移到相同的位置。并根据这个节点是否需要迁移，将节点赋值给ln或者hn，前者是迁移到相对位置，后者迁移到偏移位置。循环链表构建两个数组，链表只需用循环到上述所得最后一个与前一个节点迁移位置不同的节点即可。最后将两个链表写入新的链表的对应位置，然后将当前哈希桶数组的值设置成ForwardingNode，表示已经完成扩容。为什么需要先进行定位到最后不需用循环做构建新链表的，然后再循环到该节点呢构建链表呢？这点上我暂时没有明白，毕竟一个链表的最大长度也就7的长度，不管怎么做，其效率都是非常高的，而且不会出现特别慢的情况。另一种情况就是红黑树的情况。这种情况下依然需要构建两个红黑树，当然最开始构建的时候是构建两个TreeNode的链表，当然同时需要记录每个链表的节点数。最后根据计数结果判断是构建红黑树还是链表化。构建红黑树的时候是在TreeBin的构造函数。然后设置新的哈希桶数组的值，最后前进。最后循环进入下一个需要迁移的位置。在上诉说的第6点中提到了sizeCtl的值通过标记的移位等操作判断是最后一个执行的线程。相关代码如下。12345678...if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) &#123; if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) return; finishing = advance = true; i = n; // recheck before commit&#125;...这部分中容易受到sizeCtl注释中的影响，注释中如下，说明有负的（1+n）时代表有n个线程在帮助扩容，在我的理解下这儿的注释是错误的。When negative, the table is being initialized or resized: -1 for initialization, else -(1 + the number of active resizing threads).我的理解下，sizeCtl在进入的扩容的第一个线程时，声明为一个负得很大的数，比如当一个容量为64的map扩容时，这个sizeCtl在第一个线程进入扩容后的值为-2145845246。然后在每个线程进入扩容后，会将这个sizeCtl加1，然后每次线程结束扩容后将sizeCtl减1。所以当前正在扩容的线程应该是(resizeStamp(tab.length()) &lt;&lt; RESIZE_STAMP_SHIFT) + 2 - sizeCtl + 1。至于为什么要这么写来表示扩容呢？这点上我不是很清楚。在下面代码中表示了每个进入扩容的函数都会经历的部分相似逻辑。12345678910111213...while (s &gt;= (long)(sc = sizeCtl) &amp;&amp; (tab = table) != null &amp;&amp; (n = tab.length) &lt; MAXIMUM_CAPACITY) &#123; int rs = resizeStamp(n); if (sc &lt; 0) &#123; if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex &lt;= 0) break; if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) transfer(tab, nt); &#125; else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) transfer(tab, null);&#125;...其中表示了当已经进入扩容的情况下，当前线程加入后线程线程数限制resizeStamp + (1 &lt;&lt; (32 - 16)) - 1)，需要校验如果扩容分配的空间已经分配完成，如果满足这些条件下，则线程退出不进入扩容，否则将sizeCtl加1，进入扩容。如果没有线程进入扩容，则将sizeCtl初始化，然后进入扩容。replaceNode为什么要特别提及replaceNode函数呢？replaceNode函数不仅仅在replace的时候使用了，而且在remove的时候也调用了，只是传入的value为null。依旧，首先计算哈希值，然后循环尝试。1、当数组不存在或者哈希定位的值不存在时，结束。2、如果当前位置已经扩容，代表当前map进入扩容操作，则帮助进行扩容。3、其他情况，即当前位置存在链表或者红黑树等。这种情况下，会将当前节点加锁，并进行再次校验验证。当前是链表的情况，循环找到key对应的节点，如果需要更新的value是null的情况，则删除节点，否则替代节点。（首节点的情况下，需要单独处理，将首节点的Node设置到哈希桶数组中。）红黑树的情况，使用TreeNode的findTreeNode函数返回对应的节点，value不为null的情况，更新value或者使用removeTreeNode删除节点。删除情况通过removeTreeNode返回true/false结果判断是否进行红黑树化。4、在循环尝试结束后，判断是否删除以及是否成功等，将map的节点数减1。clearclear的意思是移除map中的所有的node，当然依然是循环哈希桶数组中的每个元素，做去除操作。每个循环里定位到当前节点。1、如果当前节点为空的情况，直接进入下一个节点。2、当前节点的hash为-1时，表示当前节点以及迁移到新的哈希桶数组，则进行帮助扩容操作，并将需要clear的哈希桶数组修改为扩容后的数组，并将清除索引修改为0，扩容后重新进行清除操作。3、其他情况，即当前节点存在链表或红黑树的情况。先给节点加锁，然后获取链表的开始节点，TreeNode的情况下也有指向下一个Node的引用，开始节点为TreeBin的first指向的节点。循环链表，累计Node的数目。然后将当前哈希桶数组的节点置为null。1234567891011121314151617181920212223242526272829public void clear() &#123; long delta = 0L; // negative number of deletions int i = 0; Node&lt;K,V&gt;[] tab = table; while (tab != null &amp;&amp; i &lt; tab.length) &#123; int fh; Node&lt;K,V&gt; f = tabAt(tab, i); if (f == null) ++i; else if ((fh = f.hash) == MOVED) &#123; tab = helpTransfer(tab, f); i = 0; // restart &#125; else &#123; synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; Node&lt;K,V&gt; p = (fh &gt;= 0 ? f : (f instanceof TreeBin) ? ((TreeBin&lt;K,V&gt;)f).first : null); while (p != null) &#123; --delta; p = p.next; &#125; setTabAt(tab, i++, null); &#125; &#125; &#125; &#125; if (delta != 0L) addCount(delta, -1);&#125;在循环清理完成后，调用addCount函数将map中的总数减掉清除的Node数目。附compute是传入function来计算新值，然后put（前提是符合条件，才进入计算新值）。以及merge等函数等。以及在1.8版本后推出使用mappingCount()来代替size函数。ConcurrentHashMap是支持并发的Map，并且尽量减少来加锁的操作以及减小了加锁的粒度，并使用了CAS操作，因而增大了并发度。对于其中一些设计及写法的原因，目前还很迷糊。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>map</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决SXSSF使用时“Attempting to write a row[?] in the range [0,?]that is already written to disk.”异常]]></title>
    <url>%2F2018%2F09%2F22%2F%E8%A7%A3%E5%86%B3SXSSF%E4%BD%BF%E7%94%A8%E6%97%B6%E2%80%9CAttempting-to-write-a-row-in-the-range-0-that-is-already-written-to-disk-%E2%80%9D%E5%BC%82%E5%B8%B8%2F</url>
    <content type="text"><![CDATA[在开发中，使用SXSSFWorkbook构建导出excel时，可能会遇到“Attempting to write a row[?] in the range [0,?]that is already written to disk.”的报错情况，如下图所示。对于这种情况下，需要我们详细分析，首先时这个错误时从哪儿抛出的，通过源码分析，查看到在SXSSFSheet的createRow函数中找到这样一个抛出异常的位置。1234567 ...if (rownum &lt;= this._writer.getLastFlushedRow()) &#123; throw new IllegalArgumentException(&quot;Attempting to write a row[&quot; + rownum + &quot;] &quot; + &quot;in the range [0,&quot; + this._writer.getLastFlushedRow() + &quot;] that is already written to disk.&quot;);&#125; else if (this._sh.getPhysicalNumberOfRows() &gt; 0 &amp;&amp; rownum &lt;= this._sh.getLastRowNum()) &#123; throw new IllegalArgumentException(&quot;Attempting to write a row[&quot; + rownum + &quot;] &quot; + &quot;in the range [0,&quot; + this._sh.getLastRowNum() + &quot;] that is already written to disk.&quot;);&#125; else &#123; ...分析这段异常的原因，当前要创建的行小于等于最近已经创建的行时，就会抛出异常。因此这个要求是，我们不能在已经创建行的位置再创建行。究其原因，是在于SXSSFWorkbook的本身实现方式，其本身实现方式在于，不断的将一定行数的表格写入临时文件，最终将所有的临时文件合并起来，这种方式中保证了内存的占用数理想，并且导出的效率也比较理想。在这种实现中，如果一个行已经写入临时文件了，就不能再修改了，因此在源代码中直接限制了重复创建并写同一栏，并在此抛出异常。解决方案1、使用HSSFWorkbook、XSSFWorkbook替代SXSSFWorkbook。这种方式中要么是在HSSFWorkbook中仅支持xls，并且导出的数量有限，并且导出文件效率也较低，内存占用较大；虽然在XSSFWorkbook中，导出效率提高了，使用了xlsx格式，导出数量限制也大大放宽，但是内存占用问题依然没有得到解决。2、避免在已经创建的行上重新创建行，使用getRow代替重复创建的情况。注：多数情况下，这种情况的出现，都是因为程序行数计数标志出现了重复、计数错误等情况导致的。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>poi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[根据前序和后序遍历构造二叉树]]></title>
    <url>%2F2018%2F08%2F19%2F%E6%A0%B9%E6%8D%AE%E5%89%8D%E5%BA%8F%E5%92%8C%E5%90%8E%E5%BA%8F%E9%81%8D%E5%8E%86%E6%9E%84%E9%80%A0%E4%BA%8C%E5%8F%89%E6%A0%91%2F</url>
    <content type="text"><![CDATA[在leetcode上做题刚好做到一题：根据前序和后序遍历构造二叉树。在我们一般构建二叉树时，一般是根据中序和前序或者后序构建二叉树。根据前序和后序构建的二叉树不一定是唯一的。889. 根据前序和后序遍历构造二叉树返回与给定的前序和后序遍历匹配的任何二叉树。pre 和 post 遍历中的值是不同的正整数。不多说，上代码：12345678910111213141516171819202122232425262728293031323334353637public TreeNode constructFromPrePost(int[] pre, int[] post) &#123; if (pre.length &lt;= 0) &#123; return null; &#125; return constructFromPrePostHelper(pre, post, 0, 0, post.length - 1);&#125;private TreeNode constructFromPrePostHelper(int[] pre, int[] post, int flag, int postStart, int postEnd) &#123; if (flag &gt;= pre.length || postStart &gt; postEnd) &#123; return null; &#125; else if (flag &lt; pre.length &amp;&amp; postStart == postEnd) &#123;//判断没有子树的节点 return new TreeNode(pre[flag]); &#125; int mid = postStart; //判断左右子树的分隔点 if (flag + 1 &lt; pre.length) &#123; for (; mid &lt; postEnd; mid++) &#123; if (post[mid] == pre[flag + 1]) &#123; break; &#125; &#125; &#125; TreeNode node = new TreeNode(pre[flag]); node.left = constructFromPrePostHelper(pre, post, flag + 1, postStart, mid); node.right = constructFromPrePostHelper(pre, post, flag + mid - postStart + 2, mid + 1, postEnd - 1); return node;&#125;public class TreeNode &#123; int val; TreeNode left; TreeNode right; TreeNode(int x) &#123; val = x; &#125;&#125;测试用例：输入：pre [1,2,4,5,3,6,7], post [4,5,2,6,7,3,1]输出：[1, 2, 3, 4, 5, 6, 7]原理：在通过递归的方式，每次找到分隔点，构建左右子树的方式，在其中主要需要判断最终一个没有子树的节点判断。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[这是一只不正经的猫：读《我是猫》]]></title>
    <url>%2F2018%2F08%2F14%2F%E8%BF%99%E6%98%AF%E4%B8%80%E5%8F%AA%E4%B8%8D%E6%AD%A3%E7%BB%8F%E7%9A%84%E7%8C%AB%EF%BC%9A%E8%AF%BB%E3%80%8A%E6%88%91%E6%98%AF%E7%8C%AB%E3%80%8B%2F</url>
    <content type="text"><![CDATA[这是一个不正经的猫，从本书中的这只猫来看，这只猫似乎有一种通晓天地，明了古今。能够不经历九年义务教育就懂得一些教育学家以及理学家的谈话。这只猫或许在老师的家里待得太久，就明了这许许多多的人事与时事，也或许通过猫界里的“人类学家”精心传授。这些都是些不正经的话语。每一本书，都有自己独到的地方，这本书当然不例外。以猫的角度写某个时期的场景，确实有一种无法比拟的悲。这种悲主要是指那些知识分子等的悲。然而这种悲伤，我无法去感同身受。人们所能感同身受的悲，莫过于自己经历过同样的悲伤。我或许还不像这书中的知识分子同样，有着面对新潮而无法接受，或者在某一种程度上却自己不被世界接受的悲伤。《我是猫》是过去作品吗？或者说写的仅仅是过去的某个时代的吗？这却得深思，在当今这个社会里，没有那些相同的吗？像苦沙弥，他正代表着自己这一类知识分子，对于实业者有着一种鄙夷，而反之金田所代表的实业家，也对那些穷苦知识分子有一种轻蔑。这是明显的两个阶层之间的矛盾。在当下，依然在有条不紊地摩擦着。这本书，我没有多少感悟，这也是一种缘。摘来部分难得的机缘，会使所有的动物敢于干出他们并非情愿的事来。临危之际，平时做不到的事这时也能做到。看起来，人哪，为了消磨时间，硬是鼓唇摇舌，笑那些并不可笑、乐那些并不可乐的事，此外便一无所长。一言以蔽之，不论是主人、寒月还是迷亭，都是些太平盛世的逸民。尽管他们像没用的丝瓜随风摇曳，却又装作超然物外的样子。其实他们既有俗念，又有贪欲。即使在日常谈笑中，也隐约可见其争胜之意、夺魁之心。进而言是一丘之貉。假如既不能零售空气，又不能割据苍天，那么，土地私有，岂不也是不合理的吗？真理在咱家手里，而权力却握在别人的手心，这时，只有两条路：或委曲求全，唯命是从；或背对权贵的耳目，我行我素。我想写美学原理的意志很坚定，可这意志对你发表后的第二天就已经忘得一干二净。因此，没能在紫薇花飘零以前完成我的著作，这时记忆力的罪孽，而不是意志的过错。既然不是意志的过错，也就没有什么理由请你吃西餐了。既然是社会动物，不管怎么自命清高，也要在某种程度上与社会协调些。那些家伙到底是“知了知了”地叫？还是“了知了知”的地鸣？冷漠乃人类本性，不加掩饰才是正直的人。]]></content>
      <categories>
        <category>read</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[时间简史：读完了多少，读懂了多少]]></title>
    <url>%2F2018%2F07%2F29%2F%E6%97%B6%E9%97%B4%E7%AE%80%E5%8F%B2%EF%BC%9A%E8%AF%BB%E5%AE%8C%E4%BA%86%E5%A4%9A%E5%B0%91%EF%BC%8C%E8%AF%BB%E6%87%82%E4%BA%86%E5%A4%9A%E5%B0%91%2F</url>
    <content type="text"><![CDATA[读完这本书，仅仅用读完来形容了。这书里面的有许多的知识都是我无法去理解的。果然发现，这是一本不符合畅销书的畅销书了。这本书里，虽然没有提到多少公式性的推到，只放了一个E=mc^2 爱因斯坦质能方程，然而就这样一本定位于科普读物的书籍，却没有多少人能够读完。为什么是畅销书呢？我们先分析人类读书的意图，除了应付考试、学以致用，剩下的一个很重要的就是“装逼”了。虽然这样谈吐起来，确实并不文雅，但现在人读书都是有着一个目标去读书的，像如何在书籍里得到职场的一些经验，如何应付当前的考试，如何在书籍里找回自己那个颗沉静的心，如何表现出高逼格等，都是现实中读书的一些需求。在现在，书籍除了用于阅读外，还有装潢的作用了。这个作用可大了，除了放在家里作实物上的修饰外，还有作为一种谈论资本上的学识上的修饰。我并不是说这个装饰不好，反而我却非常认同这种装饰，毕竟在这个装饰中，体现了一个主人的思维——读书是非常好的，知识是值得炫耀的。这点上我是非常认同的。在这本书上，除了阅读本身外，就剩下一些装饰了，而且这本书，在我看来平常的用处里，在实物上的装饰应该占比较高。有多少人读完了？又读懂了多少呢？曾有人有过这样一个观点：当哲学与科学分离后，就只剩下对于语言的理解。这点我是非常认同的。反之，科学脱离哲学后，却增加了更多的专业性以及推理性。因此在后代科学中，更加专业，并且多数基于观察现实以及对未来的预测。这本书之所以晦涩难懂，还有一个很根本的原因，因为时间简史，是基于数学运算而得出的推理，并不是基于现实的观察，这种晦涩因此十分明了了。当然，这种读完与否、读懂与否，都是一种收获。至少明白了，这世间，有许多前沿性的知识，是我当下所不能理解的。所谓不懂也是一种收获。在时间简史里，主要介绍了宇宙的本身、以及宇宙中的粒子、黑洞以及时间等许多，这些理解都是我们的基础中的认识。像这一类的科学读物，都是通过这类的读过，丰富自己的认识，或者说纠正自己的那些认识。像我平时认识中，并不明白宇宙膨胀等，也不懂一些不确定性原理等。其中我最感兴趣的就是黑洞了，黑洞并不是指洞，而是指一个密度极高的星体，将周边粒子都吸了进去，包括光粒子都逃脱不了，正式因此，所以称为黑洞了。而关于时间，我不是很明白，不懂得在数学及物理学上是怎么去量化时间的。也不明白每个人的固有时间，在物理学中是如何去推算的。但觉双生子违谬十分有趣，才明白所谓违谬，是指假的谬论，也就是这个推理是真的。其实这本书，读懂了多少？又有多少能去理解。这是一篇不像读后感的读后感，毕竟我也没读懂多少。]]></content>
      <categories>
        <category>read</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[白说：并不白说]]></title>
    <url>%2F2018%2F07%2F15%2F%E7%99%BD%E8%AF%B4%EF%BC%9A%E5%B9%B6%E4%B8%8D%E7%99%BD%E8%AF%B4%2F</url>
    <content type="text"><![CDATA[读《白说》完这本书，我是不怎么敢写读后感的。如果真的要详细写来，其中每一篇文章都可以写一个很深刻的认识，每一篇都给我一些相见恨晚的感觉。我在意的读后感，只是读后的一些感悟，形散意散，但的来源于感。我就谈谈其中一小部分的感受，这是值得再读多遍的书。《白说》，这是一本演讲集，集中了一些白岩松先生的演讲。或者也可以说成“鸡汤式”的演讲，但又不同于那些华而不实的“鸡汤”。那些鸡汤似的文大多没有多大的真实价值，唯一，也是最大的价值便是希望。也正如所有的鸡汤文一样，这本书也给希望。希望是鸡汤文里最重要的东西了，或者在很多环境都是最重要的东西。我将《白说》解释为“鸡汤”，只是代表着，它如“鸡汤文”一样，描述着正面的东西，或者正在变好，或者期望着并有实际行动变好的东西。在这点上，它们是相似的。但是在许多方面，这是一本极其厉害的书籍，包含着许多哲理性的认识，也有许多有高度的认识，用相见恨晚或者醍醐灌顶都不为过。为什么我会用相见很晚来形容呢？这本书里，涉及的东西，很多，很广。主要有幸福、成功、信仰、沟通、音乐、希望、中国梦等一系列都提到的东西。我之前的一些认识或观点，都跟这本书有一些相似，或许在印证我并不是奇怪的。我们向前走得太远了，把自己走蒙了：我到底要去哪儿啊？我确实在很多时候都很迷惘，不知道自己究竟该去哪儿？在一个物质虽然丰富的，却经济基础不能满足的环境里，我很迷惘我何去何从。或许有很多90后和我一样，被现实的房价给打击的毫无意志。“别忘了当初为什么出发”，对了，我当初为了什么出发？我出生于某个农业县的一个小村庄，为了改变自己的人生吧，就这样走着，似乎改变是已经改变了。我原来谈过幸福，我理解幸福是现实于理想的差距。但这个终究只是一种宏观意义上的理解，具体上一般理解，经济基础以及精神依靠就是幸福了。幸福需要三个层面的因素，物质、情感和精神。物质是基础，情感是依靠，精神是支柱。这些都是外在给予幸福的定义，或者应该称为条件。除了这些条件外，应该还有意识。意识或许也是在某个程度上，决定着是否幸福。幸福，不管如何，都是人的主观感受。若使你已经或者了经济、情感、以及精神，就一定幸福吗？这点就在于认识了，如果你觉得满足或者说快乐了，那就是真的幸福了。最幸福的生活状态，应该是总有一个踮起脚能够着的目标，吸引你踏踏实实始终向前。幸福的相关性太过于繁复，我理解的我们应该做好自己的这一部分。或者调整好自己的心态。人生中得意和失意都只占5%，剩下的90%是平淡。而如何将这90%过得有趣便是幸福了。正如在这些许平淡中，找到真正的乐趣，将平淡过的不平淡。生活中，没一点滴都会有有趣的东西。今天在小区里闲逛，刚好发现小区的停车位的编号的刚好都没有4结尾的，或许这是一种迷信的讲究。也或许是业主为了避免某些讲究的停车用户。在现实中，学会平淡中的心态，以及好奇的心态。正如图中，如果你处在拥挤的车流中，还能够释然吗？这便是心态，以及上述提到的没有4结尾的编号，那便是好奇了。其实，人生只要拥有很多趣味，听音乐、喝茶、美食、收藏、阅读、喝酒、有好朋友聊天……前路平淡或坎坷，就都没太大关系。我似乎谈了太多的幸福了，应该谈论些其他。信仰也是我谈过多次的东西。正如本书里涉及的一样，幸福与信仰有关，信仰也关于音乐等，一切世界里的东西都联系了起来。在本书中，还有一个非常值得去思考的是人性。如何根据人性来思考、以及决策。现在许多公司都实行了股份、期权等制度，就是将人本身的利益与公司的利益高度集中话，促进了员工的努力。这种制度，在某个程度上，就是对于人性的思考，人本身是自私的，我从来不相信什么大公无私的，那都是违背人性的，不符合科学的。正如在公益的环境下，所谓做公益就没有私心吗？这是不正确的。对于做公益而言，都是有私心的，追求内心的那一种宁静，那种帮助别人后的到喜悦或者幸福感，应该是现在公益所应该追求的。所以对于所有的东西发展等，都不应该违背人性，应该从人性的角度去思考，应该如何。比如在做产品设计一样，不应该有违背人性的操作或过程的存在。在生活中，也不应该用违背人性的规定约束人们。不经意间，我谈了许多，却完全没有完尽，这本书中有太多的东西，我拿了一些出来，提了自己的感受。当然在这本书中，通过演讲的方式，传达信息，讲一些有趣的故事，进行论述观点，或许还有一些演讲的知识等。《白说》：并不白说，十分有趣。附我谈论的一些：谈幸福信仰再论信仰探究人性]]></content>
      <categories>
        <category>read</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot解决返回体content-type非json]]></title>
    <url>%2F2018%2F07%2F07%2FSpringBoot%E8%A7%A3%E5%86%B3%E8%BF%94%E5%9B%9E%E4%BD%93content-type%E9%9D%9Ejson%2F</url>
    <content type="text"><![CDATA[最佳解决方案为自定义消息转换器。首先，为什么要自定义消息转换器？所见即所得，原本的消息转换器并不能满足我们目前的需求。在最近的项目中，使用了SpringBoot与FastJson构建项目，在我们返回时，使用 @ResponseBody的方法里，采用了fastjson里的JSON.toJSONString()方法返回我们需要的Json数据，而这种返回中，会有一个问题，在返回中@ResponseBody注解中的消息转换器会默认理解为String解析，在返回体中如下图，content-type为text/html。因此我们解决想让我们的返回体中content-type为application/json。针对于这个问题，有一种最暴力的解决方案，直接在@RequestMapping中添加produces属性，设置produces=&quot;application/json&quot;直接使得返回体设置为json格式。当然对于这种每个接口暴力解决的方案来说，对于每写一个接口都需要设置，因此增加我们写代码的重复性工作，因此需要一个一劳永逸的方式。在@ResponseBody里默认有消息转换器，一般json转换使用的是JackJson进行转换的，而我们在项目中配置使用fastjson，因此需要修改消息转化器。首先消息转化器中不只有json转换器，还有字符转换器等。在我们的项目中可以自定义一个配置类，标注有@Configuration或者在@SpringBootApplication的启动配置类中添加下面代码，就增加了fastjson的消息转换器注入。12345678910111213141516171819/** * fastjson消息转换器 * @return */@Beanpublic HttpMessageConverters httpMessageConverters() &#123; FastJsonHttpMessageConverter fastJsonHttpMessageConverter = new FastJsonHttpMessageConverter(); //添加fastJson的配置信息 FastJsonConfig fastJsonConfig = new FastJsonConfig(); fastJsonConfig.setSerializerFeatures(SerializerFeature.PrettyFormat); //处理中文乱码问题 List&lt;MediaType&gt; fastMediaTypes = new ArrayList&lt;&gt;(); fastMediaTypes.add(MediaType.APPLICATION_JSON_UTF8); //在convert中添加配置信息. fastJsonHttpMessageConverter.setSupportedMediaTypes(fastMediaTypes); fastJsonHttpMessageConverter.setFastJsonConfig(fastJsonConfig); HttpMessageConverter&lt;?&gt; converter = fastJsonHttpMessageConverter; return new HttpMessageConverters(converter);&#125;当然需要注意，这种配置的方式必须在fastjson 1.2.44版本及之后才支持。在我们使用Maven构建项目是，需要添加fastjson的依赖。12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.44&lt;/version&gt;&lt;/dependency&gt;使用这种配置后，可以在返回中去掉我们的json转化，并直接返回我们需要转化的实体，在消息转换器中会自动调用fastjson进行转json。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[边城：性格使然的悲剧]]></title>
    <url>%2F2018%2F06%2F27%2F%E8%BE%B9%E5%9F%8E%EF%BC%9A%E6%80%A7%E6%A0%BC%E4%BD%BF%E7%84%B6%E7%9A%84%E6%82%B2%E5%89%A7%2F</url>
    <content type="text"><![CDATA[再一次拿起边城，沈老先生的文笔，一直是朴素大方的，一篇中篇小说，从开始到结局，没有一点一丝的矛盾，顺其自然的发展，没有斧凿痕迹的自然。这本小说里，写的世界是美好的，每个人都有着最朴实无华的品质，没有那些勾心斗角，没有那些灯红酒绿，一切都是人最期望的平凡与宁静。而悲剧式的结尾并没有像其他悲剧一样——将美好的东西毁灭给人看，这是一种自然而然地美好式的悲剧。从开始翠翠害羞地避开问题时，就知道最终会有伤害。在文中，每个人都是有着最普通人的品质，都是抽象的人，都在不同环境下，有着人心里的一些矛盾，一些自我的思维与责任。翠翠从塑造起，就是一个最普通农家女孩，从小与爷爷相依为命，因而对爷爷依赖极深，正因为这种爱，才对于爷爷渐渐老去而感害怕，害怕自己孤单一人。在自己十五六岁时，正伴随着自己思维的成长，因而有着普通孩子的害羞，对于爷爷每次谈到恋爱婚姻等询问时，都避而不答。对于喜欢的人，因为害羞远远避开，不敢去相遇。爷爷也是极其普通老爷爷的形象，大方得总是将自己的小葫芦酒给别人喝上几口，对别人也总是嘘寒问暖。对于翠翠也是极其的爱护，希望将翠翠交给一个好人家照顾，在对于翠翠终身大事上，让翠翠自己去选择。但完全没想到，因为自己，却造成了船总大儿子天保的英年早逝，而无比地自责，也对于翠翠的未来感到无比的担忧。怀着这种愧疚，最终在大雨中去了。船总顺顺，一个朴实能干的实业家，有着幸福美满的生活。对于儿子的婚姻，也是由其发展，却也希望有一个好的未来。在小城里，是一个公正大方的人，与每个人都有着较好的关系，都受到基本人的尊重。从大儿子的死，也埋冤那老爷子，因此也不愿意再将这一个女孩迎回家门。天保，继承了父亲的老实朴素，是一个少有大为的孩子。在知道翠翠喜欢的人是瘫送时，没有选择与兄弟的反目，而是公平的竞争，以及最后的放手。一个朴实无华的老实人跃然纸上，没有对于人过多的描述，只是寥寥的点点事迹。瘫送，相比较其大哥来说，更加有聪明以及才智等。在爱恨情仇上，喜欢着翠翠，但是却又在其中得不到回复，因为失去了哥哥。却因为喜欢翠翠，始终没有怪翠翠。而却又因为自己在婚姻上的选择，与父母争吵后出去了。在沈老先生而言，文中描述一种旧时的闲适，或者一种民风，从现实中这种的消逝来说，结局正代表着这种民风的消逝，所以自然而然的悲剧的产生。我有时候怀疑，瘫送的出走，正代表着一种新青年的一种崛起，也许也代表着老先生本人。从人之间的关系，这种悲剧的产生，是性格使然的结果，如果再重复一次，依然会再一次重复这种悲剧。老爷爷因为十分爱护翠翠，每次当谈到恋爱等时，看到翠翠害羞时，都害怕继续谈下去翠翠生气，而避而不谈。却正因为没有告诉翠翠所有的事情，最终也是悲剧。这是一种因为爱护而自然而然的悲剧。而顺顺，作为父亲，因为失去的儿子而怪罪渡船老头，因为不愿意次子再娶了翠翠。这一些都是人本身性格的结果。在我认识里，虽然淳朴，但翠翠还没有真正认识到爱情，还在成长的懵懂期。正是这种害羞，不敢去面对自己喜欢的人，而没有从爷爷那里获知那一切发生的事。从每一个人的角度看来，所有人都在向着一个自己所能接受的美好的角度发展，然而从整体上而言，最终的悲剧是不可避免的。从人生角度去理解，只能感受到一种由衷的悲伤，但是这种却也是一种发展，当失去某些东西时，必定将伴随着一些的到来。像翠翠，虽然是悲剧的，但应该明白了之后的，会有长大以及思想的成熟。有时候在想，边城是代表着家乡的意思，代表着家乡的变化里，渐渐丧失了原来的一些东西，或许是自己离乡很久了，家乡就变得不像自己记忆里的那一种家乡了，最后便有了每个人心里都有一个属于自己的边城。]]></content>
      <categories>
        <category>read</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[类图中的关系]]></title>
    <url>%2F2018%2F06%2F03%2F%E7%B1%BB%E5%9B%BE%E4%B8%AD%E7%9A%84%E5%85%B3%E7%B3%BB%2F</url>
    <content type="text"><![CDATA[在我们使用UML图进行设计时，会涉及类图之间的关系，一般关系为以下的五种关系，理解其中的概要能够对于后续我们的设计有一定的帮助。1、一般化关系，或者称为继承关系2、关联关系关联关系中一个类知道另一个类的属性和方法。通常通过类里引用另一个类的实例变量实现。3、聚合关系聚合关系与下面的合成关系都是属于关联关系的一种。在聚合关系中，主要表现的是整体与个体的关系。由于本属于关联关系，因此也是通过实例变量的方式实现。聚合关系与关联关系的区别是，关联关系主要是两个类都是在同一个层次的。4、合成关系合成关系是指普通聚合关系的同时，代表整体的对象负责代表部分的对象的生命周期。合成关系是不能够共享的。代表部分的对象每个时刻只能与一个对象发生合成关系。5、依赖关系依赖关系主要指类的局部变量、方法参数以及对静态方法的调用，是另一个类的实例对象等。]]></content>
      <categories>
        <category>tech</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[读《机器崛起》]]></title>
    <url>%2F2018%2F05%2F30%2F%E8%AF%BB%E3%80%8A%E6%9C%BA%E5%99%A8%E5%B4%9B%E8%B5%B7%E3%80%8B%2F</url>
    <content type="text"><![CDATA[从开始看到这一本厚重的书，有着三百多扉页，竟然有这三十多页参考文献，让我感到有点震惊。一本本着将控制论过往的历史，引入了现代这个社会中方方面面的每一个点滴。现在我们手中的手机，包里的电脑，或者各种代步的工具，都由着这控制论的衍生。从机器里，提出控制论，或者因为控制，所以有的机器。我从书中，也得到一些有趣的论点。战争是技术最好的催化剂从人性角度，战争是残酷的；而从技术角度，战争是伟大的。每一次战争都很大促进了技术的发展。或者就在现在，军事上的技术依然超越我们目前可涉及技术一代。在第二次世界大战里，技术上提出了智能炸药以及防空系列如何预判飞行器的轨迹等武器等，都从战争中第一次的想让机器有着自动化的操作，像有着思维一般。并在后续军事技术的发展中，设计了智能头盔显示系统，以及后续的计算机网络防护。这些先进技术的发展，都是伴随着战争中的需求，或者战争后军事上的需求等，一个先进的技术上，都是从军事到民用的发展。战争在技术的发展中，明显担任了催化剂的作用。反馈从开始解除接触控制开始，就十分强调反馈的作用。在第一次接触反馈时，是在生物上的学习，有反馈调节系统，而在机器上，依然需要反馈，或者在生活的各个方面都需要反馈。在我们生活中，做每一件事，最后要能够快速给反馈。比如在针对别人的请求或者告知等事件时，需要我们首先反馈出我们的态度。或许在你每次知道事后，并没有反馈，或者对于发起人而言，告知你或许并没有那么必要，因为告知这个执行，并不知道成功与否。在机器上，同样。早期对于预算飞行器飞轨迹后，需要我们炮塔等防空无语快速作出反应。然而在炮塔的旋转后，并没有反馈是否旋转到位等，因此在后期中，引入反馈的概念。每一个系统，都是由各种反馈构成的，包括国家、机构、团队等。如果反馈机制在某一个重要的环节中断裂，就证明着现在系统是存在问题的。反馈的概念并不是仅仅针对于机器上而已，包括在生活的各个细节。在我接下来的所有行为中，我所接收到的重要消息等，我都会给予反馈，从康德的道德论来讲，我所希望的人与人之间的反馈是一种道德。信息信息即为力量。从Cybernetics所引发出赛博空间、赛博战争等。都是技术上的一种延伸。而在这些技术中，信息的重要性也尤为重要，这个在我们现在社会中也有很好的表现。信息，体现在了许多方面，比如常见的数据，也是信息的一种表现形式。因此在公司的发展中，能够保存的数据，应该存储好，后续可以做数据分析等，每一份数据都具有良好的价值。迷幻剂在计算机发展中，一直伴随着迷幻剂共同的发展，或者在某一个程度上计算机代替着迷幻剂的效果。每个人都会遇到自己的迷幻剂，但是能够说迷幻剂就是错误吗？并不能。技术在一定程度上，正是由于那些对技术如痴如醉的人，才有了技术的进一步发展。同然，在现在社会中，游戏或许在很大程度上代替着迷幻剂的作用。而对于有的经常喝醉的人而言，酒也是一种迷幻剂。而且我们无法确定自己是否已经身处迷幻剂，毕竟每个人都有所喜好的事或物。计算机是新时代的迷幻剂，下一个时代的迷幻剂会是什么？自由从赛博空间开始，都是人向往着自由，到现在的比特币技术，缘由都是想着不受控制。正因为这种对于自由的向往，才有着非对称加密技术的发展，也是第一次体现了单向函数的伟大，或者大素数的伟大作用。然而在加密技术的发展中，一直都在争议中发展。似乎体现着一种技术的成长都是带有一定的争议性，不知道目前的SDN以及区块链等是不是也是这样，最后都会发展为伟大的技术发明。附在书中还有许多有趣的故事。但是整体而言是诉说控制论以及机器的发展历程。比如在Bose提出新的播放器理论后，却没有公司接受，最终选择自己去执行，最终形成现在的Bose。都告诉我们，如果有想法，就去实现，不要犹豫。]]></content>
      <categories>
        <category>read</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[读罢此书]]></title>
    <url>%2F2018%2F03%2F19%2F%E8%AF%BB%E7%BD%A2%E6%AD%A4%E4%B9%A6%2F</url>
    <content type="text"><![CDATA[读罢此书，《自在 独行》。带着寻找心灵解药的本心，开始追寻着文学上、心理上的解脱，想要去追寻出我所期望的高度是什么，想去让自己幸福，想渡自己。读罢此书，一篇篇散文，有的朴素，有的却有深意。我明白这是一个自在的贾先生写的自在。但是我终究没有理解独行，或许是我所理解的独行不对。这书里万事万物，都以一种自由的美好角度所展示，我能看出作者所热爱的生活。当然，我明白，文字能够表现出的，是作者所想的意，或者人的细节。我明白贾先生有大男子主义，是我所不喜好的。从生活的美好里，追求生活的意义。不敢停止思考，我一直都在害怕，害怕着当有某一天，我看透了这个人生，选择离去。我害怕我会思考出自己生命的意义是没有意义。从来，对于每个人的选择都是敬畏的。当海子选择卧轨时，是抱着多大的勇气，我想，他们定是明白了这个人生了。“写给每一个孤独的行路人”，或许我明白了这书来的意义。写给孤寂的人，看到这个世间的美好，便更加有了走下去的意义。或许人生的意义，从来都是不需要去追寻的，或许它最终只是对于个人，来过这个世间的积累。看尽世间百态，或许是人生。也或许人活着，就是为了寻求人生的意义。道家里讲究死后乘鹤西去，佛家里追寻生命轮回，而唯物里，死后就什么也没有了，“化作春泥更护花”或许是唯物的追寻。我有时在想，人生的意义，是否就是追求人在死亡来临那刻的高度，精神的卓越。我始终不解，但我知道，《自在 独行》里描写的世界就是这个世界，所写出的美好，便是一个普通人理解的美好。我一直在寻找，生命的意义是什么。或许该问，寻找生命的意义的意义又是什么？有人说，生命的意义在于寻找意义的过程。或许该是如此。这书，从没有讲过生命，只是讲着这个世间的美好，而我从来喜欢“随想”，不局限思维。或许我在向一个怪人的路上渐行渐近。也是有趣。]]></content>
      <categories>
        <category>read</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[解决word章节标题段前间距不显示问题]]></title>
    <url>%2F2018%2F03%2F07%2F%E8%A7%A3%E5%86%B3word%E7%AB%A0%E8%8A%82%E6%A0%87%E9%A2%98%E6%AE%B5%E5%89%8D%E9%97%B4%E8%B7%9D%E4%B8%8D%E6%98%BE%E7%A4%BA%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[如图片所示，在word中通过样式的调整，出现这种情况，显示得不正常情况。或许你会说改段落就可以，其实非然。在目前看来，这儿有明显的段前30磅的距离，而这儿没有显示出来。首先分析，word中，所有的东西都是有格式的，只有在相同样式之间段前段后格式不会显示。而这儿是段前格式没有显示出来，那么也就是，对于这种样式，前面的也是这种样式。然而一看，前面是正文格式。或许你会发现，上一页的最后是同样的章节标题格式，但是没有表现。这点便是问题所在。因为我们使用了分节符，而由于我们可能是在写完文本后序去调整的格式，因此可能分节符的格式就是我们的章节格式。当然，解决方法就是将分节符改为与分节符前格式相同，就可解决这个问题。总结问题章节标题段前距离没有显示。解决方案将该章节标题前的分节符样式改为分节符之前的样式。]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>Word</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IDEA无限Indexing]]></title>
    <url>%2F2018%2F03%2F01%2FIDEA%E6%97%A0%E9%99%90Indexing%2F</url>
    <content type="text"><![CDATA[虽然无限Indexing并非错误，但消耗性能，并扰乱我们的开发进度。我此处遇到的异常情况是，IDEA一加载某个Js就会一直出现无限Indexing，然后关掉，或者鼠标控制其他文件就不会出现这种情况。后来发现只是我电脑会有这种情况。因此猜测是因为我IDEA主题的问题。我通过网上下载了一个名为Python的主题，并通过导入设置修改了IDEA主题。然而通过查询资料没有找到卸载主题的办法，最终选择了暴力的解决方案，卸载重装IDEA。最终解决了该问题。总结问题由于IDEA主题导致某个文件加载出现无限Indexing情况。解决方案卸载IDEA重装。附推荐如何使用IDEA开发工具中右键中的Git图形化工具。]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>Idea</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[校招一些经验]]></title>
    <url>%2F2018%2F02%2F18%2F%E6%A0%A1%E6%8B%9B%E4%B8%80%E4%BA%9B%E7%BB%8F%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[秋招对我已经过去了几个月了，现在才想起来对于我的秋招经验做一个整体的总结。秋招准备首先是怎么去准备秋招，我恰逢受学长指导，才开始于五月起准备秋招。对于秋招来说，早的公司有的会在8月的时候就开始。因此需要针对自己，做好提前准备。从五月起，我看了《算法》一书，并针对自己对于其做了自己的总结，我总结了《对于基础排序算法的简要总结》、《基础查找算法分析》以及《SCC算法初解》，后续对于SCC部分基本没有涉及。从根本来说，对于我们计算机类的学生，数据结构与算法是非常重要的，对于五个模块是需要认真学习掌握的：查找、排序、树、图、动态规划，附加数据库等一些。在我之前的学习中，完全没有涉及动态规划方向的问题，因此只能重新学习了。对于计算机网络、操作系统等，需要对于基础知识做一遍的总结归纳。然后多次记忆。避免自己忘记。通过牛客网刷题，巩固自己的记忆，以及对于一些没有复习到的知识点作完善。争取对于所有的刷题，也至少达到70%的正确率。对于算法上的复习是，最消耗时间的。我虽然之前看了算法，但又通过《剑指Offer》对于基本的题思路全部熟练。然后又通过LeetCode一些算法题目的提升，后来就基本觉得那些笔试面试的基础算法等，都没那么困难了，像曾有一个面试官，问我觉得那笔试题怎么样，我随口就回了一句挺简单的，想来是没有回答好，但这个是我的坦诚吧。LeetCode上面的题目，总体而言，难度更高一些。花费的时间也较多一些，但是想通的题目多了后，可以提高自己的思维能力，解决问题的能力。总体而言，我对于秋招的准备就是对于基础的复习，对于知识点的查缺补漏。最后需要准备的一点是，对于面试时候，面试官最后一般会问你，“还有什么问题没有”。所以需要提前准备一些问题。我一般喜欢了解一下公司，岗位职责等，培养方式等。有的经历过宣讲会，就基本没啥问题了。招聘中在校招中，会经历一段一两个月的高密度的校招，秋招时间相对于春招来说比较长一些。招聘信息的来源，有学校官网、学院官网、其他学校的官网、牛客网等众多，需要自己整理，自己分辨信息的真实性。简历，这个需要准备好。尤其对于本科生来说，没有像研究生那样有许多的项目经历等可以写，因此需要精心设计简历。本科生一般简历都是一页，因为一页能够写下。所以需要将重要的信息放在一页纸的中心位置，那个位置是视觉的聚焦点。我在简历的时候，觉得我能够拿出手的就实习与项目经历，并且我认为那部分对于公司来说应该更加看重一些。因此将这两部分放在了重心位置。秋招里。简历投递，我也基本是海投。但是本身我也是有自己的筛选，并不是所有的公司我都投递了。根据自己的兴趣爱好，以及自己对于公司的看法投简历。当然，没拿到一个offer的时候，胡乱投递也是很正常的。在笔试的时候一般会对于自己的投递有一个筛选，笔试冲突的时候，就看自己觉得是选择自己更加爱好的或者更加有把握的，按照自己的标准去放弃。在投递开始时，最好建一个表格来记录目前投递的公司，以及笔试面试的进度，或者笔试面试时间等。不要过分相信自己的记忆能力，当简历投递得过多的时候，很容易是，弄乱的。日历是一个很好的记事器。通过手机日历设置提醒每天要做那些事，完成哪些笔试，去面试哪些公司，地址在哪儿等。通过日历的提醒，可以办到自己忘记不了。面试需要带好简历、笔、成绩单、身份证、学生证等。面试中，礼貌、礼貌、礼貌很重要，重要的事说三遍。还有一点，不知道的东西，要果断，说不知道，当然可以说自己的思路，想法，展示自己的思维能力。但是千万不要遮遮掩掩。我曾旁听了一个面试，那个同学面试时，对自己不知道的东西总是遮遮掩掩。最后，他请教面试官指点一下他面试中的问题。面试官很直接就说，“我建议你以后面试中，不知道的东西，最好直接说不知道，不要遮遮掩掩，这样才能够表现出，你所表现的知道的东西更加有信服力”。关于手里的offer筛选，这个没有建议了。只是若是要拒掉一个offer最好是，客客气气的发一封邮件，礼貌有加。本人秋招的一些看法其实在秋招中，面试应该是相对的，虽然表现出来的是公司在面试你，其实你也在面试公司，通过公司招聘中的进度、效率，以及面试过程中的严谨程度等。我在面试完后，基本都把我自己认为面试过程中比较“水”的公司筛选掉了。因此这个是一个双向的筛选过程。第二点是，不要惧怕和研究生竞争，我一直想表现的就是本科生并不比研究生差。对自己要有信心。虽然他们多了三年的经历，在项目以及基础上可能要好得多，但是我们年轻，相信自己的学习能力并不比他们差。当然，找工作中，安全还是很重要的，你若没有投递过的公司发信息让你去面试等，这种都是骗局。还有注意公司信息的真实性等，对自己的未来负责。面试地址，注意偏僻地区千万别去，不要认为传销离自己很远，有可能是一里之隔。找工作当然苦了，当然有失落等。学会调节自己的心理，我想公司不会想要一个没有自控能力的人吧。当自己面试多了，自然也就习惯了。我第一次面试的时候，也是非常紧张的，而且基础知识等都没有复习完全。紧张一次后，自然后来都不紧张了。还有一点是，并不是自己面试的东西就应该是自己所擅长的。重点是表现自己的思维以及基础。我偏向于Java语言，基本没有C++项目经验，我曾去面过了一个C++的岗位，语言并不重要，当然至少得懂这门语言的核心思维。面试官一般会从你的简历上写的来了解，什么写精通等，应届生就别想通过了。笔试面试完，应该从自己的缺陷中去查缺补漏。有时候，可能关于多进程多线程等，锁等有些知识点不清楚，下来就应该快速学习或者复习。附总之，工作，说好找，也是很好找的，说难找，也难找的。只要你准备好了，就应该能够找到一份不后悔的工作。]]></content>
      <categories>
        <category>other</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Mac下Java开发环境配置]]></title>
    <url>%2F2018%2F01%2F17%2FMac%E4%B8%8BJava%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[前言作为一名程序员，每次换了电脑，都需要重新配置一次所有的环境，有时候会突然忘了一些设置以及一些软件的破解等。Java第一点是配置Java环境，下载地址http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html，目前是Jdk8，下载安装即可。同时，需要设置JAVA_HOME，可以在 ～目录下建立一个.bash_profile的文件，使用vim .bash_profile新建并打开文件，在文件中写入12export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_144.jdk/Contents/Home export PATH=$PATH:$JAVA_HOME/bin然后esc后输入:wq保存并退出，之后执行source .bash_profile即可。在命令行输入 java -version测试是否成功。IDEA第二点就是IDE了，我开始使用idea后就完全抛弃了Eclipse，当然用不起正版，这是一个不能买断的软件，当然社区版是免费的。下载地址https://www.jetbrains.com/idea/。一般下载Ultimate版本，进行破解：1、使用http://idea.iteblog.com/key.php注册，但是在最新的版本里似乎开始行不通了。2、使用该方法注册http://blog.csdn.net/zx110503/article/details/78734428，windows与mac都可行。对于每个项目配置时，可以尝试使用lombok，使用@Slf4j使用日志，减少我们所写的重复代码。附上IDEA里面添加lombok插件,编写简略风格Java代码http://blog.csdn.net/hinstenyhisoka/article/details/50468271。12345&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.18&lt;/version&gt;&lt;/dependency&gt;每次开始项目开发时，最好将配置java导入包优化以及去掉无用包开启，可以让IDEA优化我们导入的包。gitgit很重要，能够支持多程序员合作的版本控制，以及远程办公等多功能。git教程里推荐廖雪峰的git教程。安装指南有许多种安装方法供选择。Chrome 以及postman作为一名程序员，怎么可以不用Chrome呢？下载安装都极其简单。postman用于发送各种请求测试接口。有Chrome插件版本和桌面版本。在扩展程序里可以搜索postman，当然国内在这之前需要翻墙，突破The Great Wall，下载启用就行，他会自动创建快捷的启动软件入口。推荐下载桌面版本。mysql并不一定是Mysql、还有其他数据库等，看目前的需求。在mysql下载安装后，容易出现密码忘记连接不上的情况，因此这儿需要处理。1、系统偏好设置 入口进入mysql关闭mysql2、进入终端输入：cd /usr/local/mysql/bin/登录管理员权限 sudo su输入以下命令来禁止mysql验证功能 ./mysqld_safe –skip-grant-tables &amp;运行后mysql会自动重启（偏好设置中mysql的状态会变成running）3、输入命令 ./mysql输入命令 FLUSH PRIVILEGES;输入命令 SET PASSWORD FOR ‘root‘@’localhost’ = PASSWORD(‘你的新密码’);这样后mysql会重新设置成你设置的密码。Mavenmaven并不是所有的都会用到，但是个人觉得用Maven会方便许多，但是在maven里会常常遇到包冲突问题，给人以想不到的惊喜。关于maven的基础知识，请参照《Maven基础总结》。对于Maven的安装配置参照https://www.jianshu.com/p/191685a33786对于某些公司有自己的Maven镜像库，因此会在.m2文件路径下建立一个setting.xml的文件配置自己公司的Maven镜像映射。当然有时候你需要自己手动将包加入自己的Maven仓库，使用mvn install:install-file -Dfile=../a.jar -DgroupId=a.groupId -DartifactId=a.artifactId -Dversion=a.version -Dpackaging=jar命令，其中a代表jar包名，当然groupId、artifactId和version等需要根据现场修改。tomcattomcat可以下载一个tomcat8，对于7，在某些环境情况下会出现错误、而换用8就ok。当然也可以将tomcat的命令设置成全局，我个人偏好不设置而已。附对于还有一些我个人喜欢的软件，如前端编译器Hbuilder、做手机端页面时需要的Charles等，当然对我来说，有道词典是必须的。本文仅总结一些个人Java基础开发的环境配置，带有个人偏好色彩。]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>macOS</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决Java API @since 版本错误问题]]></title>
    <url>%2F2018%2F01%2F08%2F%E8%A7%A3%E5%86%B3Java-API-since-%E7%89%88%E6%9C%AC%E9%94%99%E8%AF%AF%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[在我们的项目开发过程中，常常出现Java版本过低，以导致语法中出现错误的情况，这种情况中我们通常都是比较明了的知道需要提到Java的版本。安装的Java版本过低这种情况下需要我们重新安装最新版本的Java即可。IDE中设置的Java版本过低比如在IDEA中，通过command + ; 快捷键进入项目结构中可以看到如下图项目结构中的一些信息。（注：快捷键需要是英文键）在红色框位置可以选择支持的Java版本。当然，在Modules里面也可以选择支持的Java语言版本。IDEA自动重置LanguageLevel和JavaCompiler版本如下图发生错误相同，每次都会引入项目，或者开启项目时，都会使得Java版本过低的情况。并且package后也是支持低版本的Java，会引发较大的语法问题。这个问题虽然可以每次在开发过程中手动调节版本，使得开发过程没有错误。但是不支持所有环境，即打包做出支持库等会出现语法问题，因此需要解决。解决方法是，在Maven中引入maven-compiler-plugin，并指定版本。示例如下12345678910&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.3&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt;&lt;/plugin&gt;]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[17曲终，18伊始]]></title>
    <url>%2F2017%2F12%2F30%2F17%E6%9B%B2%E7%BB%88%EF%BC%8C18%E4%BC%8A%E5%A7%8B%2F</url>
    <content type="text"><![CDATA[回顾整个17年，我个人成长了不少，我似乎开始从一个入世未深的懵懂少年成为了开始入世的大叔。我思维开始有了自己革命性的改变，我可以开始笑对我自己所面对的所有遭遇，好的，坏的，我都可笑着接受。17年，我开始表现整个自我，我开始在简书矫情，写下感动自我的文字。17年初，我正当大三下学期里的初章，我决定了我准备毕业后就工作，我去了喜马拉雅实习。那时候，我邂逅简书，我开始在简书上写下我的所遇所感，以及自我的技术总结。简书，终究还是我选择自我陶醉或者自我表达的地方。从相遇到现在，我在简书写了三万四千多文字，写了有四十篇随笔或技术。我没有那种文学上的表达能力，只是专注的写下自己的想法。没有感动别人，但终究还是感动了自我。17年里，我开始找工作，我最终找到一份比较满意的工作，选择去一个优秀的环境里变得优秀起来，最终自我选择了北漂，开启了北漂一族的生活。我未曾出过远门，而现在却独自北上，从校园到社会，对我来说，“我有什么不能够承受，或者不管什么，都得承受着。”，这是我17年后的最好的总结。我来了北京，我开始发现，是因为一个人，所以恋上一座城。而我对于每一座城都不再去追求。倘若我能够在北京好着，而没有我留恋的地方所去，则留下来。对我来说哪儿都是一座城，都是在生活里摸滚打爬。17年，也是我从16年的迷茫里里走出来的一年，这一年里，我决定了我毕业后工作的道路，我开始认真学习，我基本保持着至少一个月一本技术书籍的进度学习，认真总结学习。我开始准备构建自己的个人网站，开始学会自己安排进度。回顾这17年，我留下的一切，我开始看开感情，随风般任其跟随我心去做，“尽人事而听天命”，虽未尽人事，但也听天由命。我追求哲学里不同的认识，我开始注重经历，感受经历里的每一个风景。18年是我毕业的一年，这一年我或者是真正走上社会。这一年里，我有许多想做。每个月一本技术书籍，是我想一直坚持下去的学习。既然在技术的道路上来了，那至少让自己会些技术。17年末，我开始利用上班途中的时间学习英语。18年里，继续学习吧，方便的话也可以尝试着去考一下雅思托福。既不追求固定未来待着的地方，那么或许以后我也会选择出国深造。也相当于没有一个明确的打算，只是想看看这个世界。18年毕业之前，我会争取着让我的个人网站上线。毕业的时候，我也会穿上那个毕业的学士服，或许我也会将学士帽高高抛起。18年，我会走下一些北京有趣的地方，留下自己的足迹，带走埋藏的记忆。17年终将远去，我做过一些事。18年，我又会做哪些？]]></content>
      <categories>
        <category>other</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[关于HLS直播流HTML页面播放解决]]></title>
    <url>%2F2017%2F11%2F09%2F%E5%85%B3%E4%BA%8EHLS%E7%9B%B4%E6%92%AD%E6%B5%81HTML%E9%A1%B5%E9%9D%A2%E6%92%AD%E6%94%BE%E8%A7%A3%E5%86%B3%2F</url>
    <content type="text"><![CDATA[在最近的项目开发中，涉及了HLS直播音频流的播放，关于网上的资料较多，各种混杂，因此对此在问题解决尝试以及结果进行总结。最终解决方案使用百度播放器，通过API，自己写想要的播放器组件。什么是HLS首先，什么是HLS？HTTP Live Streaming（缩写是HLS）是一个由苹果公司提出的基于HTTP的流媒体网络传输协议。是苹果公司QuickTime X和iPhone软件系统的一部分。它的工作原理是把整个流分成一个个小的基于HTTP的文件来下载，每次只下载一些。当媒体流正在播放时，客户端可以选择从许多不同的备用源中以不同的速率下载同样的资源，允许流媒体会话适应不同的数据速率。在开始一个流媒体会话时，客户端会下载一个包含元数据的extended M3U (m3u8)playlist文件，用于寻找可用的媒体流。HLS只请求基本的HTTP报文，与实时传输协议（RTP）不同，HLS可以穿过任何允许HTTP数据通过的防火墙或者代理服务器。它也很容易使用内容分发网络来传输媒体流。—— 摘自维基百科由于是HLS技术是苹果公司提出的，虽然在该协议的推广上也是作出了许多贡献，但是也是有很多浏览器依然不支持或者不完全支持该协议。如何实现页面的直播流播放呢？对于直播流方案，我做了几种解决尝试方案一：使用video标签首先，video标签是HTML 5中的新标签，用于嵌入视频元素。而目前，video标签只支持MP4、WebM、Ogg等格式。或许，很疑惑，为什么要用视频元素标签来嵌入音频？对于我们这儿直播流的情况下，一般音频标签目前不能够解决。而使用视频元素标签来嵌入直播音频流。既然这儿video标签不支持m3u8的HLS直播流格式，那是不是我这儿说错了？肯定不是。接下来需要借助一些其他开源项目来解决。我们在这儿的解决都是基于video.js的一些衍生开源项目解决。首先是第一种直接使用video.js测试。123456789101112131415161718192021222324&lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;utf-8&quot; /&gt; &lt;title&gt;Player&lt;/title&gt; &lt;link href=&quot;https://unpkg.com/video.js/dist/video-js.css&quot; rel=&quot;stylesheet&quot;&gt; &lt;/head&gt; &lt;body&gt; &lt;video id=&quot;video&quot; class=&quot;video-js vjs-default-skin&quot; controls preload=&quot;none&quot; data-setup=&apos;&#123;&#125;&apos;&gt; &lt;source src=&quot;living.url&quot; type=&quot;application/x-mpegURL&quot;&gt; &lt;/video&gt; &lt;script src=&quot;js/video.js&quot;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot;&gt; var player = videojs(&apos;video&apos;); player.ready(function() &#123; var myPlayer = this; myPlayer.src(url); myPlayer.load(url); myPlayer.play(); &#125;); &lt;/script&gt; &lt;/body&gt;&lt;/html&gt;使用Safari浏览器测试如下然后，也可以使用videojs-contrib-hls项目解决，测试代码示例如下：1234567891011121314151617&lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;utf-8&quot; /&gt; &lt;title&gt;Player&lt;/title&gt; &lt;link href=&quot;https://unpkg.com/video.js/dist/video-js.css&quot; rel=&quot;stylesheet&quot;&gt; &lt;/head&gt; &lt;body&gt; &lt;video id=&quot;video&quot; class=&quot;video-js vjs-default-skin&quot; controls autoplay=&quot;autoplay&quot; width=&quot;640&quot; height=&quot;320&quot; data-setup=&apos;&#123;&#125;&apos;&gt; &lt;source src=&quot;living.url&quot; type=&quot;application/x-mpegURL&quot; /&gt; &lt;/video&gt; &lt;script src=&quot;https://unpkg.com/video.js/dist/video.js&quot;&gt;&lt;/script&gt; &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/videojs-contrib-hls/5.12.1/videojs-contrib-hls.min.js&quot;&gt;&lt;/script&gt; &lt;/body&gt;&lt;/html&gt;️注意：在这儿使用的js等资源皆是在线的一些支持。若需要在项目中使用，最好下载到本地使用。这儿的测试结果，是对于mac上所有浏览器的一般m3u8视频流（即非直播）都支持，都能够播放。直播流仅持safari、edge、android，其他浏览器会出现错误。方案二：基于clappr由于第一种方案，只能够部分解决HLS流播放的问题，且未解决直播流播放的浏览器兼容问题。因此需要继续寻找新的解决方案。这个方案是基于github上clappr的开源项目解决。1234567891011121314151617181920&lt;html&gt; &lt;head&gt; &lt;title&gt;test&lt;/title&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;https://cdn.jsdelivr.net/npm/clappr@latest/dist/clappr.min.js&quot;&gt;&lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;div id=&quot;player-wrapper&quot;&gt;&lt;/div&gt; &lt;script&gt; var playerElement = document.getElementById(&quot;player-wrapper&quot;); var player = new Clappr.Player(&#123; source: &apos;m3u8.url&apos;, mute: true, height: 360, width: 640 &#125;); player.attachTo(playerElement); &lt;/script&gt; &lt;/body&gt;&lt;/html&gt;通过测试，发现该方案对于m3u8的视频格式支持播放，但是对于直播流却不支持。方案三：基于ChPlayer在查询资料中发现，chplayer是网页视频播放器，支持mp4,flv,f4v以及m3u8格式，支持rtmp。支持点播和直播。因此决定使用这个尝试。首先将项目下载到本地，然后使用页面测试。12345678910111213141516171819&lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;test&lt;/title&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;chplayer/chplayer.min.js&quot;&gt;&lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;dev id=&apos;video&apos;&gt;&lt;/dev&gt; &lt;script type=&quot;text/javascript&quot;&gt; var videoObject = &#123; container: &apos;#video&apos;, //“#”代表容器的ID，“.”或“”代表容器的class variable: &apos;player&apos;, //该属性必需设置，值等于下面的new chplayer()的对象 video: &apos;living.url&apos; //视频地址 &#125;; var player = new chplayer(videoObject); &lt;/script&gt; &lt;/body&gt;&lt;/html&gt;通过这种方式测试，结果是能够解决直播流问题，并且主流浏览器都是兼容的。因此在我们的项目中决定使用这种方式解决问题。方案四：使用hls.js目前官方给出兼容情况如下：方案五：使用cyberPlayer该方式目前基本兼容常用浏览器，我测试的使用基本兼容。在该方式下，通过自己编写播放器按钮等组件可以基本解决该播放问题。但是在这个情况下，需要考虑当播放器出错时，如何屏蔽掉页面中展示的错误信息。附虽然使用chplayer已经能够解决这个问题，但是在后面的查询资料中发现FFmpeg，可以解决支持直播音频的播放以及所有解码等，虽然不仅限于该领域。后面可以借助其源码学习并解决音频领域的问题。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>HLS</tag>
        <tag>Js</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac上VPN 连接不上常用解决方案]]></title>
    <url>%2F2017%2F07%2F21%2FMac%E4%B8%8AVPN-%E8%BF%9E%E6%8E%A5%E4%B8%8D%E4%B8%8A%E5%B8%B8%E7%94%A8%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[在工作中常常使用VPN，但是也常常出现VPN连接不上的情况，对于这种情况我们常常是深恶痛绝，花掉半天的时间也没解决，因此在这儿给出我自己的常用解决方案，一般按照着方案1、2、3的顺序执行，通常情况下都是解决的了。方案1尝试着删除掉我们所配置的VPN，然后重新配置，尝试连接。方案2这是大家常见的方案，在 /etc/ppp下的options文件中写入以下代码12plugin L2TP.pppl2tpnoipsec然后重新连接。具体的操作步骤如下：在终端中输入 sudo vim /etc/ppp/options，可能需要密码；在文件中输入i进入insert方式，然后输入上诉代码，然后按esc，输入:wq，回车保存；尝试着重新连接或删除掉旧配置重新连接；方案3如果上述方案都不能够奏效，那么尝试第三种方案。此方案只能在方案2不奏效的情况下使用删除/etc/ppp/options文件，即在终端执行sudo rm -rf /etc/ppp/options；删除VPN的配置重新配置，连接。这儿一定要删除配置重新配置（至于为什么，我也不清楚，反正不重新配置一般是不能成功的）一般情况下，按照这三种方案的顺序执行后都是能够成功访问了。附若本文中未总结的相关解决方案，欢迎补充。]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>VPN</tag>
        <tag>macOS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MyBatis初解]]></title>
    <url>%2F2017%2F06%2F09%2FMyBatis%E5%88%9D%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[MyBatis是一种半自动映射的框架。是目前较为流行的Java ORM框架。（ORM模型是指数据库的表与Java的POJO的映射关系模型，解决之间的相互映射。）本文主要是我在学习了《深入浅出MyBatis技术原理与实战》后的自我总结。配置123456789101112131415161718192021222324252627282930&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE configuration PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;&lt;configuration&gt; &lt;settings&gt; &lt;!-- 全局映射器启用缓存 --&gt; &lt;setting name=&quot;cacheEnabled&quot; value=&quot;true&quot;/&gt; &lt;!-- 全局延时加载 --&gt; &lt;setting name=&quot;lazyLoadingEnabled&quot; value=&quot;true&quot;/&gt; &lt;!-- 不对带有延时加载属性的对象完全加载 --&gt; &lt;setting name=&quot;aggressiveLazyLoading&quot; value=&quot;false&quot;/&gt; &lt;!-- 对单一SQL允许返回多结果集 --&gt; &lt;setting name=&quot;multipleResultSetsEnabled&quot; value=&quot;true&quot;/&gt; &lt;!-- 允许使用列标签代替列名 --&gt; &lt;setting name=&quot;useColumnLabel&quot; value=&quot;true&quot;/&gt; &lt;!-- 允许使用自定义的主键值(比如由程序生成的UUID 32位编码作为键值)，数据表的PK生成策略将被覆盖 --&gt; &lt;setting name=&quot;useGeneratedKeys&quot; value=&quot;true&quot;/&gt; &lt;!-- 自动映射任意复杂的结果集 --&gt; &lt;setting name=&quot;autoMappingBehavior&quot; value=&quot;FULL&quot;/&gt; &lt;!-- 简单执行器 --&gt; &lt;setting name=&quot;defaultExecutorType&quot; value=&quot;SIMPLE&quot;/&gt; &lt;!-- 数据库超过25000秒仍未响应则超时 --&gt; &lt;setting name=&quot;defaultStatementTimeout&quot; value=&quot;25000&quot;/&gt; &lt;!-- 配置使用log4j记录日志--&gt; &lt;setting name=&quot;logImpl&quot; value=&quot;log4j&quot;/&gt; &lt;!-- 自动转换驼峰命名 --&gt; &lt;setting name=&quot;mapUnderscoreToCamelCase&quot; value=&quot;true&quot;/&gt; &lt;/settings&gt;&lt;/configuration&gt;这是简单Mybatis的设置。依然还有许多属性我们没有提到。在我们的设置中，autoMappingBehavior是有三种设置：NONE（取消自动映射）、PARTIAL（只会映射没有定义嵌套结果集映射的结果集，在缺省配置的情况下默认）、FULL；而defaultExecutorType表示执行器executor类型，分为三种：SIMPLE（普通执行器，默认情况下是SIMPLE）、REUSE（执行器会重用预处理语句prepared statements）、BATCH（执行器会重用语句并执行批量更新）。在configuration中还会涉及其他属性，常用的有typeAliases（类型命名）、typeHandler（类型处理器）、plugins（插件）等。而对于typeHandler的配置里，又有javaType与jdbcType，typeHandler就是解决其转换的问题。MyBatis-Spring一般情况下，我们大多数情况下是在Spring中使用MyBatis，即需要配置MyBatis-Spring。分为五步进行配置：配置数据源配置SqlSessionFactory配置SqlSessionTemple（使用Mapper接口编程方式，这儿的配置就隐藏了）配置Mapper事务处理先配置数据源。123456789101112131415161718192021222324&lt;bean id=&quot;dataSource&quot; class=&quot;com.alibaba.druid.pool.DruidDataSource&quot; init-method=&quot;init&quot; destroy-method=&quot;close&quot;&gt; &lt;property name=&quot;url&quot; value=&quot;#&#123;jdbc[&apos;jdbc.url&apos;]&#125;&quot;/&gt; &lt;property name=&quot;username&quot; value=&quot;#&#123;jdbc[&apos;jdbc.username&apos;]&#125;&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;#&#123;jdbc[&apos;jdbc.password&apos;]&#125;&quot;/&gt; &lt;!-- 配置初始化大小、最小、最大 --&gt; &lt;property name=&quot;minIdle&quot; value=&quot;#&#123;jdbc[&apos;ds.minIdle&apos;]&#125;&quot;/&gt; &lt;property name=&quot;maxActive&quot; value=&quot;#&#123;jdbc[&apos;ds.maxActive&apos;]&#125;&quot;/&gt; &lt;property name=&quot;initialSize&quot; value=&quot;#&#123;jdbc[&apos;ds.initialSize&apos;]&#125;&quot;/&gt; &lt;!-- 配置获取连接等待超时的时间 --&gt; &lt;property name=&quot;maxWait&quot; value=&quot;#&#123;jdbc[&apos;ds.maxWait&apos;]&#125;&quot;/&gt; &lt;!-- 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒 --&gt; &lt;property name=&quot;timeBetweenEvictionRunsMillis&quot; value=&quot;#&#123;jdbc[&apos;ds.timeBetweenEvictionRunsMillis&apos;]&#125;&quot;/&gt; &lt;!-- 配置一个连接在池中最小生存的时间，单位是毫秒 --&gt; &lt;property name=&quot;minEvictableIdleTimeMillis&quot; value=&quot;#&#123;jdbc[&apos;ds.minEvictableIdleTimeMillis&apos;]&#125;&quot;/&gt; &lt;property name=&quot;validationQuery&quot; value=&quot;SELECT 1&quot;/&gt; &lt;property name=&quot;testWhileIdle&quot; value=&quot;true&quot;/&gt; &lt;property name=&quot;testOnBorrow&quot; value=&quot;false&quot;/&gt; &lt;property name=&quot;testOnReturn&quot; value=&quot;false&quot;/&gt; &lt;!-- 打开PSCache，并且指定每个连接上PSCache的大小 --&gt; &lt;property name=&quot;poolPreparedStatements&quot; value=&quot;false&quot;/&gt; &lt;property name=&quot;maxPoolPreparedStatementPerConnectionSize&quot; value=&quot;20&quot;/&gt; &lt;!-- 配置监控统计拦截的filters --&gt; &lt;property name=&quot;filters&quot; value=&quot;stat&quot;/&gt;&lt;/bean&gt;这儿我们使用的Druid数据源。接下来配置SqlSessionFactory。1234567891011121314151617&lt;bean id=&quot;sqlSessionFactory&quot; class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt; &lt;!-- 主配置文件 --&gt; &lt;property name=&quot;configLocation&quot; value=&quot;classpath:/mybatis-config.xml&quot;/&gt; &lt;!-- 自动扫描sqlmap目录下的所有SQL映射的xml文件 --&gt; &lt;property name=&quot;mapperLocations&quot; value=&quot;classpath:mappers/*.xml&quot;/&gt; &lt;!-- 自动注册javabean别名 默认会使用javabean的首字母小写的非限定类名来作为它的别名--&gt; &lt;property name=&quot;typeAliasesPackage&quot; value=&quot;fei.self.model&quot;/&gt; &lt;/bean&gt;&lt;!-- spring与mybatis整合配置，扫描所有dao --&gt; &lt;bean class=&quot;org.mybatis.spring.mapper.MapperScannerConfigurer&quot;&gt; &lt;!-- 扫描基本包路径下的所有映射器接口类 采用分号或者逗号分隔 可设置多个包路径 --&gt; &lt;property name=&quot;basePackage&quot; value=&quot;com.ximalaya.ops.fei.self.dao&quot;/&gt; &lt;!--多个数据源 可设置具体的sqlSessionFactoryBean 单个数据源不必配置--&gt; &lt;property name=&quot;sqlSessionFactoryBeanName&quot; value=&quot;sqlSessionFactory&quot;/&gt; &lt;/bean&gt;这儿的mybatis-config.xml就是我们之前的configuration以及setting的那个文件。并且在这儿，我们配置了自动扫描信息，包括扫描所有的DAO以及Mapper文件。接下来只剩下事务处理的配置了。1234567891011121314151617181920212223&lt;!-- 对dataSource 数据源进行事务管理 --&gt;&lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot; p:dataSource-ref=&quot;dataSource&quot;/&gt;&lt;!-- 事务管理 通知 --&gt;&lt;tx:advice id=&quot;txAdvice&quot; transaction-manager=&quot;transactionManager&quot;&gt; &lt;tx:attributes&gt; &lt;!-- 对insert,update,delete 开头的方法进行事务管理,只要有异常就回滚 --&gt; &lt;tx:method name=&quot;insert*&quot; propagation=&quot;REQUIRED&quot; rollback-for=&quot;java.lang.Throwable&quot;/&gt; &lt;tx:method name=&quot;update*&quot; propagation=&quot;REQUIRED&quot; rollback-for=&quot;java.lang.Throwable&quot;/&gt; &lt;tx:method name=&quot;delete*&quot; propagation=&quot;REQUIRED&quot; rollback-for=&quot;java.lang.Throwable&quot;/&gt; &lt;tx:method name=&quot;reset*&quot; propagation=&quot;REQUIRED&quot; rollback-for=&quot;java.lang.Throwable&quot;/&gt; &lt;tx:method name=&quot;getExecution*&quot; propagation=&quot;REQUIRED&quot; rollback-for=&quot;java.lang.Throwable&quot;/&gt; &lt;!-- select,count开头的方法,开启只读,提高数据库访问性能 --&gt; &lt;tx:method name=&quot;select*&quot; read-only=&quot;true&quot;/&gt; &lt;tx:method name=&quot;count*&quot; read-only=&quot;true&quot;/&gt; &lt;!-- 对其他方法 使用默认的事务管理 --&gt; &lt;tx:method name=&quot;*&quot;/&gt; &lt;/tx:attributes&gt;&lt;/tx:advice&gt;&lt;!-- 启用对事务注解的支持 --&gt;&lt;tx:annotation-driven transaction-manager=&quot;transactionManager&quot;/&gt;这是最基础的MyBatis-Spring的配置。这部分其实挺无趣的，个人觉得MyBatis最有趣的就是接下来的MyBatis的技术原理以及插件等。关于Mapper的一些在这儿不作罗列了。动态SQL所谓动态SQL，指的是一些特殊的MyBatis标签的使用，从而对于SQL的拼装具有动态性的效果。主要是if、choose、trim、foreach以及bind元素这些。这部分其实挺有趣的，可以增加我们对于MyBatis的掌握。这部分的知识在这儿不作罗列，看一些例子都能明白。MyBatis原理终于到了重点且有趣的地方，这部分知识可以帮助我们理解MyBatis，然后能写一些好用的插件。在学习之前需要掌握动态代理，分为JDK动态代理与CGLIB动态代理。首先，需要构建SqlSessionFactory。第一步，先通过XMLConfigBuilder解析配置文件，存入Configuration类中（这个类里基本保存了所有的配置）。第二步，使用Configuration去构建SqlSessionFactory。对于SqlSessionFactory，这是一个接口，在一般MyBatis中用DefaultSqlSessionFactory的实现类，对于接口的方法都做了实现。第二个需要掌握的是Mapper映射器。我们提到过，在Configuration中，有所有的配置，当然映射器也在里面。需要了解的是，Mapper映射是通过动态代理的方式实现的。一般映射器里面包含有三部分：MappedStatement：用户保存映射节点；SqlSource：这是MappedStatement的一个属性，一个接口，主要是根据参数和其他规则组装SQL，当然它提供BoundSql；BoundSql：建立SQL和参数的地方。我们一般修改SQL或者参数都是在BoundSql中修改的。对于BoundSql中如何实现多种参数的注入方式，我这儿就不讲解了。既然有了SqlSessionFactory，那么我们很容易就得到SqlSession了。从Mapper映射器中，我们通过代理对象会进入到MapperMethod的execute方法。然后就能进入SqlSession的方法里了。我们需要了解的是SqlSession里的增删改查方法是如何实现的。首先SqlSession下有四大对象。1、Executor执行器：用来调度StatementHandler、ParameterHandler、ResultHandler；2、StatementHandler：这个是在SqlSession里最重要的部分，它可以使数据库的Statement，即PreparedStatement执行操作（PreparedStatement接口是继承了Statement接口）；3、ParamentHandler：用于SQL的参数处理；4、ResultHandler：用于最后返回数据集的封装。我学到这儿很疑惑这个Satement究竟是什么？Statement 对象用于执行不带参数的简单 SQL 语句；PreparedStatement 对象用于执行带或不带 IN 参数的预编译 SQL 语句；CallableStatement 对象用于执行对数据库已存在的存储过程的调用。我们一般在插件中使用的是PrepareStatement，这三者对应了三种数据库会话器，SimpleStatementHandler、PrepareStatementHandler、CallableStatementHandler。对于着Executor也分为三种SIMPLE、REUSE、BATCH。关于参数处理器以及结果处理器就不提及了。插件插件部分，我无法总结清晰，所以给出我的分页插件中重点intercept函数实现的基本流程图。附本文主要是个人的一些总结，没有完全梳理MyBatis的流程等，也没有完全涉及MyBatis的所有知识。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>MyBatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SCC算法初解]]></title>
    <url>%2F2017%2F05%2F19%2FSCC%E7%AE%97%E6%B3%95%E5%88%9D%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[在算法学习之路上漂泊，遇见了图，而分无向与有向。在本文中主要讲解关于有向图中的求极大连通分量的算法，主要是Kasaraju算法、Tarjan算法以及Gabow算法。三种算法都是基于深度优先搜索算法（DFS）而实现的，实际上后两种算法是对于Kasaraju算法的改进，减少了一次深度优先搜索（DFS），因此在性能上相比较而言要好一些。初识强连通分量首先，连通分量是无向图G的一个极大连通子图称为G的一个连通分量（或连通分支）。连通图只有一个连通分量，即其自身；非连通的无向图有多个连通分量。强连通图指每一个顶点皆可以经由该图上的边抵达其他的每一个点的有向图。意即对于此图上每一个点对(Va,Vb)，皆存在路径Va→Vb以及Vb→Va。强连通分量则是指一张有向图G的极大强连通子图G’。如果将每一个强连通分量缩成一个点，则原图G将会变成一张有向无环图。一张图被称为有向无环图当且仅当此图不具有点集合数量大于一的强连通分量，因为有向环即是一个强连通分量，而且任何的强连通分量皆具有至少一个有向环。（摘自维基百科）对于无向图，求连通分量的问题就等价于求是否连通的问题，使用深度优先、广度优先搜索的算法的到的树都能求出最大连通分量。Kasaraju算法Kasaraju算法在我第一次接触时，感觉确实有点难理解，虽然现在也还是有点难理解。本文中不会去证明算法，只是讲解算法的一些实现等。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677public static class KosarajuSCC &#123; int n; List&lt;Integer&gt;[] adj; KosarajuSCC(int n) &#123; this.n = n; this.adj = new ArrayList[n]; for (int i = 0; i &lt; n; i++) &#123; this.adj[i] = new ArrayList&lt;&gt;(); &#125; &#125; public void addEdge(int v, int w) &#123; this.adj[v].add(w); &#125; //正向遍历，以后根序压栈，保证根先出栈 public void fillorder(int v, boolean[] visited, Stack&lt;Integer&gt; s) &#123; visited[v] = true; for (Integer i : this.adj[v]) &#123; if (!visited[i]) &#123; fillorder(i, visited, s); &#125; &#125; s.push(v); &#125; //reverse 得到反向图 public KosarajuSCC getTranspose() &#123; KosarajuSCC gv = new KosarajuSCC(this.n); for (int i = 0; i &lt; n; i++) &#123; for (Integer j : this.adj[i]) &#123; gv.adj[j].add(i); &#125; &#125; return gv; &#125; //DFS打印连通分支 public void DFSUtil(int v, boolean[] visited) &#123; visited[v] = true; System.out.print(v + &quot; &quot;); for (Integer i : adj[v]) &#123; if (!visited[i]) &#123; DFSUtil(i, visited); &#125; &#125; &#125; //按照Kosaraju算法的步骤执行 public void printSCCs() &#123; Stack&lt;Integer&gt; s = new Stack&lt;Integer&gt;(); boolean[] visited = new boolean[this.n]; for (int i = 0; i &lt; n; i++) &#123; visited[i] = false; &#125; //逆后序压栈 for (int i = 0; i &lt; n; i++) &#123; if (!visited[i]) &#123; fillorder(i, visited, s); &#125; &#125; //得到反向图 KosarajuSCC gr = this.getTranspose(); for (int i = 0; i &lt; n; i++) &#123; visited[i] = false; &#125; //依据反向图算可达性 while (!s.empty()) &#123; int v = s.pop(); if (visited[v] == false) &#123; gr.DFSUtil(v, visited); System.out.println(); &#125; &#125; &#125;&#125;先理解一下Karasaju算法的思路。对图G求其逆后序，即在深度优先遍历（DFS）中在递归调用之后压入栈中；对G进行转置，在代码中即得到反图；按照第一步中得到的栈的出栈的顶点顺序，对于GR图进行DFS可以得到若干搜索树。每棵搜索树都代表一个强连通分量。如上图示例的有向图，先求逆后序排序，得到{7, 8, 6, 9, 11, 10, 12, 0, 5, 4, 2, 3, 1}，然后按照这个图的转置图GR进行DFS，最终可以得到极大强连通分量5个：{7, 8}, {6}, {9, 11, 10, 12}, {0, 5, 4, 2, 3}, {1}。在Karasaju算法中使用了两次DFS，第一次是得到节点的逆后序排序（有的算法书将逆后序排序合并在拓扑排序里面）；第二次是对于转置图DFS得到最终的强连通分量。我们当然想要对于算法进行优化，减少DFS的次数也是一种极好的优化方式，想想如果一次DFS就可以得出强连通分量岂不是很好。Tarjan算法Tarjan算法是对于Kasaraju算法的改进。其基本代码实现思维如下：遍历一个点，指定唯一时间戳DFN[i]；指定改点向前追溯可追溯到最老时间戳LOW[i]；枚举当前点的所有边，若DFN[j]=0表明未被搜索过（这儿0、-1等都是可以的，只要是自我约定好的，正常不使用的就可以，如下面算法中使用的NO_VISIT），递归搜索；当DFN[i]不为0，则j被搜索过，这时判断是否在我们存储新建的栈中，且j的时间戳DFN[j]小于当前时间戳DFN[i]，可判定成环，将LOW[i]设定为DFN[j]；若这个点LOW[i]和DFN[i]相等，则这个点是目前强连通分量的元素中在栈中的最早的节点；出栈，将这个强连通分量全部弹出，保存。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public static class TarjanSCC &#123; private int numOfNode; private List&lt;ArrayList&lt;Integer&gt;&gt; graph;//二维数组表示图 private List&lt;ArrayList&lt;Integer&gt;&gt; result;//保存极大强连通图 private boolean[] inStack;//标记节点是否在栈内 private Stack&lt;Integer&gt; stack; private int[] dfn; private int[] low; private int time;//当前时间戳（实际是一个int的数，标记当前访问的节点） private static final int NO_VISIT = 0; public TarjanSCC(List&lt;ArrayList&lt;Integer&gt;&gt; graph, int numOfNode) &#123; this.graph = graph; this.numOfNode = numOfNode; this.inStack = new boolean[numOfNode]; this.stack = new Stack&lt;Integer&gt;(); dfn = new int[numOfNode]; low = new int[numOfNode]; Arrays.fill(dfn, NO_VISIT);//将dfn所有元素都置为0，代表i还有没被访问过。 Arrays.fill(low, NO_VISIT); result = new ArrayList&lt;ArrayList&lt;Integer&gt;&gt;(); &#125; //获取强连通分量 public List&lt;ArrayList&lt;Integer&gt;&gt; tarjanResult() &#123; for (int i = 0; i &lt; numOfNode; i++) &#123; if (dfn[i] == NO_VISIT) &#123; tarjan(i); &#125; &#125; return result; &#125; //算法核心 public void tarjan(int current) &#123; dfn[current] = low[current] = time++; inStack[current] = true; stack.push(current); for (int i = 0; i &lt; graph.get(current).size(); i++) &#123; int next = graph.get(current).get(i); if (dfn[next] == NO_VISIT) &#123; tarjan(next); low[current] = Math.min(low[current], low[next]); &#125; else if (inStack[next]) &#123; low[current] = Math.min(low[current], dfn[next]); &#125; &#125; if (low[current] == dfn[current]) &#123; ArrayList&lt;Integer&gt; temp = new ArrayList&lt;Integer&gt;(); int j = -1; while (current != j) &#123; j = stack.pop(); inStack[j] = false; temp.add(j); &#125; result.add(temp); &#125; &#125;&#125;需要注意的是在算法中的时间戳这个标记，并不是代表真正的时间戳，而是对于每个节点不同的一种标记，在本文算法中都是用一个递增数组来表示，即访问每个节点时，将该时间戳变量自增赋值给该节点的时间戳DFN[i]。Gabow算法Gabow算法在基础上与Tarjan算法相似，都是利用一次DFS算法实现。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public static class GabowSCC &#123; private int numOfNode; private List&lt;ArrayList&lt;Integer&gt;&gt; graph;//二维数组表示图 private List&lt;ArrayList&lt;Integer&gt;&gt; result;//保存极大强连通图 private Stack&lt;Integer&gt; path; private Stack&lt;Integer&gt; root; private int[] order; private int time;//当前时间戳（实际是一个int的数，标记当前访问的节点） private static final int NO_VISIT = -1; private int[] part; // 连通变量的标号； private int partNum = 0; public GabowSCC(List&lt;ArrayList&lt;Integer&gt;&gt; graph, int numOfNode) &#123; this.graph = graph; this.numOfNode = numOfNode; this.path = new Stack&lt;&gt;(); this.root = new Stack&lt;&gt;(); order = new int[numOfNode]; part = new int[numOfNode]; Arrays.fill(order, NO_VISIT); Arrays.fill(part, NO_VISIT); &#125; public int[] gabowResult() &#123; for (int i = 0; i &lt; numOfNode; i++) &#123; if (order[i] == NO_VISIT) &#123; gabow(i); &#125; &#125; return part; &#125; public void gabow(int v) &#123; order[v] = ++time; path.push(v); root.push(v); for (int i = 0; i &lt; graph.get(v).size(); i++) &#123; int next = graph.get(v).get(i); if (order[next] == NO_VISIT) &#123; gabow(next); &#125; else if (part[next] == NO_VISIT) &#123; while (order[root.peek()] &gt; order[next]) &#123; root.pop(); &#125; &#125; &#125; if (v == root.peek()) &#123; root.pop(); partNum++; int top; do &#123; top = path.peek(); part[top] = partNum; path.pop(); &#125; while (top != v); &#125; &#125;&#125;其算法基本思路是：在所有顶点中，找一个没有被访问的节点v，如果没有则完成；记录v的访问顺序；将v压入堆栈path和root；如果v指向的邻接点，对应每个邻接点next：1、如果没有访问过，则以next为参数，递归到第二步；2、如果访问过，且没有确定它属于哪个强连通分量，弹出root栈中next之后（即之上）的所有顶点；3、如果root栈中的元素等于v，那么在part中记录顶点对应的强连通分量递归返回附本文只涉及算法的实现，没有设计算法的证明等，如有想法，请分享。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基础查找算法分析]]></title>
    <url>%2F2017%2F05%2F13%2F%E5%9F%BA%E7%A1%80%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[在之前学习了一些排序算法，得出了基础排序算法的总结。之后学习了一些查找算法，今天来对于基础的一些查找算法进行总结。排序与查找是我们一般开发中最常用的算法。例如在开发中需要找出某个人的个人信息，就需要根据某个关键信息去查找。顺序查找顺序查找是按照我们思维最通俗易懂的算法，就是依次去对比，得到相等的则查找成功。当然这种算法是十分低效的，但是它对于我们需要查找的数据源，没有任何要求，就如数组中数据是可以乱序的。二分查找相似与之前排序算法的分治的思想，但是这种类似于分治的思想确实不同于分治。与分治得到有序结果相对应的是我们在查找的时候需要查找的数据源是有序的。12345678910111213141516public int halfFind(Key key) &#123; int lo = 0, hi = N - 1; while (lo &lt;= hi) &#123; int mid = (lo + hi) / 2; int cmp = key.compareTo(keys[mid]); if (cmp &lt; 0) &#123; hi = mid - 1; &#125; else if (cmp &gt; 0) &#123; lo = mid + 1; &#125; else &#123; return mid; &#125; &#125; return lo;&#125;上述代码是基于有序数组的二分查找算法简单实现，可以极大的减少比较次数，但是无法改变减少运行所需的时间，因为在查找源是无序的情况，将其排序成有序的情况也是需要一定运行时间的。二分查找的思想在很多查找算法里面都有体现，如插值查找、切波那锲查找、二叉查找数等都体现了这种思想。二叉查找树二叉查找树也是使用了二分的思想，只是在数据存储时使用二叉树的存储方式，也是链表的方式。12345678910public Value halfTreeFind(Key key) &#123; return get(root, key);&#125;private Value get(Node x, Key key) &#123; if (x == null) return null; int cmp = key.compareTo(x.key); if (cmp &lt; 0) return get(x.left, key); else if (cmp &gt; 0) return get(x.right, key); else return x.val;&#125;在二叉查找树中，插入难度和查找是差不多的，运行时间主要取决于树的形状。而删除一个结点，是将其右子树中最小的结点上浮来替代。当然从其运行时间与树的形状相关，因此我们需要想办法使得树的形状基本趋于平衡，而使得效率最高。即平衡查找树。平衡查找树由二叉查找树的缺点而推出平衡查找树，其中包括2-3查找树、红黑树等。在一棵完美的2-3查找树中、所有空链接到根结点的距离都是相同的。其有两种结点、具有1个数和2个数的结点、即有2个子分支和3个子分支。在查找与插入的时候都需要分别考虑，虽然情况是有限的几种，但是我还是觉得有点繁琐。而红黑树相比较像是对于2-3树的一种升级，用红的连接来替代3结点。但是我还是比较喜欢是结点标红的意思。对于红黑树的定义在之前的文章中体现过。红黑树在于查找、插入和删除上都是十分好的，所以在java1.8的HashMap中，满足某个特定条件时会将链表转化为红黑树。对于红黑树，所有基于红黑树的符号表实现都能保证操作的运行时间为对数级别，当然范围查找除外。散列表我第一次听说散列表的时候，对于散列的意思有点迷糊，搞不懂其与哈希表的关系。后来才明白散列表就是哈希表。哈希表中，首先需要的是一个哈希算法，最常见的就是%，除留余数法。第二点是解决冲突，一般就是拉链法与线性探测法。对于开发地址散列表中，最简单的方法就是线性探测法。至于对于散列表，我就不详解了，HashMap源码分析看完后都能基本明白。附在查找算法中，普遍都是基于二分的思想进行优化的。类似于排序算法中基于分治的思想一样。虽然本文总结不够完善，但也基本理清我的思维。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[洗牌算法]]></title>
    <url>%2F2017%2F05%2F04%2F%E6%B4%97%E7%89%8C%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[第一次接触洗牌算法是在一次面试上，面试官要求我写出一个算法将一个1～100的有序数组打乱，不考虑性能，那次我想了许久，想到一种基于二叉排序的方式实现了随机洗牌，但是那个性能呢，惨不忍睹。后来详细学习排序算法的时候，发现为了保证快速排序的性能，需要在排序之前对排序的数组进行洗牌操作。为什么不基于一般排序算法做洗牌？众所周知，一般排序算法在在性能上以快速排序最好吧，时间复杂度基本在N*logN，空间复杂度在logN，当然三切分快速排序更好一些。所有算法中空间复杂度最好时为1，这当然是最好的。详细见对于基础排序算法的简要总结。但是在排序算法中没有能够达到时间复杂度N的线性的。而在洗牌算法中，我们随便便能实现N的线性的时间复杂度，因此基于排序算法做洗牌不可取。洗牌算法第一版初次想的是一个排列好的数组，再新建一个长度相等的数组，每次通过随机数，随机一个N以内的数作为下标将其添加到新数组，并将该随机下标与N为下标的数交换，当然N需要自减。在N开始的时候为数组长度减1的值（保证下标最大而不越界）。那么最后会形成一个任意数组在数组内的某一位置的概率都是1/N的随机数组。12345678910public static Comparable[] Shuffle1(Comparable[] c) &#123; Comparable[] a = new Comparable[c.length]; int N = c.length - 1; for (int i = 0; i &lt; c.length; i++, N--) &#123; int ran = intRandom(0, N); a[i] = c[ran]; c[ran] = c[N]; &#125; return a; &#125;这种算法相比较之前打算基于一般排序算法求解的方式，在时间复杂度上有了很大的提升。在时间复杂度上，这种算法保证了N次循环（N为数组长度），N次获取随机值，N次交换（但是有2N次数组元素赋值操作）实现了分部均匀的洗牌算法。但是它的缺点是需要另建数组，使得空间复杂度增加。在算法中使用了随机数的intRandom函数如下1234567private static int intRandom(int min, int max) &#123; if (min &gt; max) throw new IllegalArgumentException(&quot;min can not bigger than max&quot;); if (max == min) return max; return new Random().nextInt(max - min + 1) + min; &#125;洗牌算法第二版为了减少空间复杂度，使得算法在原地进行洗牌操作，尝试着将算法改进。在本算法中使用随机生成一个下标，使得对应的数与第一个i个数交换（i会从0到N-1自增）。123456789public static void Shuffle2(Comparable[] c) &#123; int N = c.length; for (int i = 0; i &lt; N; i++) &#123; Comparable mid = c[0]; int ran = intRandom(0, N-1); c[0] = c[ran]; c[ran] = mid; &#125; &#125;当然在本算法中，空间复杂度是1，达到最小。而时间复杂度也没有很大升高，依然需要N次循环，N次随机，N次交换（但是有3N次赋值操作）。因为对于数组中的每个数都会进行同样的操作，不因为数组元素顺序等变化，因此对于任意一个数分布在某个位置的概率是相同的。所有这是目前我发现的最好的洗牌算法。附本文仅讲述一些自我对于洗牌算法的一些了解以及自我的一些思考以及实现，在目前我的了解中，这两种洗牌算法是最好的了，如有更好，请指出，共同学习。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven基础总结]]></title>
    <url>%2F2017%2F05%2F03%2FMaven%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[鉴于最近基本看完《Maven实战》这本书，对于我自己的所看的结果作一下总结，理清自己的思路，并复习书中的知识。当然有时间会继续学习一下Gradle，似乎是一个更好的工具。我原来对于Maven的印象就是依赖管理的工具，但是在认真学习之后，认识到Maven可以实现挺多实用功能。自动化构建依赖管理（提供中央仓库，能够帮我们自动下载构建）项目信息管理在Maven中最重要的思维莫过于约定优于配置。虽然在Maven中没有确定的文件定义一些要求，但是大家约定的一些写法等，保证了项目的移植性，当然也可以自定义，但是不推荐（因为你写了可能就自己看得懂了，别人都看不懂）。在Maven项目中默认的主代码目录为src/test/java，默认的测试代码目录为src/test/java。Pom文件在平时开发中，感觉到pom.xml文件是Maven项目中最重要的一环，它提供了项目信息与依赖管理等。首先，pom.xml文件中，包含一般XML文件头，指定xml文件版本以及编码方式等；接下来是project元素，包含相关的命名空间以及xsd元素等。12345678910111213141516171819202122232425&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;groupId&gt;com.fei&lt;/groupId&gt; &lt;artifactId&gt;fei.empty.spring.web&lt;/artifactId&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;properties&gt; &lt;jetty.port&gt;8417&lt;/jetty.port&gt; &lt;spring.version&gt;4.2.0.RELEASE&lt;/spring.version&gt; &lt;mybatis.version&gt;3.3.1&lt;/mybatis.version&gt; &lt;slf4j.version&gt;2.6.2&lt;/slf4j.version&gt; &lt;log4j2.version&gt;2.6.2&lt;/log4j2.version&gt; &lt;/properties&gt; &lt;dependencyManagement&gt; &lt;/dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; ...元素接下来重要的是groupId、artifactId、version元素，分别表示组（当前Maven项目隶属的实际项目）、唯一ID、版本。这个是Maven的坐标元素，基本可以确定一个项目，当然这三项是必须的，不管是在项目信息还是在依赖管理中，还有packaging、classifier分别表示打包方式和帮助定义构建输出的一些附属构建（ classifier是不能直接定义的，附属构建不是项目直接默认生成的，而是由附加的插件帮助生成）。例如在本例中因为是Javaweb项目，所以使用war的打包方式，在项目中如果不做声明，默认的是jar打包方式。这5个元素可以唯一的确定项目。版本关于版本，分为发布版本和快照版本，在本例中的1.0-SNAPSHOT就是快照版本，快照版本是不稳定的。在Maven中版本号的约定是&lt;主版本&gt;.&lt;次版本&gt;.&lt;增量版本&gt;-&lt;里程碑版本&gt;。关于版本管理的一些本文不会涉及。在配置的pom文件中提供了properties标签自定义。利用这个我们将所有的版本号集中在一起，方便更新、引用，以及减少一些版本号重复性。依赖除了在项目信息中使用到了这些元素标签，还在依赖管理中使用，这是很必要的，需要用它们去确定一个Maven项目。在 dependencies里会有许多dependency来确定每个依赖。例如spring项目中一般会包含spring-core、spring-context、spring-context-support等都是Spring Framework实现依赖注入等功能必要的构建，都需要在项目中依赖。在依赖的servlet中定义了scop标签，表示定义依赖的范围，那么provided是什么意思呢？在一般情况中，我们有6种依赖范围：1、compile：编译依赖范围，一般在缺省默认情况下也使用这个默认范围；2、test：测试依赖范围；3、provided：已提供依赖范围，表示对于编译和测试classpath有效，但是在运行的时候无效；4、runtime：运行时依赖范围，即测试和运行classpath有效；5、system：系统依赖范围，该依赖范围与三种classpath的关系与provided相同，但是在使用这个依赖范围时，必须通过systemPath元素显式地指定依赖文件的路径，在使用时会造成不可移植性；6、import：导入依赖范围，其实是继承父模版的依赖配置，继承依赖范围。依赖范围（scop）对于编译classpath有效对于测试classpath有效对于运行classpath有效示例compileYYYspring-coretest-Y-JUnitprovidedYY-servlet-apiruntime-YYJDBC驱动实现systemYY-类似于java的属性继承一样，Maven也具有传递性依赖，继承依赖范围关系如下，左一列为直接依赖，横一栏为间接依赖，内容表示最终依赖范围。compiletestprovidedruntimecompilecompile--runtimetesttest--testprovidedprovided-providedprovidedruntimeruntime--runtime这儿其实有一些规律：在间接依赖为compile时其他两者一致；当间接依赖为test时，不具有传递性；当间接依赖为provided时，只有provided才能传递，且最终依赖为provided；当间接依赖为runtime时，一般情况时直接依赖与最终依赖一致，除了直接依赖为compile时最终依赖为runtime。既然有传递性依赖，以及继承等机制（这些会在后续讲到），并没有像Java一样限制只能单继承，那么必会出现像C++一样通过不同路径继承同意文件而产生冲突的情况，那么如何解决？Mave这儿需要依赖调解。第一原则是路径最近者优先；第二原则是第一声明者优先。当然在依赖的时候，提供了optional标签来表示可选。可选依赖是不会传递的。也提供exclusions标签来排除继承时的某些依赖，可以解决在继承时快照版本依赖的不稳定性问题。仓库在上文中讲到依赖，那么依赖后引入的包相对于其对应仓库中的路径应该是多少呢？在路径与坐标的大致对应关系为groupId/artifactId/version/artifactId-version.packaging。对于Maven来说，仓库只分为两种：本地仓库和远程仓库。一般情况是当我们使用依赖去引入一种构建，当Maven根据坐标寻找构建时，先会去本地查找此构建，如果本地没有这个构建，去远程仓库查找，发现则下载到本地使用（当然本地构建需要查看更新时也是需要去远程仓库查找）。本地仓库一般在用户中本机中，默认情况下都有一个.m2/repository/的仓库目录。远程仓库远程仓库分为中央仓库以及自己建立的私服等。一般情况下，基本每个公司都是有自己的Maven仓库的，在开发之前的环境配置时会加上一个自己公司的setting.xml文件的配置。生命周期Maven拥有三套独立的生命周期，分别为clean、default、site。clean生命周期目标是清理项目；default是构建项目；而site生命周期目的是建立项目站点。clean生命周期包括pre-clean、clean、post-clean。一般调用clean时会依次执行pre-clean、clean。一般命令都是执行到指定的阶段截止。default是所有生命周期中最核心的部分。包括了许多阶段：calidate、initialize、generate-sources、process-sources、generate-resources、process-resources、compile、process-classes、generate-test-sources、process-test-sources、generate-test-resources、process-test-resources、test-compile、process-test-clasess、test、prepare-package、package、pre-integration-test、integration-test、post-integration-test、verify、install、deploy。在这个生命周期中可以看到有许多编译、测试等阶段。而site生命周期有pre-site、site、post-site、site-deploy四个阶段。插件个人觉得Maven中插件是非常重要的一环，可以帮助我们完成一些任务，并且与生命周期中的某个阶段绑定。1234567891011121314151617181920212223...&lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.3&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;configuration&gt; &lt;port&gt;$&#123;web.port&#125;&lt;/port&gt; &lt;path&gt;/$&#123;project.artifactId&#125;&lt;/path&gt; &lt;uriEncoding&gt;UTF-8&lt;/uriEncoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; ...在这段代码中使用plugin标签加入了maven-compiler-plugin以及tomcat插件，可以使得项目可编译以及不用本地的tomcat服务器。compiler的插件是内置绑定的compile阶段，不用显式申明。当然也可以自定义绑定，在配置中加入executions、execution标签配置 执行一个任务，并用phase绑定生命周期。测试讲到插件，就不能跳过Maven的测试。测试也是使用插件来实现的，如maven-surefire-plugin插件。可以帮助我们单元测试、集成测试等。聚合与继承聚合特性能把项目的各个模块聚合在一起构建，而继承特性能帮助抽取各模块相同的依赖和插件等配置。所有模块组成的一个构建结构就是反应堆。单模块项目就是这个模块本身；而多模块项目则包含了各模块之间的继承和依赖关系、计算合理构建顺序。附本文中对于许多详细知识没有作总结，只是对于常用的一些部分作了浅入的涉及。如测试、聚合与继承、以及Nexus建私服、profile、站点等知识没有解释，需要学习的可以仔细看一下《Maven实战》。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对于基础排序算法的简要总结]]></title>
    <url>%2F2017%2F04%2F24%2F%E5%AF%B9%E4%BA%8E%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E7%9A%84%E7%AE%80%E8%A6%81%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[本文主要分析排序算法中的选择排序、插入排序、希尔排序、归并排序、快速排序和堆排序，以及其部分优化方式，部分代码示例。当然快速排序算法是最快的通用排序算法，这使得其在java中的地位非凡，通常的ArrayList.sort()函数就是使用的快速排序。在这之前，我们先声明两个方法：分别为比较大小与数据交换的方法。123456789final static boolean less(Comparable i, Comparable j) &#123; return i.compareTo(j) &lt; 0;&#125;final static void exch(Comparable[] a, int i, int j) &#123; Comparable t = a[i]; a[i] = a[j]; a[j] = t;&#125;在排序中我们使用Comparable[]的数组进行排序，以便兼容其他类型的数组。选择排序快速排序是的思维是依次找到最小或最大的值，将这个值与我们所比较的值中的第一个或进行交换。这种算法的特点是：1、运行时间与输入无关，就算是输入有序运行时间也是差不多的；2、数据的移动是所有算法中最少的。1234567891011public static void selectionSort(Comparable[] a) &#123; int N = a.length; for (int i = 0; i &lt; N; i++) &#123; int min = i; for (int j = i+1; j &lt; N; j++) &#123; if (less(a[j], a[min])) min = j; exch(a, i, min); &#125; &#125; &#125;插入排序插入排序的基本思路是在循环中将下标i之前的元素进行比较交换（这儿是不符合比较小或比较大的条件则交换）。这种算法对于有序或者比较有序的数组时效率较高。123456789101112131415public static void insertSort(Comparable[] a) &#123; int n = a.length; for (int i = 1; i &lt; n; i++) &#123; Comparable mi = a[i]; boolean f = false; int j = i; for (; j &gt; 0 &amp;&amp; less(mi, a[j - 1]); j--) &#123; a[j] = a[j - 1]; f = true; &#125; if (f) &#123; a[j] = mi; &#125; &#125; &#125;在上述插入排序代码示例中，并没有每次比较交换相邻的两个元素，而是将较大的元素都向右移，也是每次循环中将比循环比较的最后一个元素的值大的元素都作右移操作，从而减少访问数组的次数。对于减少访问数组的次数，这点需要详细说明一下：对于普通的插入排序，是每次获取相邻两个元素的值进行比较交换，即每次循环都会获取2*i次数据，总的访问数组（即获取数组元素）的次数就是n*(n-1)次（n为数组的长度）；而对于优化后的插入排序，每次循环访问数组i+1次，总的访问数组(n-1)*(n+2)/2次，大约减少了一半的访问数组的次数。而对于插入排序与选择排序的比较，主要是在数组有序或部分有序时，减少了交换的次数，从而对于部分有序或有序的数组较高。希尔排序希尔排序的思想是使数组中的任意间隔为h的元素都是有序的。相对于插入排序改变了原来的插入的顺序。从原来的相邻的两个元素交换改成现在相邻两个增量交换的排序（增量即间隔）。通过增量递减的方式重复排序，直到增量为1，使得原数组有序。（增量序列为一组递减的且最后一个元素为1的数组。）12345678910public static void shellSort(Comparable[] a) &#123; int N = a.length; for (int h = N / 2; h &gt;= 1; h = h / 2) &#123; for (int i = h; i &lt; N; i++) &#123; for (int j = i; j &gt;= h &amp;&amp; less(a[j], a[j - h]); j -= h) &#123; exch(a, j, j - h); &#125; &#125; &#125; &#125;在示例中我是将增量/2得到之后的增量；当然这种增量序列不是最优的。在张连堂与张博的《希尔排序最佳增量序列研究》中做了一些分析并得到一种最优的增量序列：… 2^k -1, … 15, 7, 3, 1。希尔排序对于之前的排序算法是对于平方级的突破，权衡了子数组的规模与有序性使得其更加高效。归并排序归并排序分为原地归并、自顶向下、自底向上三种归并方式。但是最主要的思维也是归并，归并是将前后两端进行比较，将小的放上去，需要注意越界。而自顶向下是采用分治的思想，使用递归的方式进行归并。自底向上是采用相邻两个归并，在到相邻两组归并，刚好与自顶向下相反。123456789101112131415161718192021222324252627282930313233343536373839404142public static class Merge &#123; private static Comparable[] aux; /*归并*/ public static void merge(Comparable[] a, int lo, int mid, int hi) &#123; int i = lo, j = mid + 1; for (int k = lo; k &lt;= hi; k++) &#123; aux[k] = a[k]; &#125; for (int k = lo; k &lt;= hi; k++) &#123; if (i &gt; mid) a[k] = aux[j++]; else if (j &gt; hi) a[k] = aux[i++]; else if (less(aux[j], aux[i])) a[k] = aux[j++]; else a[k] = aux[i++]; &#125; &#125; /*自顶向下*/ public static void mergeTopSort(Comparable[] a) &#123; aux = new Comparable[a.length]; sort(a, 0, a.length-1); &#125; private static void sort(Comparable[] a, int lo, int hi) &#123; if (hi &lt;= lo) return; int mid = lo + (hi - lo)/2; sort(a, lo, mid); sort(a, mid+1, hi); merge(a, lo, mid, hi); &#125; /*自底向上*/ public static void sort(Comparable[] a) &#123; int N = a.length; aux = new Comparable[N]; for (int sz = 1; sz &lt; N; sz = sz+sz) &#123; for (int lo = 0; lo &lt; N -sz; lo += sz+sz) &#123; merge(a, lo, lo+sz+1, Math.min(lo+sz+sz-1, N-1)); &#125; &#125; &#125; &#125;快速排序快速排序是最常用的排序算法，采用分治的思想。将一个数组分为两个数组再排序。切分（partition）是使用交换等方法将某个值放确切的位置，再将其左右排序切分。这个确切的值满足其左边都小于它，右边都大于它，使得在其确定后，在整个排序过程中都不会对其产生影响，其位置不会再作变化。12345678910111213141516final static int partition(Comparable[] a, int lo, int hi) &#123; int i = lo, j = hi + 1; Comparable v = a[lo]; while (true) &#123; while (less(a[++i], v)) &#123; if (i == hi) break; &#125; while (less(v, a[--j])) &#123; if (j == lo) break; &#125; if (i &gt;= j) break; exch(a, i, j); &#125; exch(a, lo, j); return j; &#125;而排序算法就是使用递归的方式去调用切分的方法。123456public static void quickSort(Comparable[] a, int lo, int hi) &#123; if (hi &lt;= lo) return; int j = partition(a, lo, hi); quickSort(a, lo, j - 1); quickSort(a, j + 1, hi); &#125;上述为标准快速排序，其在很多地方依然具有缺陷，如在切分不平衡时可能使得排序十分低效，如将{6, 5, 4, 3, 2, 1}转换成由小到大排序时就十分低效。当然对于快速排序，先辈们依然做了许多优化的方法：1、快速排序对于小数组的排序特别慢，因此使用在数组小时以及分治到较小是采用插入排序优化；2、使用三取样切分，来解决具有大量重复数据情况。三取样切分的快速排序算法示例如下：1234567891011121314151617public static void quick3waySort(Comparable[] a, int lo, int hi) &#123; if (hi &lt;= lo) return; int lt = lo, i = lo + 1, gt = hi; Comparable v = a[lo]; while (i &lt;= gt) &#123; int cmp = a[i].compareTo(v); if (cmp &lt; 0) &#123; exch(a, lt++, i++); &#125; else if (cmp &gt; 0) &#123; exch(a, i, gt--); &#125; else &#123; i++; &#125; &#125; quick3waySort(a, lo, lt - 1); quick3waySort(a, gt + 1, hi); &#125;优先队列以及堆排序顾名思义，是具有优先级的队列，即对于这个队列中的数据是有序的。实现方式有很多，基于数组、链表、堆都可以实现。这儿主要介绍一下基于二叉堆的优先队列的实现，下述代码中已经十分清晰。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public static class MaxPQ&lt;Key extends Comparable&lt;Key&gt;&gt; &#123; private Key[] pq; private int N = 0; public MaxPQ(int maxN) &#123; pq = (Key[]) new Comparable[maxN + 1]; &#125; public boolean isEmpty() &#123; return N == 0; &#125; public int size() &#123; return N; &#125; private boolean less(int i, int j) &#123; return pq[i].compareTo(pq[j]) &lt; 0; &#125; private void exch(int i, int j) &#123; Key t = pq[i]; pq[i] = pq[j]; pq[j] = t; &#125; private void swim(int k) &#123; while (k &gt; 1 &amp;&amp; less(k / 2, k)) &#123; exch(k / 2, k); k /= 2; &#125; &#125; private void sink(int k) &#123; while (2 * k &lt;= N) &#123; int j = 2 * k; if (j &lt; N &amp;&amp; less(j, j + 1)) &#123; j++; &#125; if (!less(k, j)) &#123; break; &#125; exch(k, j); k = j; &#125; &#125; public void insert(Key v) &#123; pq[++N] = v; swim(N); &#125; public Key delMax() &#123; Key max = pq[1]; exch(1, N--); pq[N + 1] = null; sink(1); return max; &#125; &#125;需要注意的是上浮swim()和下沉sink()函数，是分别在插入与删除的时候被调用使得二叉堆平衡。而堆排序算法如下：12345678910public static void heapSort(Comparable[] a) &#123; int n = a.length; for (int k = n/2; k &gt;= 1; k--) &#123; sink(a, k, n); &#125; while (n &gt; 1) &#123; exch(a, 1, n--); sink(a, 1, n); &#125; &#125;这儿的sink(i,j,N)也是下沉函数，是将从j为顶开始下沉操作，使得平衡，具体实现类似于之前的优先队列的sink函数。这儿的思想是得到最大数与最后一个数交换再对前面的数组进行下沉操作，以此类推。总结对于排序算法，我们需要分析其稳定性。在排序算法中保留重复元素的相对位置，则该算法是稳定的。对于目前的排序算法中，插入与归并排序是稳定的；而选择、希尔、快速、堆排序不是稳定的。算法是否稳定是否原地排序时间复杂度空间复杂度备注选择排序否是N^21插入排序是是介于N和N^2之间1取决于输入元素的排列情况希尔排序否是1快速排序否是N*logNlgN运行效率由概率提供保证三切分快速排序否是介于N和N*logN之间lgN运行效率由概率提供保证，同时取决于输入元素的分布情况归并排序是否N*logNN堆排序否是N*logN1附本文并没有涉及所有的排序算法，还有如冒泡排序、基数排序等，需要的可以找找资料学习。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap 源码分析]]></title>
    <url>%2F2017%2F04%2F03%2FHashMap-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[HashMap是非常常用的键值对类型。本文主要讲述了HashMap的思维以及其重要或者常用的put，get，remove以及resize函数。首先Java定义了java.util.Map的接口，而常用的实现类型主要有HashMap、ConcurrentHashMap、LinkedHashMap和TreeMap。对于原来常用HashTable在不强调线程安全性时可以用HashMap替代（也就是说HashMap是线程不安全的），而在线程安全的情况下用ConcurrentHashMap替代。总体结构首先HashMap在Java1.8之后修改了其部分实现方式，将原来“数组+链表”的实现方式改为现在的“数组+链表+红黑树”的实现方式，采用红黑树的实现方式，增强了对于数据查找、删除、修改等性能，对于增加来说，应该是减慢了，但是个人觉得对于增加影响非常小。红黑树，RBTree，平衡二叉查找树的一种，具有良好的查找性能。他有五点要求：1、任何一个节点都有颜色，黑色或者红色；2、根结点是黑色的；3、父子节点之间不能出现两个连续的红节点；4、任何一个节点向下遍历到其子孙的叶子节点，所经过的黑节点个数必须相等；5、空节点被认为是黑色的。其实现方式比较复杂，若有时间我看完其源码再做分析。冲突的含义：是指当两个不同的键值对（key不相同）在put的时候hash(key)所得的值是相同的，他们会放到哈希桶数组的同一下标位置，形成链表或者红黑树，这种情况就是冲突。当然，在HashMap中我们要尽量的选取比较好的哈希函数来避免冲突，但是大多数情况冲突是不能完全避免的，所以要引入链表和红黑树来解决冲突。节点首先，HashMap类中包含了多个内部类，如Node、KeySet、Values、EntrySet等，在此就不一一列举。Node是HashMap中非常重要的类型，它代表每个节点，包含（hash，key，value，next）等属性，源码如下：123456789101112131415161718192021222324252627282930313233343536373839static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + &quot;=&quot; + value; &#125; public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125;&#125;先来说说Node每个属性的含义，1、hash：代表存储是的哈希值，一般由hash(key)函数得出；2、key；3、value：这两个就是键和值；4、next：是指指向下一个节点的指针。HashMap重要字段1、transient Node[] table; table表示哈希桶数组，transient表示其不参与序列化，即修饰的变量不是该对象持久化的部分。这个修饰符需要注意两点：1、只能修饰变量，本地变量不能被修饰（本地变量：局部变量）；2、静态变量（static修饰）不管有没有被修饰都不能序列化。2、transient int size; size是指当前存储的键值对数目。3、int threshold; threshold表示最大容纳的键值对个数，一般为threshold=length*loadFactor；length是指哈希桶数组长度，在当前键值对数目超过这个值时，哈希桶数组会扩容。4、final float loadFactor; loadFactor，负载因子（默认或缺省为0.75）。构造函数HashMap有4个构造函数，其一示例如下：123456789101112public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(&quot;Illegal initial capacity: &quot; + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(&quot;Illegal load factor: &quot; + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity);&#125;其他几个构造函数是将loadFactor缺省或者将参数全部缺省，以及其拷贝构造函数。注意的是对于上述构造函数中将参数loadFactor赋值给负载因子，并将参数initialCapacity通过tableSizeFor函数操作后传给threshold，由上面所述，threshold是最大容纳的键值对个数，而initialCapacity理论上应该是初始化容量，即哈希桶数组初始化长度，而且这儿并没有初始化哈希桶数组长度，因此这儿赋值是跟其思维上不符合的，那么我们的threshold最终究竟是多少，以及在哪儿初始化了哈希桶数组长度呢？这一点，我会在后面分析put方法时讲到。很好奇tableSizeFor函数是做了什么操作？他是在函数里面进行了一系列的移位操作，保证初始化容量为2的n次方。例如，我们new一个HashMap(11)传入的参数为11，按照之前的观点，初始化哈希桶长度应该是11，但是其进行一系列移位操作后，使得初始化容量为16。关于tableSizeFor源码如下：123456789static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125;get操作这儿的思路是非常简单的，就是通过hash(key)&amp;(table.length-1)得到对应的哈希桶数组位置，再去对应的位置查找，当然现在对应的位置可能是链表类型，也可能是RBTree类型，对于Java1.7时，是只有链表类型，因此遍历链表类型可以查找出对于的字段；而对于Java1.8添加了红黑树结构之后，就需要判断当前对应的table[j]的node是不是TreeNode，如果是则通过红黑树去查找，不是则通过链表查找。1234567891011121314151617181920212223public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125;final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125;put操作这部分相对于get操作就复杂了许多，需要注意的一点是put操作会有返回值，当该key有对应的值时，put操作会返回原来的值（至于覆盖与否，我接下来分析putVal函数参数时会讲到），当对应key不存在时则返回null。接下来，我们分为几种情况讨论put操作：1、table为空或者table.length为0的时候。这种情况会出现在两个时候，分别是刚刚new了一个HashMap和前面操作将table删掉的情况（删除操作在后面的章节会做另外的讨论）。我们前面构造函数部分提到过，在构造的时候只是初始化了负载因子loadFactor，和将初始化哈希桶长度赋值给了最大容纳的键值对个数threshold。并没有对于哈希桶数组table做初始化，因此在这儿table是空NULL，就触发了扩容，在扩容的时候就会将threshold赋值给table的长度length，而真正的threshold在这儿赋值成length*loadFactor。这里解决了我们之前对于table在哪儿赋值以及threshold最终值的疑问。2、一般情况。就是将key转换成对应的哈希值从而找到对应的数组下标位置，再判断该位置是否存储有数据，该数据的key是否就是我们需要put的数据的key，存储的是链表还是红黑树，将数据插入就好，当然这儿就有一个情况——当插入之后，该链表的长度（即节点数）刚好超过8，那么根据我们一般的猜想就是转换为红黑树RBTree，其实不然。这儿分为两种情况，第一种（也是最特殊的一种），当链表长度超过8的时候，但是总的哈希表容量size并没有达到MIN_TREEIFY_CAPACITY=64，这时候会出发扩容的情况（扩容一般上会降低同一点的冲突，具体情况我会在扩容一章resize的时候讲到；第二种情况就是size达到或超过64，大家众所周知的转为红黑树。既然有链表转化为红黑树的操作，那么想必有红黑树转化为链表的操作，这个函数就是untreeify，他会在红黑树的节点数减少到6的时候（即小于等于6）将红黑树转化为链表。123456789101112131415161718192021222324252627282930313233343536373839404142434445public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125;final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125;注意putVal函数中后面有两个参数onlyIfAbsent和evict。onlyIfAbsent为ture的时候表示仅当该key缺省（即不存在）时才将该键值对加入HashMap。evict表示是否覆盖旧值，一般情况下evict是ture，表示你在后面put一个跟原来key一样的值时会覆盖掉原来的值，而如果是false时，则保留原来的值，也就是不覆盖，相当于put相同key的值没效果吧。1234567891011121314151617181920final void treeifyBin(Node&lt;K,V&gt;[] tab, int hash) &#123; int n, index; Node&lt;K,V&gt; e; if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY) resize(); else if ((e = tab[index = (n - 1) &amp; hash]) != null) &#123; TreeNode&lt;K,V&gt; hd = null, tl = null; do &#123; TreeNode&lt;K,V&gt; p = replacementTreeNode(e, null); if (tl == null) hd = p; else &#123; p.prev = tl; tl.next = p; &#125; tl = p; &#125; while ((e = e.next) != null); if ((tab[index] = hd) != null) hd.treeify(tab); &#125;&#125;这儿有个instanceof函数表示判断前者是否是后者的一个实例。例如，Result = object instanceof class; 判断object是不是class的一个实例，如果是则返回ture。TreeNode，树节点，他是继承自Node节点的，也就是说TreeNode形成的实例既有Node的key，value等属性，重要的是他有next属性指向下一个节点，而有有TreeNode的parent，left，rigth等属性，这儿在TreeNode里面增加了pre属性来指向前一个节点，只能够在红黑树中使用。在查找HashMap中是否包含某个value的时候将所有都当作链表节点来使用，将父类与本身的属性发挥的非常不错，比如在ContainsValue函数中就没有区分是否是红黑树去查找而是直接使用其父类的next函数查找下一个依次遍历。3、putMapEntries这个函数就是将，一个Map的所有值加入当前Map，当然需要指定evict参数。12345678910111213141516171819final void putMapEntries(Map&lt;? extends K, ? extends V&gt; m, boolean evict) &#123; int s = m.size(); if (s &gt; 0) &#123; if (table == null) &#123; // pre-size float ft = ((float)s / loadFactor) + 1.0F; int t = ((ft &lt; (float)MAXIMUM_CAPACITY) ? (int)ft : MAXIMUM_CAPACITY); if (t &gt; threshold) threshold = tableSizeFor(t); &#125; else if (s &gt; threshold) resize(); for (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) &#123; K key = e.getKey(); V value = e.getValue(); putVal(hash(key), key, value, false, evict); &#125; &#125;&#125;类似的有putAll函数，他就是引用了一下putMapEntries函数，区别就是默认了evict为true而已。123public void putAll(Map&lt;? extends K, ? extends V&gt; m) &#123; putMapEntries(m, true);&#125;resize函数这部分非常重要，时HashMap重要思维的体现之处之一。首先扩容会在两种情况发生，第一种，在链表转化为红黑树的时候阐述过链表长度大于8且哈希桶数组的长度size&lt;64时会出发扩容；第二种，size&gt;threshold的时候会触发扩容（threshold=length*loadFactor）。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;&quot;rawtypes&quot;,&quot;unchecked&quot;&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125;从代码中可以看出resize函数是返回一个新的哈希桶数组，那么为什么要返回一个新的哈希桶数组呢？这点要从数组讲起，众所周知数组的长度是固定的，不能变长，那么我们怎么在HashMap中产生一个是原来长度两倍的数组呢？这儿就只能够创建一个新的数组来代替老的数组，需要将原来数组里面的变量一一填充到新的数组里面来。在Java1.7以及之前是一次将原来HashMap中的所有节点通过hash算法依次定位到新的Map中来。在Java1.8中对于老的数组同意位置的链表或红黑树中的节点填充到新的Map中做了很大的优化，使得扩容的速度快了许多。当然虽然优化了很多，但是这也是非常消耗时间成本的，因此我们在创建HashMap的时候就需要提前估计其能达到的最大容量，尽量一次性分配足够的空间，减少扩容情况。在Java1.8中对于HashMap扩容时数据转移做了很大的优化，这儿需要讲到hash获取数组下标的方法(n-1)&amp;hash(key)。对于hash(key)方法我不做过多阐述，想要学习的看看源码再自己测试一下就明白了。而对于按位与&amp;这儿需要说明一下，比如我们的数组长度n=4，那么呢n-1就是二进制的0011，举个例子当hash(key)为2和6的二进制分别时0010和0110，（前面的一些0就不做过多书写了），他们对于n-1的&amp;后得到的0011是相同的，也就是产生冲突，就会形成链表或者红黑树。而扩容之后，n’为8，n’-1二进制为0111，hash(key)进行&amp;操作后就是0010和0110，刚好是原来下标位置和原位置下标加上原来数组长度后作为下标的位置。这儿就可以直接用原来数组长度n的二进制0100与两个hash(key)进行&amp;操作，来判断是否需要将下标位置加上n了，如果是1则加。这样就不需要对于每个节点依次去进行一次重新定位操作。remove函数当然，跟之前的分析一样，我们都需要关注返回值，这儿返回的是value或者null，那么value是哪个value呢？就是原来我们移除的那个节点的value，当无这个节点时，那么返回null。其实这儿跟put函数一样，都是对于其基础函数的封装，这里remove函数是对于removeNode函数的封装。12345678910111213141516171819202122232425262728293031323334353637383940414243444546public V remove(Object key) &#123; Node&lt;K,V&gt; e; return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value;&#125;final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) &#123; Node&lt;K,V&gt; node = null, e; K k; V v; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) node = p; else if ((e = p.next) != null) &#123; if (p instanceof TreeNode) node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); else &#123; do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; node = e; break; &#125; p = e; &#125; while ((e = e.next) != null); &#125; &#125; if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) &#123; if (node instanceof TreeNode) ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); else if (node == p) tab[index] = node.next; else p.next = node.next; ++modCount; --size; afterNodeRemoval(node); return node; &#125; &#125; return null;&#125;从上面removeNode函数可以看出其返回的是一个Node类型，即返回移除的节点，除了没有对应节点时返回null，这儿有两个比较特殊的参数matchValue和movable，matchValue表示是否匹配value的值，而moveable表示是否可以移除，对于这点我有点想不太明白。在remove函数中这部分都是和value一起以默认值传出。在removeNode函数里面又有判断当为红黑树时的removeTreeNode函数，对于这个函数我不作过多分析，需要的可以自己去看一下源码。附对于其他函数等操作等，我就不具体分析，比如contains一系列，clear函数以及一系列Set等，以及其迭代器iterator等。这些如果需要学习可以仔细看一下其源码分析。最后推荐下美团点评技术团队的《Java 8系列之重新认识HashMap》。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>map</tag>
      </tags>
  </entry>
</search>
