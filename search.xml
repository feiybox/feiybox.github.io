<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[三年，北漂]]></title>
    <url>%2F2021%2F07%2F11%2F%E4%B8%89%E5%B9%B4%EF%BC%8C%E5%8C%97%E6%BC%82%2F</url>
    <content type="text"><![CDATA[​就这样想想，来北京待三年多，快三年半了。准备离开，说实话，算是有点小期待吧，毕竟还是很期待离家近的。对我来说，北京是个适合拼搏的城市，但不适合生活，离家太远，又很孤单，陌生的城市里一个人躺在出租屋里沉默。北京是一个适合成长的城市，你所看到的，见过的或许都是别人不知道的，只有自己处在那个位置，才知道那儿的风景是什么样子的。刚来北京时，像没见过世面的孩子一样，期待着新世界。也确实是没见过世面的孩子，对着一切有着新的好奇。工作这三年，我待过两家公司，也遇到一些贵人，这些朋友在我成长与人生路上帮助了我不少。17年底去了比特大陆，在比特一年里见证了18年比特币价格下滑的一年。至今为止我也还没有看透比特币，总觉得这是资本的炒作，究竟有多少人是信仰呢？在比特遇到尉哥，在工作中给了我很多帮助，后面找工作中帮了我许多，尉哥是一个很开朗的人，总是笑呵呵的，很能感染人。也遇到阿冬等好友，有很多交流，是我生活中的导师类的角色吧，能够在我感情不顺的时候陪着我喝点小酒。在18年底从比特离职，也算感谢比特把我裁掉，在安逸的日子里待着，成长必然就慢了。后来才会来字节以及在字节经历的一切。后续来了字节幸福里团队，经常有人问我，字节也做房产么？可以确切的回答：做。幸福里就是做这个的，这是一个挺不错的团队，在我感知里，大家的目标是统一的——将房产做好，将业务做出色。（有需要内推的同学也可以继续找我）在幸福里待了两年多时间，同样也遇到挺多贵人，比如和我们一起成长的leader，算是一起成长了两年，都有着挺大的变化。在幸福里遇见庆洲，一起拼搏着支持从0到1，有庆洲在的时候，我的压力也没那么大，会聚焦到某个具体事情上，在这个期间，算是完成了我北京的第一阶段突破。感谢庆洲在这段日子里的陪伴与鼓励。从天使到中兴再到天作，搬过两次工区，经常在摆渡车上穿梭。还有很多，幸福里遇到很多人，很好的同学，都在这儿一起感谢了，感谢这两年间来的照顾。凑巧，在我写这段文字的时候，字节取消大小周了，算是刚好错过双休的字节。读书18年终究是不忙碌的日子，刚来北京，不太熟悉，喜欢通过书籍去慰藉我的孤寂。在这一年我喜欢读一些名著类小说。这年里读了12本书，创建了自己的公众号“青纸”，写下自己的一些读书笔记与想法，虽然写得不是很好，但也算是自我满足着，我至少在去做，在去思考、去总结，算是对没有文采的我的自我安慰。19年，20年都开始忙碌起来。19年读了13本书，这一年还读了挺多的名著小说，后来就不读这一类了，转向技术与科学等类别了。20年只读了两本书，总结与产出也降低了。这些日子里，看过不正经的猫——《我是猫》；读过悲惨中的苦行者——《悲惨世界》；也读过从人类到上帝的《人类简史》。通过《谁动了我的奶酪》学会了改变，在《王慧文清华产品课》学习了解行业，选择行业。也恰巧知晓了“倒却鹦鹉捶碎楼”的有趣事迹。21年要继续加油了，加油多读点书。愿我们能做到“第一境”，“独上高楼，望尽天涯路”。生活从最开始住着回龙观，再到后来搬到中关村，再后来在牡丹园住了有两年时间。租房确实很贵（T_T）。刚来北京时很不适应，天气太干燥了，因为流鼻血而夜间醒来。冬天的阳光格外耀眼，明晃晃的，总是晃着看不清前方。尤其是风，让我对 “二月春风似剪刀” 有了额外的认识，二月的风如剪刀一般扎着脸疼。有时想想，如果自己再瘦一点，是不是就可以上天了。北京到成都的距离挺远的，高铁只有那几班，基本都是8-10小时。我第一次坐308到北京时，第二天躺了整整一天，很累，全身酸痛。后来好多了，基本没啥感觉了。三年里，足迹在北京漫山遍野。去天安门上“挥了挥手”，去故宫“登基”，去颐和园度假，去奥森锻炼，去古北水镇团建。天坛看天圆地方，香山登顶。在食宝街吃点小吃，我最喜欢的还是烤鸡爪，在西单溜达溜达，在北四环上单骑燃烧我的卡路里。感情三年也挺快的，找到她，一切尽在不言中。终北京是一个很不错的城市，适合拼搏与成长，机会也有很多。但北京和成都给我的感受始终不同，北京没有成都那种亲切感，虽然依旧很熟悉，但那种给我亲切感却着实不太一样。过些日子准备离开北京了，在此给大家道别。见字如面，一切皆好，勿念。感谢这些日子里大家的鼓励陪伴，以后有空来成都聚聚。愿好。“青山一道同云雨，明月何曾是两乡”。]]></content>
      <categories>
        <category>other</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[设计模式归纳]]></title>
    <url>%2F2021%2F06%2F29%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%BD%92%E7%BA%B3%2F</url>
    <content type="text"><![CDATA[设计模式是什么？是一种通用术语，本质是为了减少沟通的成本，并不是一种规范，一定要这么写才是好的。并且设置模式告诉我们有这些代码的组织方式，通过这些组织方式可以让我们的代码扩展性会更好（当然易读性会降低）。还有一点，设计模式本质是对于继承、组合等的多种组织代码的方式。设计的原则开闭原则：一个软件实体应当对扩展开放，对修改关闭。即软件实体应尽量在不修改原有代码的情况下进行扩展单一职责原则：一个类只负责一个功能领域中的相应职责，或者可以定义为：就一个类而言，应该只有一个引起它变化的原因。里氏替换原则：所有引用基类（父类）的地方必须能透明地使用其子类的对象。依赖倒置原则：高层模块不应该依赖低层模块，两者都应该依赖其抽象；抽象不应该依赖细节，细节应该依赖抽象，其核心思想是：要面向接口编程，不要面向实现编程。接口隔离原则：使用多个专门的接口，而不使用单一的总接口，即客户端不应该依赖那些它不需要的接口。迪米特原则：一个软件实体应当尽可能少地与其他实体发生相互作用。创建型模式工厂方法：在父类中提供一个创建对象的方法， 允许子类决定实例化对象的类型。也就是每个实现方可以按照自己的需要创建对应的对象。需要业务在需要哪个对象时去调用对应的工厂方法。子类自己初始化即可。简单工厂：拥有一个包含大量条件语句的构建方法， 可根据方法的参数来选择对何种产品进行初始化并将其返回。抽象工厂：在简单工厂上抽象了一层，可以解决需要创建一组相关或者相互依赖对象，而不用指定其具体对象生成器：分步生成复杂对象原型：复制对象单例：只生成一个实例结构型模式适配器：转换与适配。对象适配器，写一个适配器的方法或者类进行封装，进行适配逻辑；类适配器：继承多个类或实现多个接口来进行适配桥接：将一个大类或一系列紧密相关的类拆分为抽象和实现两个独立的层次结构， 从而能在开发时分别使用（在两者之间构造一个桥梁，比如在电脑与打印机之间构造mac与Windows电脑）组合：可以使用它将对象组合成树状结构， 并且能像使用独立对象一样使用它们（组织架构树）装饰：通过将对象放入包含行为的特殊封装对象中来为原对象绑定新的行为。实现功能的组合外观：能为程序库、 框架或其他复杂类提供一个简单的接口。不关心内在实现，只想使用简单接口，可以让自己的代码独立于复杂子系统享元：摒弃了在每个对象中保存所有数据的方式， 通过共享多个对象所共有的相同状态， 让你能在有限的内存容量中载入更多对象代理：能够提供对象的替代品或其占位符。 代理控制着对于原对象的访问， 并允许在将请求提交给对象前后进行一些处理。Java里有动态代理：基于接口，基于类行为模式责任链：将请求沿着处理者链进行发送，各种框架中的中间件是这种模式命令：将请求转换为一个包含与请求相关的所有信息的独立对象迭代器：在不暴露集合底层表现形式 （列表、 栈和树等） 的情况下遍历集合中所有的元素中介者：限制对象之间的直接交互， 迫使它们通过一个中介者对象进行合作。对象之间有相互影响的依赖逻辑，将这些逻辑都提炼出一个中介者，对象只需要和中介者交互，无需关心其他对象的依赖逻辑备忘录：在不暴露对象实现细节的情况下保存和恢复对象之前的状态。经典实现方式依赖于许多流行编程语言 （例如 C++、 C# 和 Java） 所支持的嵌套类。每次构建新对象等都保存之前的样子，用于撤回等操作。观察者：定义一种订阅机制， 可在对象事件发生时通知多个 “观察” 该对象的其他对象。发布订阅状态：能在一个对象的内部状态变化时改变其行为， 使其看上去就像改变了自身所属的类一样。都与有限状态机紧密相关。重点是将每个状态转换变成一个对象，对象内部执行逻辑，将上层进行简化。策略：定义一系列算法， 并将每种算法分别放入独立的类中， 以使算法的对象能够相互替换。和工厂的区别在于关注点不同，本方法关注点在于执行什么逻辑，而工厂关注点在于构造什么对象。和状态模式区别在于状态模式里多个状态间可以知晓对方存在，而策略无须如此，状态模式可以理解为策略模式的扩展。模版方法：在超类中定义了一个算法的框架， 允许子类在不修改结构的情况下重写算法的特定步骤。和策略区别在于层次不同。访问者：将算法与其所作用的对象隔离开来。主要做辅助功能。疑问：如果我只关注策略里策略方法的对象生成，那么它是工厂模式？如果我关注模版方法中的一个方法，那么对这个方法来说是否就是策略模式？]]></content>
      <categories>
        <category>tech</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[“欲穷千里目，更上一层楼”，现在几楼？]]></title>
    <url>%2F2021%2F05%2F22%2F%E2%80%9C%E6%AC%B2%E7%A9%B7%E5%8D%83%E9%87%8C%E7%9B%AE%EF%BC%8C%E6%9B%B4%E4%B8%8A%E4%B8%80%E5%B1%82%E6%A5%BC%E2%80%9D%EF%BC%8C%E7%8E%B0%E5%9C%A8%E5%87%A0%E6%A5%BC%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[白日依山尽，黄河入海流；欲穷千里目，更上一层楼。王之涣的《登鹳雀楼》只有二十个字，却表达出磅礴万里之气势。该诗写于鹳雀楼，在今山西永济市境内。那么问题来了，“欲穷千里目，更上一层楼”，诗人现在在几楼，才能够做到上一层楼就看到那么遥远的距离呢？先抛出答案：不存在这么高的楼，因此诗人看不到这么远。那么接下来，我们证明一下这个问题。首先我们要提出几个假设：假设地球是一个标准的球体，不是非规则的椭球假设光线在在地球上呈现直线传播，忽略由于地球引力导致的光偏折问题假设光线可达的具体为可见距离，实际的可视距离远远小于该距离我们设当时作者的所在高度离地心的距离为R（R大于海平线到地心的距离）；设x为能看到千里目的位置的高度。1千里等于500km。其中 R = 地球海平线半径 + 海拔，其中地球海平线半径约为6371.393千米，山西永济平均海拔在400米左右，因此R约为6372千米。那么根据上述公式进行计算，x约为19千米，而世界上最高的楼为828米（哈利法塔，原名迪拜塔），喜马拉雅高度为8844.43米，而民航一般不会超过12600千米。因此我们平常人无法穷千里目。当然，上火星看地球是可以的当然是可以的。]]></content>
      <categories>
        <category>other</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[协程里的通信]]></title>
    <url>%2F2021%2F04%2F24%2F%E5%8D%8F%E7%A8%8B%E9%87%8C%E7%9A%84%E9%80%9A%E4%BF%A1%2F</url>
    <content type="text"><![CDATA[在我们项目中经常遇到一些生产者-消费者问题，比如在我们提出的kafka组件，就是面对生产者与消费者的中间通信组件。我们在开发中常提到线程，常常通过线程来做并发处理。任何一个函数，或者任何一个组件，实际都是存在输入、输出。从其中将问题归纳，也是生产者-消费者。在Golang中存在协程，在协程中怎么解决并发的问题。1234567891011121314151617181920212223242526272829errChan := make(chan error, 10)// 生产者go func() &#123; defer close(errChan) conCu := 10 wg := new(sync.WaitGroup) wg.Add(conCu) for i := 0; i &lt; conCu; i++ &#123; go func(flag int) &#123; defer wg.Done() println(flag) if flag % 3 == 0 &#123; errChan &lt;- fmt.Errorf(&quot;3, i=%d&quot;, flag) &#125; &#125;(i) &#125; wg.Wait()&#125;()// 消费者for true &#123; err, ok := &lt;- errChan if !ok &#123; break &#125; fmt.Printf(&quot;err=%s\n&quot;, err)&#125;println(&quot;done&quot;)代码中使用的并发方案，使用sync.WaitGroup与chan来进行协程间通信。协程是什么协程是一种比线程更加轻量级的存在，又言用户级协程。其对内核透明，系统并不知道协程存在，由用户程序进行调度控制，协程上下文切换也是完全由用户自己控制。「Golang-协程调度原理」协程间通信常用的协程间通信方式由多种：共享内存WaitGroupchannel 通道在Golang中推荐通过通道通信，而不推荐通过共享内存的方案进行通信。在上述三者中，WaitGroup是基于CAS来实现，为什么使用CAS以及CAS解决了什么问题，这个我们后面再讲讲，这次中就不提及了。channel使用要注意什么（内部原理）channel底层数据结构中，有几个重要的点：buf：数据缓存，指向一个环形缓冲区recvq：接收者列表sendq：发送者列表lock：互斥锁，每次写入与消费数据都需要加索从channel的语法中分为两种：有缓冲的channel与没有缓冲的channel，我个人理解是认为他们是相同的，唯一的区别缓冲buf为0，不能缓冲任何结果。从上述描述中可以看出，在使用channel中需要注意些什么？当channel中buf不够时，再向channel写入的时候，回阻塞协程channel使用完成后，需要close掉，否则消费channel的协程最后不会被销毁、回收channel在close之后，如果其中数据存在，依然可以从其中读取数据，直到最终监听到channel close的消息后死锁在使用channel的时候，需要避免的事死锁，什么时候会发生死锁的情况呢？其中channel中的缓冲区被消费完成后，如果再向channel中写入的时候，会阻塞当前协程，如果在阻塞之后没有协程会消费channel中的数据，则会发生死锁，协程也是因此阻塞。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>Golang</tag>
        <tag>Goroutine</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[什么是技术？]]></title>
    <url>%2F2021%2F04%2F18%2F%E4%BB%80%E4%B9%88%E6%98%AF%E6%8A%80%E6%9C%AF%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[我们在工作中，每天在做的事情是：接需求、分析需求、选择与设计方案、开发、测试、上线、监控。似乎我们一直在这个循环中进行轮回，一直在忙着做事，解决问题；却不知道我们在成长什么，我们的竞争力是什么？我一直将成长分为四个方向，这四个方向都需要成长与突破：技术、问题解决、业务理解、管理。业务理解指的是对业务的理解能力，对业务的感知，知道在现有需求中哪些是应该突破的方向；问题解决指的是问题解决能力，如需求解决、事情推动、项目负责等。那么技术应该是什么？我们常说的我们要提升自己的技术能力，那么在工作中哪些是技术能力？技术是解决问题的方法及方法原理，是指人们利用现有事物形成新事物，或是改变现有事物功能、性能的方法。技术应具备明确的使用范围和被其它人认知的形式和载体，如原材料（输入）、产成品（输出）、工艺、工具、设备、设施、标准、规范、指标、计量方法等。技术与科学相比，技术更强调实用，而科学更强调研究；技术与艺术相比，技术更强调功能，艺术更强调表达。百科中提到「技术是解决问题的方法及方法的原理」。也就是工作即是技术，工作本质是解决问题。那么我们的核心竞争力是什么呢？一般面试中，常面试的是基础、项目、代码能力，考察人的基础是否扎实，项目能力多是看目前解决问题的能力、对项目的理解，代码能力主要是考察思考能力、聪明程度等。我们常说的技术方向，需要深度与广度并重，最近发现在技术上似乎荒废了一段时间，在一段时间里，技术上似乎没有成长，对于各种技术方法的原理理解不多，对于项目的总结也不多。常常提到“架构”，架构师又是做什么的呢，需要有什么能力呢？知乎有答案参考，摘录部分如下：针对软件需求中的业务场景和流程，功能性需求进行功能性架构设计通过软件需求中的非功能性需求，来考虑整个系统的技术架构设计对于软件生命周期和软件工程域标准内容的设计按照我的思维细拆了一下我理解的技术方向，其中常说的技术，更偏向于方案这个分类，也就是常说的硬实力。]]></content>
      <categories>
        <category>other</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[打工人如何选择行业-读《王慧文清华产品课》随想]]></title>
    <url>%2F2021%2F03%2F21%2F%E6%89%93%E5%B7%A5%E4%BA%BA%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9%E8%A1%8C%E4%B8%9A-%E8%AF%BB%E3%80%8A%E7%8E%8B%E6%85%A7%E6%96%87%E6%B8%85%E5%8D%8E%E4%BA%A7%E5%93%81%E8%AF%BE%E3%80%8B%E9%9A%8F%E6%83%B3%2F</url>
    <content type="text"><![CDATA[这是讲如何做产品的课程，同样可以让我们学会如何剖析产品。作为一个打工人，如何选择自己的行业也可以在这里找到一些思路。或许在很多场景中，老板都会和你聊当前行业前景很大，在这个行业中会有很大的收获，俗称“画饼”。那么如何判断这个饼是否真实呢？正如文档中提到的，一般来说在一个领域中一个产品的成功对应着无数产品的失败，这个比例大约在1:30。如何判断我们所处在的行业是可以成功的，并且我们是可以去突破这个极限的呢？首先我们需要看到这个行业的市场体量，如果是一个很小的市场，那么这个市场就无法做到画伟大蓝图的前景；并且我们还需要知道目前处在这个市场是增量还是存量市场，这个和市场的规模同样需要知道，知道目前市场的前景是什么样子的，在打增量市场和在打存量市场所对应的难度是不同的，比如说在熟人聊天这个行业，现在入场就很难了，这儿也就有存量市场一个因素。另外需要判断这个市场的扩展是具有规模效应的，如何快速的讲当前的模式就行扩展，进行规模化，并且需要考虑规模化的成本。需要清晰这个规模效应的模式，比如一个行业中最重要的链主是什么？这一点需要清楚，我们才能找到具体的生意模式，以及知道找到整个生意中最重要的部分。在进入一个行业时，还需要考虑这个行业的市场集中度，比如在这个行业中头部公司对市场的占有率，在一个头部公司对市场占有率还没那么高的行业，就可以体现出这个行业目前还有很大的竞争潜力，在这个行业中将会有很大的发展。还需要考虑另外一个点，波特五力模型，综合起来影响着产业的吸引力以及现有企业的竞争战争策略。比如说我们经常提到的行业壁垒，这个也是在这个行业中提到了的一点。一个壁垒高的行业，在增长曲线上表现为则是指数形的，并且先发优势也很大，对于后发者，难度特别高。比如微信，这个行业就是这种情况。而对于淘宝，这个行业的增长曲线是线性的，因此后来的拼多多成长起来了。以上只是我在读《王慧文清华产品课》的一些简单想法。强力推荐读这篇文稿，可以看到一些很不一样的视角。【笔记】读《王慧文清华产品课》]]></content>
      <categories>
        <category>read</category>
      </categories>
      <tags>
        <tag>pro</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【笔记】读《王慧文清华产品课》]]></title>
    <url>%2F2021%2F03%2F21%2F%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91%E8%AF%BB%E3%80%8A%E7%8E%8B%E6%85%A7%E6%96%87%E6%B8%85%E5%8D%8E%E4%BA%A7%E5%93%81%E8%AF%BE%E3%80%8B%2F</url>
    <content type="text"><![CDATA[一个领域里一个产品的成功对应着无数的产品的失败，比例大约在1:30。产品经理是CEO的学前班，不管是否是专业出身，都要有做创业产品经理的心态和思维。战略战略是指不同时空中ROI最高的Strategy。空间有多个含义，不同的地区是空间，不同的业务也是空间。市场体量投入的合理性取决于对市场体量的判断，需要判断两点：市场足够大、时机合适。规模效应交易额/客户使用量足够大之后所产生的客户体验优势或成本优势，具体是成本优势还是客户体验优势取决于具体的生意模式。不同的生意具有不同的规模效应。企业发展的过程中，越早抓住那些有规模效应的要素，越会因为规模效应起作用（成本低或用户体验好）。所以规模效应是决定企业发展速度成败的高权重要素。1、规模效应曲线指数形：网络效应线性形：规模性越强，则价值越高对数形：规模上升，到一个水平后规模效应的增长变缓了，常常有一些负作用，常常有一些负作用出现。一般具有“双边网络具有同边负效应”。2、规模效应的范围全球型/全国型/城市型/蜂窝型规模效应的曲线形状和起作用的范围决定了很多生意的市场格局。3、规模效应曲线的参数比如斜率的大小。4、要素的规模应用业务选定下，哪些是有规模效应的，哪些是没有的，哪些要素是反规模效应的，而这些要素里你的经营取舍，商业模式设计，管理取舍就非常重要了。（管理是反规模效应的）马太效应凡有的，还要加倍给他叫他多余；没有的，连他所有的也要夺过来。快速做大（做出名）——利用马太效应。市场集中度市场中排名前几名对市场的占有率。产业链每个产业链都有链主，链主才是这个行业里生存最好的角色，也是产业变革中更有主权的一方。在一个产业里面生存最好的是处于最上游接近核心供应资源和最下游接近消费者的企业。总的来说：对产业链的控制。波特五力模型：综合起来影响着产业的吸引力以及现有企业的竞争战争策略。同行业内现有竞争者的竞争能力潜在竞争者进入能力替代品的替代能力供应商的讨价还价能力购买者的议价能力先发与后发先发优势后发优势不需要说服其他人；知道这个事情一定能实现了；后发者通常是比较常规的商业思维模式，而创新者通常思维是很独特的，但也带来了认知盲区。创新者和后发者的根本差别是创新者通常是有思维盲区，而后者思维盲区会小些。存量与增量任何一个时间点要知道我们在做增量还是存量的市场。存量市场的发展实在是太难了。对组织的要求也很高，所以还是在增量市场去发展。衡量增量存量的一个标准就是渗透率。高频低频高频打低频APP就具备优势。入场时机天时大于地利，地利大于人和。“如果你相信一件事早晚会发生，就每三年试一次”。只要你没有倒闭，就是早入场比晚入场好，但怎么扛住别倒闭这件事对大公司和小公司都很难。麦克波特三战略成本领先，差异化，聚焦。（只是商业中竞争的一部分）标准化战略和有效战略Strategy for ProductPMF（Product Market Fit）为市场匹配一个产品。无论是要做一个多大的市场，最开始都需要找一个更锐利的切入点切入市场，这个PMF选择越犀利，早期ROI就高，成功的概率就越高。创新的扩散、STP、4P帮助找到PMF。创新的扩散在产品设计和市场推广的过程中能分清扩散的阶段和匹配扩散阶段设计产品会极大的提高ROI，当资金、组织能力、研发能力都上来之后再扩展新的人群，提供更好的产品。创新的扩散里第一阶段是创新Innovator，第二阶段是Early Adopter。需要正确地找到自己的Innovator或Early Adopter。STPS是市场做划分，分成很多块，T是划分完的市场里选一块作为目标市场，P是市场和产品（供给端）的认知连接。1、Segmenting选择正确的选择系来划分市场。坐标系的划分可以有非常多的维度，把哪些要素选入坐标系中，是非常根本性地影响你对这个行业和生意和产品的看法的。如果你要做一个很艰难的决策，那可能是你分析不够好，你没有选择正确的维度和颗粒度去分析，所以怎么做都很艰难。2、Targeting警惕市场空间选得太大了。3、Positioning对用户来说，你的产品是什么，用户为什么要选你的产品。T偏向需求和客户，而P更偏供给和产品。高效的营销是能快速把T和P关联起来营销。要用最低的成本去建立用户认知。4P理论价格、产品、渠道、推广定价决定产品，定价影响需求，而产品是供给。用STP选完选择之后再分别应用4P。互联网时代的4P理论4P理论一方面是我们做商业模式设计的框架，另一方面是定义产业链的利益分配。Strategy for Operation分层经营没有一个产品可以满足其所在领域的所有需求，也没有一个经营分层可以解决所有需求，不同的经营分层的差别是很大的。（分层经营的挑战在认知和组织局面都很大）不同产品的经营分层同一种产品的经营分层分类经营需求需求的不可满足性能满足的需求远远少于不能满足的需求。需求的永恒性和变化性需求分为两种：1、一直很强烈，一直很广泛但实现很难；2、虽然一直存在但最近一段时间强烈度和广泛程度变大。所有伟大的需求都有两个很重要的特征：1、人们会说这是一个伟大的需求但不可能实现；2、人们会说没有这个需求。如何识别需求搞清楚过去那些人为什么没有成功（尤其要研究那些挺成功的失败）。微观层面的需求基本没有用户会直接说出自己的需求，大部分人提的是Demand或者Requirement，极少有人提的是Needs。供需关系供需关系的重要性空间要素时间要素分层非市场要素线上与线下]]></content>
      <categories>
        <category>read</category>
      </categories>
      <tags>
        <tag>pro</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2020：间歇性踌躇满志，持续性混吃等死]]></title>
    <url>%2F2020%2F12%2F31%2F2020%EF%BC%9A%E9%97%B4%E6%AD%87%E6%80%A7%E8%B8%8C%E8%BA%87%E6%BB%A1%E5%BF%97%EF%BC%8C%E6%8C%81%E7%BB%AD%E6%80%A7%E6%B7%B7%E5%90%83%E7%AD%89%E6%AD%BB%2F</url>
    <content type="text"><![CDATA[年初的时候，我给了今年的目标：书13 增加认知，科学方面，减少文学偏向底层（计算机系统，数据库）leetcode刷题24（保持思维活跃）课程12（mooc对其他方向及事物了解）回头来看这一年完成了多少。首先读书上，方向变了，不再读文学方向的书了，开始朝着科学的方向开始学习，不再看小说类的书。这一年离读书的目标还有点遥远，只读完成了两本书。第一本是《数据库系统概念》，写了笔记，这本书基本快跨度一年的周期，但目前还未对该方向形成更加系统的总结，还没有形成深刻刻入到我骨肉的东西。在leetcode上，这一年做了18道题，整体上符合预期，达到了活跃思维的目的了。课程上，这一年基本没有在这个方向上发力，或者说这一年也太懒了。这个方向目的也是为了看书的弥补和总结。最终都是为了形成自己的思维。这一年，写了7篇博客，博客主页：https://feiybox.com。这一年相比较上一年，产出降低了，当然在思考和总结方面也有更多的收获，开始思考不仅仅做技术的事情，开始考虑一些做业务的事情，学会怎么做一个事情。这一年，我遇到了相知人，和小伍在一起了（手动撒花）。这一年，我依然在某个方向上的沉淀不够，需要多沉淀和总结，对自己看过的，遇到的，以及做过的，不管是业务还是技术，多总结思考。这一年也开始思考，我想成为一个生命样的人，我想成为一个有趣的人，有一个有趣的灵魂。有丰富的见闻，有独立的主见，也有同理心。这一年，经历了疫情，我还活着。这一年，我来北京三周年了，我还活着。这一年，就这么过了，没有煽情，有点平淡，也有惊喜。总结来说：我还活着。间断性踌躇满志，持续性混吃等死。and 有你真好（手动撒花）。]]></content>
      <categories>
        <category>other</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[社区产品思考]]></title>
    <url>%2F2020%2F12%2F27%2F%E7%A4%BE%E5%8C%BA%E4%BA%A7%E5%93%81%E6%80%9D%E8%80%83%2F</url>
    <content type="text"><![CDATA[任何一个产品，都需要想着几个问题：产品的使命和价值观用户可以在我们产品得到什么，即我们可以为用户提供什么样的服务建立用户信任社区也是这样，需要考虑我们的使命和价值观，也需要考虑我们可以为用户提供什么样的服务，同时也需要让用户建立对产品的长期信任。什么是社区？以某种介质为交流载体，可沉淀社交关系的产品形态，就是广义的社区。社区也是一种社交，只不过是弱社交的一种产品形态。弱社交：用户间没有太强的社交关系，用户井入这样的社区更多是获取内容。这样的社区更多以内容取胜，因此应该着重关注内容产生情况（发贴量），以及原创内容的情况。强社交：用户间由于存在较强的社交关系，用户进入这样社区更不是获取其社交关系网动态。因此这样的社区应该更关注用户间的互动数据（互踩，互留评论），这反应用户间社交关系亲密度。社区产品：用户目的就是为了消费这些内容，来满足自身的需求。与内容建立联系是主线，而与人建立联系是副线（即使想去建立联系但也可能很难实现）社交产品：注重的是用户属性，所有内容都是为了用户属性，并不是为了消费这些内容，只是借由这些更好地去了解特定的人，与特定的人建立联系。与人建立联系是主线，内容是副线。从上述可以看出，社区的两大要素是人与内容，最优形态也是和社交产品一样形成社交网络（比如关注网络等）。社区的基石是文化、角色、内容，社区的定位决定了社区的文化，而社区的文化影响社区角色的行为以及它们所产生和消费的内容，而内容作为文化的载体吸引着认同社区文化的用户进入社区。为什么要做社区？人都拥有社交、尊重和自我实现的需求。什么样的社区是好的社区？有归属感的社区就是好的社区。用户可以在社区上构建出自己的圈子，形成自己的交际圈子。归属感会带来用户忠诚度和粘性，是一个优秀社区的核心竞争力。归属感可以拆分成以下几件事情：社区的使命愿景价值观安全和可信赖的社区环境社会资本在用户之间产生。用户之间相互作用，会沉淀社交关系，才会产生社会资本。产生的社会资本越来越多，对社区的归属感就越强。有属于自己社区的故事。互联网有很多梗、热词、草根火起来，一般都是出自某个社区，然后在全网流传，这就是属于自己社区的故事。（爆款的本质就是社区的一个故事在全网范围的传播，可能是运营包装策划的，也可能是网友自发传播。）怎么做好的社区？文化：让团队来建立强有力的社区明文化让用户来养成社区的暗文化角色：为生产者提供工具，为消费者提供内容（为用户提供服务，细节）注重KOL，更注重KOC打造角色等级体系的上升通道内容：注重没有时效性的内容做好内容分类，明确内容主题内容生产（内容搬运，官方生产，活动引导）内容筛选与内容价值合理排序以合适的方式进行分发社区可能突围的创新方向有两个：极低成本获取特定兴趣用户的能力全新的信息载体格式做社区中有什么常规的操作？构建圈子、话题、活动等方式引导用户发内容、推广大v内容活动等。构建用户画像，构建内容特征，为用户群体提供个性化内容。变现注重一点，任何产品留下用户，都是因为用户对该产品的信任，因此变现方式需要能对得起用户的信任。]]></content>
      <categories>
        <category>pro-exp</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[字符串匹配算法]]></title>
    <url>%2F2020%2F12%2F07%2F%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[字符串匹配：本身是指在一个字符串中找到另一个字符串，可以暴力的方式按照字符来进行匹配。优化匹配的效率的方向是：减少不成功的匹配次数，比如KMP、BM等优化策略都是如此，通过某种方式，或者某种规则来加速匹配过程。BF算法（暴力算法）普通模式的匹配算法：两个循环嵌套进行匹配，直到匹配成功。Golang语法下可以截取字符串进行比较：1234567891011// Golang语法字符串截取优化func MatchUseGo(str string, target string) int &#123; strArr := []rune(str) targetArr := []rune(target) for i := 0; i &lt;= len(strArr)-len(targetArr); i++ &#123; if target == string(strArr[i:i+len(targetArr)]) &#123; return i &#125; &#125; return -1&#125;123456789101112131415161718192021// BF算法：暴力算法func MatchBF(str string, target string) int &#123; strArr := []rune(str) targetArr := []rune(target) for i := 0; i &lt;= len(strArr)-len(targetArr); i++ &#123; match := true if target == string(strArr[i:len(targetArr)]) &#123; return i &#125; for j := 0; j &lt; len(targetArr); j++ &#123; if strArr[i+j] != targetArr[j] &#123; match = false break &#125; &#125; if match &#123; return i &#125; &#125; return -1&#125;RK算法（基于BF算法的改进）核心思想是哈希，即在详细比较之前，先使用hash进行比较，如果不匹配则右移。如果匹配，由于hash值可能存在碰撞的情况，因此需要进行详细判断。12345678910111213141516171819202122// RK算法：使用hash匹配匹配进行优化func MatchRK(str string, target string) int &#123; strArr := []rune(str) targetArr := []rune(target) for i := 0; i &lt;= len(strArr)-len(targetArr); i++ &#123; // 使用字符串的hash进行匹配，如果一致再进行详细匹配 if md5.Sum([]byte(string(strArr[i:i+len(targetArr)]))) != md5.Sum([]byte(target)) &#123; continue &#125; match := true for j := 0; j &lt; len(targetArr); j++ &#123; if strArr[i+j] != targetArr[j] &#123; match = false break &#125; &#125; if match &#123; return i &#125; &#125; return -1&#125;KMP算法关键在于部分匹配表（RMT表）：字符串起始位置到当前位置的字符串，“前缀”和“后缀”的最长的共有元素长度。移动位数 = 已匹配的字符数 - 对应的部分匹配值。部分匹配表代表：模式串中某个位置匹配失败的时候，可以直接转到某个位置开始重新开始匹配。1234567891011121314151617181920212223242526272829303132333435// KMP算法：部分匹配表，在匹配失败时，可以跳过部分字符匹配func MatchKMP(str string, target string) int &#123; strArr := []rune(str) targetArr := []rune(target) // 构建部分匹配表（RMT表） targetRMT := make([]int, len(targetArr)) k := -1 targetRMT[0] = -1 for i := 0; i &lt; len(targetRMT) - 1; &#123; if k == -1 || targetArr[i] == targetArr[k] &#123; i++ k++ targetRMT[i] = k &#125; else &#123; k = targetRMT[k] &#125; &#125; // 匹配 i, j := 0, 0 for ; i &lt; len(strArr) &amp;&amp; j &lt; len(targetArr); &#123; if j == -1 || strArr[i] == targetArr[j] &#123; i++ j++ &#125; else &#123; j = targetRMT[j] // 当前位置的字符匹配失败，直接转移到模式串匹配表对应位置 &#125; &#125; if j &gt;= len(targetArr) &#123; return i - len(targetArr) &#125; return -1&#125;BM算法从后往前对模式串进行扫描与主串进行匹配的，使用两个启发策略。坏字符算法：坏字符：字符串中的某个字符跟模式串的某个字符不匹配时，这个失配字符为坏字符。模式串中有对应的坏字符时，让模式串最靠右的对应字符与坏字符相对。模式串中不存在坏字符，那么直接右移整个模式串长度这么大步数。坏字符表的定义为：对于输入字符集合中的字符C，如果C不在模式串中，则C对应的值=模式串最末元素的索引值-字符C在模式串中最右出现的位置，字符不在模式串中时对应的值为-1。好后缀算法：模式串中有子串和好后嘴完全匹配，则将最靠右的那个子串移动到好后缀的位置继续进行匹配。如果不存在和好后缀完全匹配的子串，则好后缀中找到具有如下特征的最长子串，使得P[m-s...m] = P[0...s]。如果完全不存在和好后缀匹配的子串，则右移整个模式串。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061func MatchBM(str string, target string) int &#123; strArr := []rune(str) strLen := len(strArr) targetArr := []rune(target) targetLen := len(targetArr) // 构建坏字符 badArr := make([]int, 256) for i := 0; i &lt; 256; i++ &#123; badArr[i] = targetLen &#125; for i := 0; i &lt; targetLen; i++ &#123; badArr[targetArr[i]] = targetLen - i - 1 &#125; // 构建好后缀 suff := make([]int, targetLen) suff[targetLen-1] = targetLen for i := targetLen - 2; i &gt;= 0; i-- &#123; q := i for q &gt;= 0 &amp;&amp; targetArr[q] == targetArr[targetLen-1-i+q] &#123; q = q - 1 &#125; suff[i] = i - q &#125; goods := make([]int, targetLen) for i := 0; i &lt; targetLen; i++ &#123; goods[i] = targetLen &#125; for i := targetLen - 1; i &gt;= 0; i-- &#123; j := 0 if suff[i] == i+1 &#123; for ; j &lt; targetLen-1-i; j++ &#123; if goods[j] == targetLen &#123; goods[j] = targetLen - 1 - i &#125; &#125; &#125; &#125; for i := 0; i &lt; targetLen-1; i++ &#123; goods[targetLen-1-suff[i]] = targetLen - 1 - i &#125; // 查找 for i := 0; i &lt;= strLen-targetLen; &#123; j := targetLen - 1 for ; j &gt;= 0 &amp;&amp; targetArr[j] == strArr[i+j]; j-- &#123; &#125; if j &lt; 0 &#123; return i &#125; max := badArr[int(strArr[i+j])] - targetLen + 1 + j if goods[j] &gt; max &#123; max = goods[j] &#125; i = i + max &#125; return -1&#125;Sunday算法从前往后扫描模式串的，其思路更像是对于“坏字符”策略的升华，关注的是主串中参与匹配的最末字符的下一位，将其与当前跳表判断下一步移动距离。启发策略：当遇到不匹配的字符时，如果关注的字符没有在模式串中出现则直接跳过即移动位数=子串长度+1。当遇到不匹配的字符时，如果关注的字符在模式串中也存在时，其移动位数=模式串长度-该字符最右出现的位置（以0开始）或者移动位数=模式串中该子串最右出现的位置到尾部的距离+1。123456789101112131415161718192021222324252627282930313233func MatchSunday(str string, target string) int &#123; strArr := []rune(str) targetArr := []rune(target) strLen := len(strArr) targetLen := len(targetArr) // 构建跳表 jump := make([]int, 255) for i := 0; i &lt; 255; i++ &#123; jump[i] = targetLen + 1 &#125; for i, c := range targetArr &#123; jump[c] = targetLen-i &#125; for i := 0; i &lt;= strLen-targetLen; &#123; flag := true for j := 0; j &lt; targetLen; j++ &#123; if targetArr[j] != strArr[i+j] &#123; flag = false break &#125; &#125; if flag &#123; return i &#125; // 使用当前匹配对应长度的下一个字符计算移动距离 i = i + jump[strArr[i+targetLen]] &#125; return -1&#125;]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>Algo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【笔记】数据库系统概念]]></title>
    <url>%2F2020%2F11%2F25%2F%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[引言数据库管理系统（DBMS）由一个互相关联的数据的集合（数据库）和一组用以访问这些数据的程序组成。数据库系统的一个主要目的是为用户提供数据的抽象视图，系统隐藏数据存储和维护的细节。数据库结构的基础是数据模型：一个用于描述数据、数据之间的联系、数据语义和数据约束的概念工具的集合。关系数据模型是最广泛使用的将数据存储到数据库中的模型。其他的数据模型有面向对象模型、对象-关系模型和半结构化数据模型。数据操纵语言（DML）是使得用户可以访问和操纵数据的语言。数据定义语言（DDL）是说明数据库模式和数据的其他特征的语言。数据库设计主要包括数据库模式的设计。实体-联系（E-R）数据模型是广泛用于数据库设计的数据模型，提供一种方便的图形化的方式来观察数据、联系和约束。数据库设计流程：制定出用户需求的规格文档在概念设计阶段开发出来的模式提供企业的详细概述：描述数据以及它们之间的联系，而不是指定无力的存储细节逻辑设计阶段：设计者将高层的概念模式映射到要使用的数据库系统的设计数据模式上物理设计阶段：指定数据库中的物理特性，这些特性包括文件组织的形式以及内部的存储结构数据库系统由几个子系统构成：1、存储管理器子系统在数据库中存储的低层数据与应用程序和向系统提交的查询之间提供借口。2、查询处理器子系统编译和执行DDL和DML语句。事务是数据库应用中完成单一逻辑功能的操作结合。每个事务是一个既具有原子性又具有一致性的单元。原子性和持久性的保证是数据库系统自身的职责。事务管理负责保证不管是否有故障发生，数据库都要处于一致的（正确的）状态。事务管理器还保证并发事务的执行互不冲突。数据库系统的体系结构受支持其运行的计算机系统的影响很大。数据库系统可以是集中式的。或是客户-服务器方式的，即一个服务器及其为多个客户机执行工作。数据库系统还可以设计成具有能充分利用并行计算系统结构的能力。分布式数据库跨越多个地理上分布的互相分离的计算机。典型地，数据库应用可被分为运行在客户机上的前端和运行在后端的部分。在两层的系统结构中，前端直接和后端运行的数据库进行通信。在三层结构上，后端又被分为应用服务器和数据库服务器。知识发现技术试图自动地从数据中发现统计规律和模式。数据挖掘领域将人工智能和统计分析研究人员创造的知识发现技术，与使得知识发现技术能够在极大地数据库上高效实现的技术结合起来。数据挖掘指半自动地分析大型数据库并从中找出有用的模式的过程。关系数据库关系模型介绍数据模型是描述数据、数据联系、数据语义以及一致性约束的概念工具的集合。数据库模式是指数据库的逻辑设计，数据库实例是指给定时刻数据库中数据的一个快照。关系数据模型建立在表的集合的基础上。数据库系统的用户可以对这些表进行查询，可以插入新元组、删除元组以及更新（修改）元组。表达这些操作的语言又几种。关系的模式是指它的逻辑设计。而关系的实例是指它的特定时刻的内容。数据库的模式和实例的定义的类似的。关系的模式包括它的属性，还可能包括属性类型和关系上的约束，比如主码和外码约束。关系的超码是一个或多个属性的集合，这些属性上的取值保证可以唯一识别出关系中的元组。候选码是一个最小的超码，也就是说，它是一组构成超码的属性集，但这组属性的任意子集都不是超码。关系的一个候选码被选作主码。在参照关系中的外码是这样的一个属性集合：对于参照关系中的每个元组来说，它在外码属性上的取值肯定等于被参照关系中某个元组在主码上的取值。模式图是数据库中模式的图形化表示，它显示了数据库中的关系，关系的属性、主码和外码。关系查询语言定义了一组运算集，这些运算可以作用于表上，并输出表作用结构。这些运算可以组合成表达式，表达所需的查询。关系代数提供了一组运算，它们以一个或多个关系为输入，返回一个关系作为输出。诸如SQL这样的实际查询语言的基于关系代数的，但增加了一些有用的句法特征。SQLSQL是最有影响力的商用市场化的关系查询语言。包括以下几个部分：1、数据定义语言（DDL），提供了定义关系模式、删除关系以及修改关系模式的命令；2、数据操作语言（DML），提供查询语言，以及往数据库中插入元组、从数据库中删除元组修改数据库中元组的命令。SQL的数据定义语言用于创建具有特定模式的关系。除了声明关系属性的名称和类型之外，SQL还允许声明完整性的约束，例如主码约束和外码约束。SQL提供多种用于查询数据库的语言结构，其中包括select、form和where子句。SQL支持自然连接操作。SQL还提供了对属性的关系重命名，以及对查询结果按特定属性进行排序的机制。SQL支持关系上的基本集合运算，包括并、交和差运算。SQL通过在通用真值true和false外增加增值“unknown”，来处理对包含空值进行排序的机制。SQL支持在外层查询的where和from子句中嵌套子查询。它还在一个表达式返回的单个值所允许出现的任何地方支持标量子查询。SQL提供了用于更新、插入、删除信息的结构。中级SQLSQL支持包括内连接、外连接在内的几种连接类型，以及几种形式的连接条件。视图关系可以定义为包含查询查询结果的关系。视图可以隐藏不需要的信息，可以把信息从多个关系收集到一个单一的视图中。事务是一个查询的更新的序列，它们共同执行某项任务。事务可以被提交或回滚。当一个事务被回滚，该事务执行的所有更新所带来的影响将被撤销。完整性约束保证授权用户对数据库所做的改变不会导致数据一致性的破坏。参照完整性约束保证出现在一个关系的给定属性集上的值同样出现在另一个关系的特定属性集上。域约束指定了在一个属性上可能取值的集合。这种约束也可以禁止在特定属性上使用空值。断言是描述性表达式，它指定了我们要求总是为真的谓词。SQL数据定义语言提供对定义诸如date和time那样的固有域类型以及用户定义域类型的支持。通过SQL授权机制，可以按照在数据库中不同数据值上数据库用户所允许的访问类型对他们进行区分。获得了某种形式授权的用户可能允许将此授权传递给其他用户。但是，对于权限怎样在用户间传递我们必须很小心，以保证这样的权限在将来的某个时候可以被收回。角色有助于根据用户在组织机构中扮演的角色，把一组权限分配给用户。高级SQLSQL查询可以从宿住语言通过嵌入和动态SQL激发。ODBC和JDBC标准给C、Java等语言的应用程序定义接入SQL数据库的应用程序接口。函数和过程可以用SQL提供的过程来定义，它允许迭代和条件语句。触发器定义了当某个事件发生而且满足相应条件时自动执行的动作。触发器有很多用处，例如实现业务规则、审计日志，甚至执行数据库系统外的操作。联机分析处理（OLAP）工具帮助分析人员用不同的方式查看汇总数据。OLAP工具工作在以维属性和度量属性为特性的多维数据之上。数据立方体由以不同方式汇总的多维度数据构成。预先计算数据立方体有助于提高汇总数据的查询数据。交叉表的显示允许用户一次查看多维数据的两个维及其汇总数据。下钻、上卷、切片和切块是用户使用OLAP工具时执行的一些操作。形式化关系查询语言关系代数定义了一套在表上运算且输出结果也是表的代数运算。这些运算可以凝合使用来得到表达所希望查询的表达式。关系代数定义了关系查询语言中使用的基本运算。关系代数运算可以分为：1、基本运算；关系代数基本运算有：选择、投影、并、集合差、笛卡尔积和更名。选择、投影和更名运算是一元运算符。选择：选出满足给定谓词的元组。二元运算自然连接使得我们可以将某些选择和笛卡尔积运算合并为一个运算。自然连接运算首先形成它的两个参数的笛卡尔积，然后基于两个关系模式中都出现的属性上相等性进行选择，最后还要去除重复属性。2、附加的运算，可以用基本运算的表达；包括集合交、自然连接和赋值。3、扩展的运算，其中的一些扩展了关系代数的表达能力。广义投影：允许在投影列表中使用算术运算和字符串函数等来对投影进行扩展。以下三种等价：基本关系代数（不包含扩展关系代数运算）限制在安全表达式范围内的元组关系演算限制在安全表达式范围内的域关系演算没有任何一个域关系演算等价于聚集运算，但是它可以扩展支持聚集。关系代数式一中简洁的、形式化的语言，不适合于那些偶尔使用数据库系统的用户。因此，商用数据库系统采用有更多“语言修饰”的语言。元组关系演算和域关系演算使非过程化语言，代表了关系查询语言所需的基本能力。基本关系代数式一种过程化语言，在能力上等价于被限制在安全表达式范围内的关系演算的这两种形式。关系演算的简洁的、形式化的语言，并不适合于那些偶尔使用数据库系统的用户。数据库设计数据库设计与E-R模型数据库设计的最初阶段需要完整地刻画未来数据库用户的数据需求设计者选择数据模型，并采用所选数据模型的概念将这些需求转化为数据库的概念模式。在概念设计阶段所产生的模式提供了一个对企业的详细综述。完善的该你那模式还指明企业的功能需求。从抽象数据模型到数据库的实现的转化在最后两个设计阶段中进行逻辑设计阶段：将高层概念模式映射到将使用的数据库系统的实现数据模式上。物理设计简单：指明数据库的物理特征。在设计一个数据库模式时，需要确保避免两个主要缺陷：冗余、不完整。数据库设计主要涉及数据库模式的设计。实体-联系（E-R）数据库模型是一个广泛用于数据库设计的数据模型。提供了一个方便的图形化表示方法以查看数据、联系和约束。E-R模型主要用于数据库设计过程。它的发展是为了帮助数据库设计，这是通过允许定义企业模式实现的。这种企业模式代表数据库的全局逻辑结构，可以用E-R图形化表示。实体是在现实世界中存在并且区别于其他对象的对象。通过把每个实体同描述该实体的一组属性相关联来表示区别。联系是多个实体间的关联。相同类型的联系的集合为联系集，相同类型的实体的集合为实体集。每个属性都有一个可取值的集合，称为该属性的域，或者值集。术语超码、候选码以及主码同适用于关系模式一样适用于实体和联系集。映射的基数表示通过联系集可以和另一实体相关联的实体的个数。不具有足够属性构成的主码的实体集称为弱实体集。具有主码的实体集称为强实体集。E-R模型的各种性质为数据库设计者提供了大量的选择，使设计人员可以最好地表示被建模的企业。在某些情况下，概念和对象可以用实体、联系或属性来表示。企业总体结构的各方面可以用弱实体集、概化、特化或聚集很好地描述。设计者通常需要在简单的、紧凑的模型与更精确但也更复杂的模型之间进行权衡。用E-R图定义的数据库设计可以用关系模式的集合来表示。数据库的每个实体集和联系集都有唯一的关系模式与之对应，其名称即为相应的实体集或联系集的名称。这是从E-R图转换为关系数据库设计的基础。特化和概化定义了一个高层实体集和一个或多个低层实体集之间的包含关系。特花是取出高层实体集的一个子集来形成一个低层实体集。概化湿用两个或者多个不相交的（低层）实体集的并集形成一个高层实体集。高层实体集的属性被低层实体集继承。聚集是一种抽象，其中联系集（和它们相关的实体集一起）被看作高层实体集，并且可以参与联系。UML是一种常见的建模语言。UML类图广泛用于对类建模以及一般的数据建模。关系数据库设计冗余存储则存在不一致的风险。如果该域的元素被认为是不可分的单元，这个域是原子的。如果关系模式R的所有属性的域都是原子的，那么称R属于第一范式（1NF）。在许多含有复杂结构的实体域中，强制使用第一范式会给应用程序员造成不必要的负担。设计与开发时需要从当前业务考虑。一个关系的满足所有现实世界的约束的实例，称为关系的合法实例（满足业务要求的实例）。使用F+符号表示F集合的闭包，能够从给定F集合推导出所有函数依赖的集合。F+包含了F的所有函数依赖。具有函数依赖集F的关系模式R属于BCNF的条件是，对于F+中所有形如a-&gt;b的函数依赖（其中a与b都包含于R），下面至少一项成立：1、a-&gt;b是平凡的函数依赖（即b包含于a）；2、a是模式R的一个超码。一个数据库设计属于BCNF的条件是，构成该设计的关系模式集中的每种模式都属于BCNF。第三范式：对于F+中所有形如a-&gt;b的函数依赖（其中a，b都包含于R）以下至少一项成立：1、a-&gt;b是一个平凡的函数依赖；2、a是R的一个超码；3、b-a中的每个属性A都包含于R的一个候选码中（候选码是最小的超码，且任意子集都不是超码）。给定关系模式r(R)，如果r(R)的每一个满足F的实例都满足f，则R上的函数依赖f被r上的函数依赖F逻辑蕴涵。F的闭包是被F逻辑蕴涵的所有函数依赖的集合（F+）。函数依赖和多值依赖集为D的关系模式r(R)属于第四范式的条件是，对于D+中所有形如a–&gt;b的多值依赖（其中a和b都包含于R），以下至少一项成立：1、a–&gt;b是一个平凡的多值依赖；2、a是R的一个超码。应用设计和开发数据存储和查询存储和文件结构最快的存储介质（如高速缓冲存储器和主存储器）称为基本存储。层次结构中的基本存储介质的下一层介质（如磁盘）称为辅助存储或联机存储。层次结构中最底层的介质（如磁带机和自动光盘机）称为三级存储或脱机存储。易失性存储在设备断电后将丢失所有的内容。存储介质的可靠性由两个因素决定：1、电源故障或系统崩溃是否导致数据丢失；2、存储设备发生物理故障的可能性有多大。通过保留数据的多个拷贝，可以减少物理故障的可能性。对磁盘来说可以使用镜像技术。或者可以使用更复杂的基于独立磁盘冗余阵列（RAID）的方法。通过将数据拆分到多张磁盘上，可以提高大数据量访问的吞吐率；通过引入多张磁盘上的冗余存储，可以显著提高可靠性。可以把一个文件从逻辑上组织成映射到磁盘块上的一个记录序列。把数据库映射到文件的一种方法是使用多个文件，每个文件只存储固定长度的记录。另一种方法是构造文件。使之能适应多种长度的记录。分槽的页方法广泛应用于在磁盘块中处理变长记录。通过在多张磁盘上进行数据拆分来提高传速率。数据拆分最简单的形式是将每个字节按比特分开，存储到多个磁盘上。这种拆分称为比特级拆分。块级拆分是将块拆分到多张磁盘。磁盘系统并行有两个主要目的：1、负载平衡多个小的访问操作（块访问），以提高这种访问操作的吞吐量；2、并行执行大的访问操作，以减少大访问的响应时间。大对象常常存储到一个特殊的文件（或文件的集合）中而不是与记录的其他（短）属性存储在一起。然后一个指向该对象的（逻辑）指针存储到包含该大对象的记录中。顺序文件是为了高效处理按某个搜索码的顺序排序的记录而设计的。搜索码是任何的一个属性或者属性的集合。多表聚簇文件组织是一种在每一块中存储两个或者更多个关系的相关记录的文件结构。数据库系统的一个主要目的就是尽量减少磁盘和存储器之间传输的块数目。负责缓冲区空间分配的子系统称为缓冲区管理器。缓冲的是块而非数据。索引与散列数据库系统首先查找索引，找到相应记录所做的磁盘块，然后取出该磁盘块，得到所需的记录。如果包含记录的文件按照某个搜索码指定的顺序排序，那么该搜索码碎影的索引称为聚集索引。索引顺序文件是数据库系统中最古老的索引模式之一。为了允许按搜索码顺序快速检索记录，记录按顺序存储，而无序记录链接在一起。为了允许快速的随机访问，使用了索引结构。可以使用的索引类型有两种：稠密索引和稀疏索引。稠密索引对每个搜索码值都有索引项，而稀疏索引只对某些搜索码值包含索引项。利用稠密索引通常可以比稀疏索引更快地定位一条记录。但是，稀疏索引所占空间较小，并且插入和删除时所需的维护开销也较小。（折中方案：为每个块建一个索引项的稀疏索引）利用多级索引搜索记录与用二分法搜索记录相比需要的I/O操作要少得多。如果搜索码的排序序列和关系的排序序列相匹配，则该搜索码上的索引称为聚集索引，其他索引称为非聚集缩影或辅助索引。辅助索引可以提高不以聚集索引的搜索码作为搜索码的查询的性能。但是，辅助索引增加了修改数据库的开销（辅助索引必须是稠密索引，对每个搜索码值都有一个索引项，而且对文件中的每条记录都有一个指针）。候选码上的辅助索引看起来和稠密聚集索引没有太大区别，只不过索引中一系列的连续值执行的记录不是连续存放的。索引顺序文件组织的主要缺点是随着文件的增大，性能会下降。为了克服这个缺点，可以使用B+树索引。B+树索引采用平衡树的形式，即从树根到树叶的所有路径长度相等。B+树的高度与以关系中的记录数N为底的对数成正比，其中每个非叶子结点存储N个指针，N值通常约为50～100。因此，B+树比其他的平衡二叉树（比如AVL树）要矮喝多，故定位记录所需的磁盘访问次数也较少。B+树上的查询是直接而且高效的。然而插入和删除要更复杂一些，但是仍然很有效。在B+树中，查询、插入和删除所需的操作数与以关系中的记录数N为底的对数成正比，其中每个非叶子结点存储N个指针。可以用B+树去索引包含记录的文件，也可以用它组织文件中的记录。B树索引和B+树索引类型。B树的主要优点在于它去除了搜索码值存储中的冗余（当搜索码值唯一的情况下，只允许搜索码值出现一次）。主要缺点在于整体的复杂性以及节点大小给定时减小了扇出（直接连接下级个数，节点大导致扇出小，深度增加）。在实际应用中，系统设计者几乎无一例外的倾向于使用B+树索引。R树是B+树的扩展，用于处理在多个维度上的索引。覆盖索引存储一些属性（但不是搜索码属性）的值以及指向记录的职责。存储附加的属性值对于辅助索引是非常有用的，仅仅使用索引就能够回答一些查询，甚至不需要找到实际的记录。顺序文件组织需要一个索引结构来定位数据。相比之下，基于散列的文件组织允许我们通过计算所需记录搜索码值上的一个函数直接找出一个数据项的地址。由于设计时我们不能精确知道哪些搜索码值将存储在文件中，因此一个好的散列函数应该能均匀且随机地将搜索码值分散到各个桶中。静态散列所用散列函数和桶地址集合是固定的。这样的散列函数不容易适应数据库随时间的显著增长。有几种允许修改散列函数的动态散列技术。可扩充散列是其中之一，它可以在数据库增长或缩减时通过分裂或合并桶来应付数据库大小的变化。也可以用散列技术创建辅助索引：这样的索引称为散列索引。为使记法简便，假定散列文件组织中用户散列的搜索码上有一个隐式的散列索引。可扩充散列可以通过桶的分裂或合并来适应数据库的大小的变化。由于重组每次仅作用于一个桶，因此所带来的性能开销较低，可以接受。可扩充散列的最主要优点是其性能不随文件的增长而降低，其空间开销是最小的。缺点在于查找涉及一个附加的间接层。像B+树和散列索引这样的有序索引可以用作涉及单个属性且基于相等条件的选择操作。当一个选择条件中涉及多个属性时，可以取多个索引中检索到的记录标示符的交。对于索引属性只有少数几个不同值的情况，位图索引提供了一种非常紧凑的表达方式。位图索引的交操作相当得快，使得它成为一种支持多属性上的查询的理想方式（属性有限变量下）。查询处理对于一个查询，系统首先要做的事就是将之翻译成系统内部的表示形式。对于关系数据库系统而言，内部形式通常是基于关系代数的。在产生查询的内部形式的过程中，语法分析器检查用户查询语句的语法，验证出现在查询语句中的关系名是数据库中的关系名等。如果查询语句是用视图表达的，语法分析器把所有对视图名的引用替换成计算该视图的关系代数表达式。查询处理步骤：1、语法分析与翻译；2、优化；3、执行。加了“如何执行”注释的关系代数运算称为计算原语。用于执行一个查询的原语操作序列称为查询执行计划或者查询计算计划。查询执行引擎接受一个查询执行计划，执行该计划并把结果返回给查询。给定一个查询，通常有许多计算它的方法。将用户输入的查询语句转化成等价的、执行效率更高的查询语句，这是优化器的责任。优化器通常努力去尽可能降低查询计划总的资源消耗，而不是尽可能缩低响应时间。辅助索引存储的是B+树文件组织中作为码值的属性值。通过这种辅助索引存取一条记录的代价将更大：首先必须搜索辅助索引以找到主索引的搜索码值，然后查找主索引来找到记录。对于包含简单选择的查询语句，可以通过线性扫描或者利用索引来处理。通过计算简单选择结果的并和交，可以处理复杂选择操作。数据排序：1、SQL查询会指明对结果进行排序；2、当输入的关系已排序时，关系运算中的一些运算（如连接运算）能够得到高效实现。可以用外部归并排序算法对大内存的关系进行排序。设计自然连接的查询语句可以有多种处理方法，如果处理取决于是否有索引可用以及关系的物理存储形式。若连接的结果大小几乎和两个关系的笛卡尔积相当，可以采用嵌套循环连接策略较好。若存在索引，则可用索引嵌套循环连接。若关系已排序，则归并连接比较可取。在连接计算前对关系排序是有利的（为了能使用归并连接算法）。散列连接算法把关系划分成多个部分，使每个部分都能被内存所容纳。划分过程是通过连接属性上的散列函数来进行的，这样相应的划分对可以独立地进行连接。嵌套循环连接算法不要求有索引，并且不管连接的条件是什么，该算法均可以使用。块嵌套循环连接是以块的方式而不是以元组的方式处理关系，可以减少不少块读写次数。索引嵌套循环连接，可以在已有索引或者为了计算该连接而专门建立临时索引的情况下使用。归并连接算法（排序-归并-连接算法）可用于计算自然连接和等值连接。混合归并-连接算法把已排序关系与B+树辅助索引叶结点进行归并。散列连接算法可用于实现自然连接和等值连接，基本思想是把这两个关系的元组划分成连接属性值上具有相同散列值的元组集合。去除重复、投影、集合操作（并、交、差）、聚集操作都可以用排序和散列实现。外连接操作可以通过对连接算法的简单扩展来实现。散列与排序在某种意义下是对偶的。因为任何能用散列实现的操作（如去除重复、投影、聚集、连接、外连接）也可用排序来实现，反之亦然；即任何能用排序来实现的操作也能用散列实现。可以采用物化方法进行表达式的计算。系统计算每个子表达式的结果并将其存在磁盘上，然后用它进行父表达式的计算。流水线方法在子表达式产生输出的同时就在父表达式的计算中使用其输出结果，帮助我们避免了将许多子查询的结果写到磁盘的操作。由于去除重复的代价相对较大，因此SQL查询语言要求用户显示指明需要去除重复，若不指明则保留重复。每次计算的结果都被物化到一个临时关系中已备后用。这个方法的缺点是需要构造临时关系，这些临时关系必须写到磁盘上（除非很小）。减少临时文件数是通过将多个关系操作组合成一个操作的流水线来实现的，其中一个操作结果将传送到下一个操作。查询优化给定一个查询，一般有多种方法可以计算结果。系统负责将用户输入的查询转换成能够更有效执行的等价查询。为处理查询找出一个好的策略的过程称为查询优化。复杂查询的执行涉及多次存取磁盘的操作。由于从磁盘中传输数据相对于主存速度和计算机系统的CPU速度要慢，因此进行一定量的处理以选择一个能够从最小化磁盘存取的方法是完全值得的。查询执行计划的产生有三步：1、产生逻辑上与给定表达式等价的表达式；2、对所产生的表达式以不同方式作注释，产生不同的查询计划；3、估计每个执行计划的代价，选择估计代价最小的一个。有很多等价规则供我们用于将一个表达式转化成等价表达式。我们使用这些规则系统地产生与所给查询等价的所有表达式。（如果两个关系表达式在每一个有效数据库实例中都会产生相同的元组集，则我们称它们是等价的。）若一组等价规则中任意一条规则都不能由其他规则联合起来导出，称这组等价规则集为最小等价规则集。优化器采用两种关键思想可以极大地减少空间和时间上的开销：如果在子表达式e(i)上使用等价规则把表达式E1转化成E‘，则除了e(i)及其转换，E1与E‘有相同的子表达式。而且e(i)及其转换通常也有许多相同的子表达式。可以采用一些表达式表示技术，使两个表达式指向共享的子表达式，这样可以明显减少对空间的需求。不必总是用等价规则产生所有可以产生的表达式。如果考虑估计的执行代价，优化器可以避免检查某些表达式。每个关系代数表达式都表示某个特定的操作序列。选择查询处理策略的第一步就是找到一个关系代数表达式，使它与所给的表达式等价并且据估计有更小的执行代价。基于代价的优化器从给定查询等价的所有查询执行计划空间中进行搜索，并选择估计代价最小的一个。数据库系统为执行一个操作所选择的策略依赖于每个关系的大小和列值的分布情况。数据库系统可以为每个关系r存储统计信息，从而能够基于这些可靠信息选择适合的策略。这些统计信息包括：关系r中的元组数关系r中的一个记录（元组）的大小（按字节计数）关系r中的某个特定属性中出现的不同取值的数目许多数据库系统使用直方图来存储一个属性在每个区间上的取值个数。直方图通常采用取样来计算。这些统计信息使得我们可以估计各种操作的结果集的大小和执行操作的代价。当处理一个查询的过程中有多个索引可用于辅助的时候，关系的统计信息特别有用，这些信息对查询处理策略的选择有很大影响。物理等价规则允许将例如连接这样的逻辑操作转换成像散列连接或嵌套循环连接这样的物理操作。通过将这类规则添加到原来的等价规则中，程序可以产生所有可能的执行计划。对每个表达式，我们可以用一些等价规则产生多个可选的执行计划，然后从中选择代价最小的执行计划。不少优化技术可以减少需要产生的可选表达式和执行计划的数量。我们使用启发式方法来减少需要考虑的执行计划的数量，从而减少优化的代价。用于关系代数查询转换的启发式规则包括“尽早执行选择操作”、“尽早执行投影操作”、和“避免笛卡尔积操作”。用一个具有连接的查询（可能使用临时关系）去替代嵌套查询的过程称为去除相关。物化视图可以用来加速查询处理。当原关系发生修改时，需要用增量的视图维护来高效地更新物化视图。利用包含一个操作的输入的变化量的代数表达式，能够完成对该操作的变化量的计算。其他与物化视图相关的问题还包括如何借用物化视图进行查询优化和如何选择需要待物化的视图。查询优化器的工作应该包括知道何时可利用物化视图来提高查询处理速度。一些优化技术，包括top-K优化、连接极小化、更新优化、多查询优化和参数化查询优化。共享式扫描优化的工作方式如下：不是对于需要扫描一个关系的每一个查询，都从磁盘上重复地读取该关系，而是从磁盘上读取一次数据，然后流水线地传递给每一个查询。（一次读取，多次使用）如果最优计划受查询中的常数值影响不大，则通过计划缓存重用计划是合理的。然而如果计划受常数的影响，则可以使用参数化查询优化作为替代。事务管理事务指的是构建单一逻辑工作单元的操作的集合。事务事务时一个程序执行单位，它访问且可能更新不同的数据项。理解事物这个概念对于理解与实现数据库中的数据更新是很关键的，只有这样才能保证并发执行与各种故障不会导致数据库处于不一致状态。事务具有ACID特性：原子性、一致性、隔离性、持久性。原子性保证事务的所有影响在数据库中要么全部反映出来，要么根本不反应；一个故障不能让数据库处于事务部分执行后的状态。一致性保证若数据库一开始是一致的，则事务（单独）执行后数据库仍处于一致状态。隔离性保证并发执行提高了事务吞吐量和系统利用率，也减少了事务等待时间。持久性保证一旦一个事务提高后，它对数据库的改变不会丢失，即使系统可能出现故障。事务的并发执行提高了事务吞吐量和系统利用率，也减少了事务等待时间。计算机中不同存储介质包括异失性存储器、非易失性存储器和稳定性存储器。易失性存储器（例如RAM）中数据当计算机崩溃时丢失。非易失性存储器（如磁盘）中的数据在计算机崩溃时不会丢失，但是可能会由于磁盘崩溃而丢失。稳定性存储器中的数据永远不会丢失。为了一个事务能够持久，它的修改应该写入稳定性存储器。为了一个事务是原子的，日志记录需要在对磁盘上的数据库做任何改变之前写入稳定性存储器。必须支持在线访问的稳定性存储器与磁盘镜像或者其他形式的提供冗余数据存储的RAID接近。对于离线或归档的情况，稳定性存储器可以由存储在物理安全位置的数据的多个磁带备份所构成。撤销已提交事务所造成的影响的唯一方法是执行一个补偿事务。多个事务在数据库中并发执行时，数据的一致性可能不再维持。因此系统必须控制各并发事务之间的相互作用。由于事务时保持一致性的单元，所以事务的串行执行能保持一致性。调度捕获影响事务并发执行的关键操作，如read和write操作，而忽略事务执行的内部细节。我们要求事务集的并发执行所产生的任何调度的执行效果等价于由这些事务按某种串行顺序执行的效果。保证这个特性的系统称为保证可串行化。存在几种不同的概念，从而引出了冲突可串行化与视图可串行化的概念。事务并发执行所产生的调度的可串行化可以通过多种并发控制机制中的一种来加以保证。给定一个调度，我们可以通过为该调度构造优先图几搜索是否无环来判定它是否冲突可串行化。然而，有更好的并发控制机制可用来保证可串行化。调度必须时可恢复的，以确保：若事务a看到事务b的影响，当b中止时，a也要中止。（一个可恢复调度应该满足：对于每个事务T(i)和T(j)，如果T(j)读取了之前由T(i)所写的数据项，则T(i)先于T(j)提交。）调度最好是无级联的，这样不会由于一个事务的中止引起其他事务的级联中止。无级联性是通过只允许事务读取已提交数据来保证的。（因单个事务故障导致一系列事务回滚的现象称为级联回滚。（无级联调度=可恢复调度）可串行化：通常保证可串行化调度。可重复读：只允许读取已提交的数据，而且在一个事务两次读取一个数据项期间，其他事务不得更新该数据项。已提交读：只允许读取已提交数据，但不要求可重复读。未提交读：允许读取未提交数据。（脏读）所有隔离性级别都不允许脏写，即如果一个数据项已经被另一个尚未提交或者中止的事务写入，则不允许对该数据项执行写操作。数据库的并发控制管理部件复杂处理并发控制机制。快照隔离可以保证读数据的尝试永远无须等待，但带来的问题是提供了太多的隔离。如果事务多次运用之间数据库发生改变，那么即使是同一个事务，在多次不同运行中也可能会使用不同的数据项。并发控制当多个事务在数据库中并发执行时，数据的一致性可能不再维持。系统有必要控制各事务之间的相互作用，这是通过称为并发控制机制的多种机制中的一种来实现的。为保证可串行性，我们可以使用多种并发控制机制。所以这些机制要么延迟一个操作，要么中止发出该操作的事务。最常用的机制是多种封锁协议、时间戳排序机制、有效性检查技术与多版本机制。封锁协议是一组规则，这些规则阐明了事务何时对数据库中的数据项进行加速和解锁。两阶段封锁协议仅在一个事务未曾释放任何数据项上的锁时才允许该书屋封锁新数据项。该协议保证可串行化，但不能避免死锁。在没有关于数据项访问方式信息的情况下，两阶段封锁协议对于保证可串行性既是必要的又是充分的。两阶段封锁协议：要求每个事务分两个阶段提出加锁和解锁申请。增长阶段：事务可以获得锁，但不能释放锁。缩减阶段：事务可以释放锁，但不能获得新锁。严格两阶段封锁协议要求事务持有的所有排他锁必须在事务结束时方可释放，其目的是保证结果调度的可恢复性和无级联性，强两阶段封锁协议要求事务持有的所有锁必须在事务结束时方可释放。锁转换：提供一种将共享锁升级为排他锁，以及将排他锁降级为共享锁的机制。锁管理器可以实现一个过程，从事务接受消息并反馈消息。数据结构：为目前已加锁的每个数据项维护一个链表，每一个请求为链表中一条记录，按请求到达的顺序排序。当一个锁请求消息到达时，如果相应的数据项的链表存在，在该链表末尾增加一个记录；否则新建一个仅包含该请求记录的链表。在当前没有加锁的数据项上总是授予第一次加锁请求，但当事务向已被加锁的数据项申请加锁时，只有当该请求与当前持有的锁相容，并且所有先前的请求都已授予锁的条件下，锁管理器才为该请求授予锁，否则该请求只好等待。当锁管理器收到一个事务的解锁消息时，它将与该事务相对应的数据项列表中的记录删除，然后检查随后的记录，如果有，如前所述，就看该请求能否被授权，如果能，锁管理器授权该请求并处理气候记录，如果还有，类似地一个接一个处理。如果一个事务中止，锁管理器删除该事务产生的正在等待加锁的所有请求。一旦数据库系统采取适当动作撤销该事务，该中止事务持有的所有锁将被释放。基于图的封锁协议对访问数据项的顺序加以限制，从而不需要使用两阶段封锁还能够保证可串行性，而且又能够保证不会产生死锁。许多种封锁协议都不能防止死锁。一种可以防止死锁的方法是使用数据项的一种顺序，并且按与该顺序一致的次序申请加锁。另一种防止死锁的方法是使用抢占的事务回滚。为控制抢占，我们给每个事务赋予一个唯一时间戳，这些时间戳用于决定事务是等待还是回滚。如果一个事务回滚，它在重启时保持原有时间戳。wound-wait机制是一个抢占机制。如果没有预防死锁，系统必须用死锁检测与恢复机制来处理它们。为此，系统构造了一个等待图。当且仅当等待图包含环时，系统处于死锁状态。当一个检测算法判断死锁存在，系统必须从死锁种恢复。系统通过回滚一个或多个事务来解除死锁。某些情况下把多个数据项聚为一组，将它们作为聚集数据项来处理，其效果可能更好，这就导致了粒度的多个级别。我们允许各种大小的数据项，并定义数据项的层次，其中小数据项嵌套于大数据项之中。这种层次结构可以图形化地表示为树。封锁按从根结点到叶结点的顺序进行；解锁则按从叶结点到根结点的讯息进行。该协议保证可串行性，但不能避免死锁。时间戳排序机制通过事先对每对事务之间选择一个顺序来保证可串行性。系统中的每个事务对应一个唯一的固定时间戳。事务的时间戳决定了事务的可串行化顺序。这样，如果事务T(i)的时间戳小于事务T(j)的时间戳，则该机制保证产生的调度等价于事务T(i)出现在事务T(j)之前的一个串行调度。该机制通过回滚违反该次序的事务来保证这一点。在大部分事务时只读的情形下，冲突频率很低，这种情况下有效性检查机制是一个适当的并发控制机制。系统中的每个事务对应一个唯一的固定时间戳。串行性次序是由事务的时间戳决定的。在该机制中，事务不会延迟。不过，事务要完成必须通过有效性检查。如果事务未通过有效性检查，则该事务回滚到初始状态。有效性检查协议要求每个事务T(i)在其生命周期中按两个或三个阶段执行，这取决于该事务时一个只读事务还是一个更新事务。读阶段：系统执行事务T(i)。各数据项值被读取并保存在事务T(i)的局部变量中。所有的write操作都是对局部临时变量进行的，并不对数据库进行真正的更新。有效性检查阶段：对事务T(i)进行有效性测试。判断是否可以执行write操作而不违反可串行性。如果事务有效性测试失败，则系统终止这个事务。写阶段：若事务T(i)已通过有效性检查，则保存T(i)任何写操作结果的临时局部变量值被复制到数据库中。只读事务忽略这个阶段。多版本并发控制机制基于在每个事务写数据项时为该数据项创建一个新版本。读操作发出时，系统选择其中的一个版本进行读取。利用时间戳，并发控制机制保证按确保可串行性的方式选取要读取的版本。读操作总能成功。在多版本时间戳排序中，写操作可能引起事务的回滚。在多版本的两阶段封锁中，写操作可能导致封锁等待或者死锁。快照隔离时一种基于有效性检验的多版本并发控制协议，与多版本两阶段封锁协议不同，它不需要将事务声明为只读或更新的。快照隔离不保证可串行化，但是许多数据库系统仍然支持它。仅当要删除元组的事务在该元组上具有排他锁时，delete操作才能够进行。数据库中插入新元组的事务在该元组上被授予排他锁。插入操作可能导致幻象现象，这是插入操作与查询操作发生逻辑冲突，尽管两个事务可能没有存取共同的元组。如果封锁仅加在事务访问元组上，这种冲突就检测不到。关系中用于查找元组的数据需要加锁，索引封锁技术要求对某些索引结点加锁来解决这个问题。所加的锁保证所有事务在实际的数据项上发生冲突，而不是在幻象上。索引封锁协议运作如下：每个关系至少有一个索引。只有首先在关系的一个或多个索引上找到元组后，事务T(i)才能访问关系上的这些元组。为了达到索引封锁协议的目的，全表扫描看作一个索引上所有叶结点的扫描。进行查找（不管区间查找还是点查找）的事务T(i)必须在它要访问的所有索引叶结点上获得共享锁。在没有更新关系r上的所有索引之前，事务T(i)不能插入、删除或更新关系r中的元组t(i)。该事务必须获得插入、删除或更新所影响的所有索引叶结点上的排他锁。对于插入和删除，受影响的叶结点时那些（插入后）包含或（删除前）包含元组搜索码值的叶结点。对于更新，受影响的叶结点时那些（修改前）包含搜索码旧值的叶结点，以及（修改后）包含搜索码新值的叶结点。元组照常获得锁。必须遵循两阶段封锁协议规则。弱级别的一致性用于一些应用中，在这些应用中，查询结果的一致性不是至关重要的，而使用可串行性会使查询对事务的处理起反作用。二级一致性是这种弱级别的一致性之一，游标稳定性是二级一致性的一个特例，而且已被广泛应用。游标稳定性保证：正被迭代处理的元组被加上共享锁。任何被更改的元组被加上排他锁，直至事务提交。跨越用户交互的事务并发控制是一个有挑战性的任务。应用程序通常实现一种基于采用元组中存储的版本号来验证写操作的机制。这种机制提供了弱可串行化水平，而且可以实现在应用层，而无需修改数据库。可以为特殊的数据结构开发特色的并发控制技术。通常，特色的技术用到B+树上，以允许较大的并发性。这些技术允许对B+树进行非可串行化访问，但它们保证B+树结构是正确的，并保证对数据库本身的存取是可串行化的。恢复系统数据库系统的一个重要组成部分就是恢复机制，它负责检测故障以及将数据库恢复至故障发生前的某一状态。恢复机制必须提供高可用性，必须将数据库崩溃后不能使用的时间缩减到最短。计算机中的各种存储器类型有易失存储器、非易失存储器和稳定存储器。易失存储器（如RAM）中的数据在计算机发生故障时会丢失。非易失性存储器（如磁盘）中的数据在计算机发生故障时一般不丢失，只是偶尔由于某些故障如磁盘故障才会丢失。稳定存储器中的数据从不丢失。必须能联机访问的稳定存储器用镜像磁盘或RAID的其他形式模拟，它提供冗余数据存储。脱机或归档稳定存储器可能是数据的多个磁带备份，并存放在物理安全的地方。一旦故障发生，数据库系统的状态可能不再一致，即它不能反映数据库试图保存的显示世界的状态。为保持一致性，我们要求每个事务都必须是原子的。恢复机制的责任就是要保证原子性和持久性。在基于日志的机制中，所有的更新都记入日志，并存放在稳定存储器中。当事务的最后一个日志记录，即该事务的commit的日志记录。输出到稳定存储器时，就认为这个事务已提交。日志记录包括所有更新过的数据项项的旧值和新值。当系统崩溃后需要对更新进行重做时，就使用新值。如果在正常操作中事务中止，回滚事务所做的更新时需要用到旧值；在事务提交之前发生系统崩溃的情况下，回滚事务所做的更新也需要用到旧值。在演出修改机制下，事务执行时所有write操作都要延迟到事务提交时才执行，那时，系统在执行延迟写中会用到日志中与该事务有关的信息。在延迟修改机制中，日志记录不需要包含已更新的数据项的旧值。为减少搜索日志和重做事务的开销，我们可以使用检查点技术。（a）在执行检查点操作的过程中不允许执行任何更新，（b）在执行检查点的过程中将所有更新过的缓冲块都输出到磁盘中。检查点执行过程如下：1、将当前位于主存的所有日志记录输出到稳定存储器；2、将所有修改的缓冲块输出到磁盘；3、将一个日志记录输出到稳定存储器，其中L是执行检查点时正活跃的事务的列表。当前恢复算法基于重复历史的概念，在恢复的重做简单重演（自最后一个已完成的检查点以来）正常操作中所做的所有动作。重复历史的做法将系统状态恢复到系统崩溃之前的最后一个日志记录输出到稳定存储器时的系统状态。然后从这个状态开始执行一个撤销阶段，反向处理未完成事务的日志记录。不完全事务的撤销写出特殊的redo-only日志记录和一个abort日志记录。然后就认为该事务已完成，不必再对它进行撤销。在事务处理所基于的存储模型中，主存储器中有一个日志缓冲区，一个数据库缓冲区和一个系统缓冲区。系统缓冲区中有系统目标码页面和事务的局部工作区域。恢复机制的高效实现需要尽可能减少向数据库和稳定存储器写出的数目。日志记录在开始时可以保存在易失性的日志缓冲区中，但是当下述情况之一发生时必须写到稳定性存储器中：在&lt;T(i), commit&gt;日志记录可以输出到稳定存储器之前，在事务T(i)相关的所有日志记录必须已经输出到稳定存储器中。在主存中的一个数据库输出到（非易失性存储器中的）数据库之前，与该块中的数据相关的所有日志记录必须已经输出到稳定存储器中。当前的恢复技术支持高并发性封锁技术，例如用户B+树并发控制的封锁记录。这些技术允许提前释放通过插入或删除这样的操作获得的低级别的锁，低级别的锁允许别的事务其他的这些操作可以执行。低级别的锁被释放之后，不能进行物理undo，而需要进行逻辑undo，例如，用删除来对一个插入操作undo。事务保持高级别的锁以确保并发的事务不会执行这样的动作，它可能导致一个操作的逻辑undo是不可能的。为从造成非易失性存储器中数据丢失的故障中恢复，我们必须周期性地将整个数据库的内容转储到稳定存储器中–例如每天一次。如果发生了导致物理数据库块丢失的故障，我们使用最近一次转储将数据库恢复至前面的某个一致状态。一旦完成该恢复，我们再用日志将数据库系统恢复至最当前的一致状态。ARIES恢复机制支持一些提供更大并发性，削减日志开销和最小化恢复时间的特性。它也是基于重复历史的，并允许逻辑undo操作。该机制连续不断地清洗页，从而不需要检查点时清洗所有页。它使用日志顺序号（LSN）来实现各种优化从而减少恢复所花的时间。从系统崩溃中恢复的过程经历三个阶段：1、分析阶段：决定哪些事务要撤销，哪些页在崩溃时时脏的，以及重做阶段应从哪个LSN开始；2、redo阶段：从分析阶段决定的位置开始，执行重做，重复历史，将数据库恢复到发生崩溃前的状态；3、undo阶段：回滚在发生崩溃时那些不完全的事务。远程备份系统提供了很高程度的可用性，允许事务处理即使在主站点遭受火灾、洪水或地震的破坏时也能继续。主站点上的数据和日志记录连续不断地备份到远程备份站点。如果主站点发生故障，远程备份站点就执行一定的恢复动作，然后接管事务处理。系统体系结构数据库系统体系结构集中式数据库系统完全运行在单台计算机上。随着个人计算机和局域网的发展，数据库前端功能不断移向客户机，而后端功能由服务器系统提供。客户-服务器接口协议推动了客户-服务器数据库系统的发展。服务器可以是事务服务器，也可以是数据服务器。尽管在提供数据库服务方面，事务服务器的使用大大超过数据服务器的使用。事务服务器有多个进程，可能运行在多个处理器上。所以这些进程要访问公共数据，比如数据库缓冲区，系统将这些数据存放在共享内存中。除了处理查询的进程，还有执行诸如锁和日志管理以及检查点等任务的系统进程。数据服务器系统提供给用户的是为加工的数据。这样的系统通过把数据和锁高速缓存在客户端，来努力使客户端和服务器之间的通信最小化。并行数据库系统使用类似的优化。并行数据库系统由通过高数互联网连接在一起的多台处理器和多张硬盘构成。加速比衡量通过增加并行性可以得到的对单个事务的处理数据的增长。扩展比衡量通过增加并行性可以的带的处理大量事务的能力。干扰、偏斜和启动代价是得到理想的加速比和扩展比的障碍。并行数据库系统结构包括共享内存、共享硬盘、无共享以及层次的体系结构。这些体系结构在可扩展性以及通信速度方面各有千秋。共享内存的优点在于处理器之间的通信效率极高，存放在共享内存中的数据可以被任何处理器访问，而不需要由软件来移动。共享内存机器的缺点是这种体系结构的规模不能超过32个或64个处理器。因为总线或互联网络会变成瓶颈（因为它是所有处理器共享的）。共享硬盘体系结构有两个优点：1、由于每个处理器都有自己的主存储器，因此存储器总线不再是瓶颈了；2、这种体系结构给出了一个经济的方法来提供一定程度的容错性（如果一个处理器或者它的主存储器发生故障，其他处理器可以代替它的工作，这是因为数据库驻留在磁盘上，而磁盘是所有处理器都可以访问的）。虽然存储器总线不再是瓶颈，但与磁盘子系统互连现在成为了瓶颈。无共享提供的主要缺点是通信的代价和非本地磁盘访问的代价，这些代价比共享内存或共享硬盘体系结构中的代价要高，因为数据传送涉及两端的软件交互。层次的体系结构综合了共享内存、共享硬盘和无共享体系结构的特点。分布式数据库系统是部分独立的一组数据库系统，它们共享一个公共模式（理想情况下），并且协调地处理访问非本地数据库的事务。系统之间通过通信网络来相互通信。局域网连接分布在小的地理范围内的结点，比如连接单个建筑或几个相邻建筑。广域网连接分布在大的地理范围内的结点。现在Internet是使用最广泛的广域网。存储区域网是一种特殊形式的局域网，是为大型存储设备和多台计算机之间提供快速互连而设计的。并行数据库在I/O并行中，把关系划分到多张可用的磁盘中，从而使检索速度更快。三种常用的划分技术使轮转法划分，散列划分和范围划分。（一般而言，更倾向于使用散列划分和范围划分，而不是轮转法划分）轮转法：适合于希望对每个查询顺序地读取整个关系的应用。散列划分：适合于机遇划分属性的点查询。范围划分：适合于在划分属性上的点查询和范围查询。偏斜式一个主要的问题，特别是当并行度增高时。平衡的划分向量、使用直方图以及虚处理器划分是用于减少偏斜的技术。属性值偏斜指的是某些值出现在许多元组的划分属性中。划分偏斜指的是，即使不存在属性值偏斜，划分也可能会出现负载不均衡。通过为每个关系的每个属性创建和存储该属性值的频率表或直方图，可以降低由于构建平衡的范围划分向量而产生的I/O开销。使用虚处理器，特别是针对范围划分带来的偏斜，可以使偏斜的影响达到最小。核心思想是：即使由于偏斜使得在一个范围内有比其他范围更多的元组，这些元组也将划分到多个虚处理器的范围上。在查询间并行中，并发地运行不同的查询以提高吞吐量。共享磁盘系统中协议保证，当事务对页面设置共享锁或排查锁时，能够得到该页面的正确版本：1、事务对一个页面进行任何读或写访问之前，先用相应的共享或排他模式封锁该页面。一旦事务获得了页面的共享锁或排他锁后，它立刻从共享磁盘中读取该页面的最新版本；2、在事务释放一个页面的排他锁之前，它将该页面刷新到共享磁盘中，然后释放锁。查询内并行指的是单个查询在多个处理器和磁盘上并行执行，试图减少运行查询的代价。两类查询内并行：1、操作内并行，通过并行地执行每一个运算来加快一个查询的处理速度；2、操作间并行，通过并行地执行一个查询表达式中的多个不同的运算，来加快一个查询的处理速度。采用操作内并行来并行地执行关系运算，例如排序和连接。因为关系运算是面向集合的，所以操作内并行对关系运算是很自然的。对于像连接这样的二元运算，有两种基本的并行化的方法（这两种并行技术都可以与任何一种连接技术结合使用）：在基于划分的并行中，两个关系分成几个部分，而且r(i)中的元组仅与s(i)中的元组进行连接。基于划分的并行仅适用于自然连接和等值连接。在分片和复制中，两个关系都被划分，并且每个划分都被复制。在非对称的分片和复制中，一个关系被复制，而另一个关系被划分。与机遇划分的并行不同，分片和复制以及非对称的分片和复制对于任何连接条件都是用。在独立的并行中，互不依赖的多个不同的操作按并行方式执行。在流水线并行中，处理器在计算一个操作结果的同时将结果发送给另一个操作，无须等待整个操作的完成。两个常用启发式方法来减少需要考虑的并行执行计划的数目：仅考虑那些利用所有的处理器，对每个运算都并行化，并且不采用任何流水线的执行计划。选择最搞笑的串行执行计划，然后将该执行计划中的运算并行化。分布式数据库分布式数据库系统由站点的集合构成，每个站点维护一个本地数据库系统。各个站点能够处理局部事务：这些事务访问的数据仅位于该单个站点上。此外，站点可以参与到全局事务的执行中：这些全局事务访问多个站点上的数据。全局事务的执行需要在站点之间进行通信。分布式数据库可能是同构的，其中所有站点拥有共同的模式和数据库系统代码，或者是异构的，其中模式和系统代码可能不同。关于在分布式数据库中存储关系涉及几个问题，包括复制和分片。系统应尽量减小用户需要了解关系如何存储的程度。水平分片：通过将r的每个元组分给一个或多个分片来划分关系垂直分片：通过对关系r的模式R进行分解来划分关系数据透明性：分片透明性：用户不要求知道关系是如何分片的复制透明性：在用户看来，每个数据对象逻辑上都是唯一的。分布式系统可能为了提高系统性能或者数据可用性而复制对象，用户不必关系什么数据对象被复制了，也不必关系副本存放在何处。位置透明性：用户无须知道数据的物理位置。只要用户事务提供数据标示符，分布式数据库系统应能够找到任何数据。局部事务是那些只在一个局部数据库中访问和更新数据的事务；全局事务是那些多个局部数据库中访问和更新数据的事务。每个站点都有其自身的局部事务管理器，其功能是保证在该站点上执行的那些事务的ACID特性。各个事务管理器相互协作以执行全局事务。事务管理器：管理那些访问存储在一个局部站点中的数据的事务（或子事务）的执行。注意每个这样的事务既可以是局部事务也可以是全局事务的一部分。维护一个用于恢复目的的日志参与到一个合适的并发控制方案，以协调在该站点上执行的事务的并发执行事务协调器：协调在该站点上发起的各个事务的执行。启动事务的执行将事务分成一些子事务，并将这些子事务分派给合适的站点去执行协调事务的中止，这可能导致事务在所有站点上都提交或者所有站点上都中止分布式系统可能遭受与集中式系统相同类型的故障。但是，分布式环境中还有另外一些需要处理的故障，包括站点故障、链路故障、消息丢失以及网络划分。在分布式故障恢复模式的设计中需要考虑每个这样的问题。为了保证原子性，执行事务T的所有站点必须在执行的最终结果上取得一致。T要么在所有站点上提交，要么在所有站点上中止。为了保证这一特性，T的事务协调器必须执行一种提交协议。使用最广泛的提交协议是两阶段提交协议。两阶段提交协议可能导致阻塞，在这种情况下，事务的命运必须等到故障站点（协调器）恢复后才能确定。为了减少阻塞的可能性，可以使用三阶段提交协议。持久消息为分布式事务处理提供了一种可选模式。该模式将单个事务拆分成在不同数据库执行的多个部分。持久消息（无论是否发生故障。都保证正好只传送一次）被传送到需要采取动作的远程站点。虽然需要持久消息避免阻塞问题，但是应用程序开发者必须编写代码来处理各种类型的故障。在集中式系统中使用各种并发控制方案修改后可用于分布式环境。就封锁协议而言，须做的唯一改变是锁管理器的实现方式。可以采用一个或多个中央协调器。如果拆用分布式锁管理器，复制数据就必须特殊对待。处理已复制数据的协议包括主副本协议、多数协议、有偏协议和法定人数同意协议。它们在开销方面和发生故障时工作的能力方面各有不同的取舍权衡。就时间戳和有效性演奏方案而言，所需的唯一修改是开发一种产生全局唯一性时间戳的机制。许多数据库系统支持延迟复制，其中更新被传播到执行更新的事务的范围之外的副本。这样的工具必须小心使用，因为他们可能导致不可串行化的执行。分布式锁管理器环境中的死锁检测需要多个站点之间的合作，因为甚至在没有局部死锁的情况下也可能有全局死锁。为了提高可用性，分布式诗句哭必须检测故障，重构系统以使计算机能够继续进行，并在处理器或链路修复之后能够恢复。由于要在网络划分和站点股掌之间进行区分是很困难的，因此这个任务就变得非常复杂。通过使用版本号，可以对多数协议进行扩展使其即使存在故障的情况下仍允许进行事务处理。虽然该协议代价昂贵，但它无论在何种类型的故障下都能工作。可以使用较小代价的协议来处理站点故障，但是它们艰涩不会发生网络划分。一些分布式算法需要使用协调器。为了提供高可用性，系统必须维护一个准备好的在协调器故障时能继续其支者的备份副本。另一种方法是在协调器发生故障后选出新的协调器。确定哪个站点应该作为协调器的算法称为选举算法。分布式数据库上的查询可能需要访问多个站点。可以使用集中优化技术来识别需要访问的最佳站点集。查询可以依据关系的分片来自动重写没然后可以在每个分片的副本之间做出选择。可以应用半连接技术减少跨不同站点的关系（或相应的分片或副本）连接中所涉及的数据传输。异构分布式数据库允许站点有它们自己的模式和数据库系统代码。多数数据库系统提供了一种环境，在其中新的数据库应用可以访问位于多重易购软硬件环境的各个先前存在数据库中的数据。局部数据库系统可以采用不同的逻辑模型以及数据定义和数据操纵语言，并且可以在它们的并发控制和事务管理机制上存在差别。多数据库系统虚拟了逻辑上的数据库集成，不需要物理上的数据库集成。为了响应超大规模Web应用对数据存储的需求，近年来在云上构建了大量数据存储系统。这些数据存储系统允许扩展到地里上分布的数千个结点上，而且具有高可用性。然而，它们并不支持通常的ACID特性，而且在划分时以副本一致性为代价来获得可用性。目录系统可视为一何总特殊形式的数据库，其中信息按照一种分层的方式组织，类似于文件系统中文件的组织方式。目录通过标准化目录访问协议（例如LDAP）来访问。目录可以分布到多个站点上来提供各个站点的自治。目录可以包含对其他目录的引用，这有助于建立集成视图，借此查询被发送给单个目录，并且在所有相关的目录上透明地执行。数据仓库、数据挖掘和信息检索数据仓库与数据挖掘数据仓库是从多个数据源种进行数据采集，并以一种共同的、统一的数据库模式进行存储的数据仓储。存放在数据仓库中的数据将用于各种复杂聚集和统计分析。决策支持系统分析由事务处理系统收集的在线数据，以帮助人们做出商业决策。由于现在大多数组织结构都进行了广泛的计算机化，因此有非常大量的信息可用于决策支持。决策支持系统有不同的形式，包括OLAP系统和数据挖掘系统。数据仓库有助于收集和归档重要的操作数据。数据仓库用于基于历史数据的决策支持和分析，例如趋势预测。对来自输入数据源的数据进行清理通常是数据仓库中的一项重要任务。数据仓库的模式一般是多维的，包括一个或一些非常大的事实表以及几个小得多的维表。在很多数据仓库应用程序中，面向列的存储系统能提供良好的性能。数据挖掘是一个能半自动地分析大型数据库以找出有用的模式的过程。数据挖掘的引用有许多，比如基于以往示例的数值预测，购买行为关联的发现，以及人和电影的自动聚类。分类处理的事：基于训练用例的属性和训练用例实际所属的类，通过利用测试用例的属性来预测测试用例所属类。分类器类型有很多种：决策树分类器。这种分类器通过基于训练用例所构造的一棵树来执行分裂，该树的叶节点具有类别标签。对每个测试用例遍历这棵树以找到一个叶节点，该叶节点所属的类即是预测的类。有几种技术可用于构造决策树，其中大部分是基于贪心的启发式方法。贝叶斯分类器放入构造比决策树分类器更简单，并且在属性值缺失或为空的情况下工作得更好。支持向量机是另一种广泛应用的分类技术。关联规则识别经常同时出现的项，比如同一位孤苦可能购买的一些商品。相互关联找出与期望关联等级的偏离。其他类型的数据挖掘包括聚类、文本挖掘和数据可视化。信息检索信息检索系统用于存储和查询如文档那样的文本数据。与数据库系统相比，它们使用更将蛋的数据模型，但能够在首先的模型里提供更强大的查询能力。查询试图通过指定关键字集合来定位用户感兴趣的文档。用户心里所想的查询往往不能精确的表述，因此，信息检索系统基于潜在的相关性对答案的排名。相关性排名利用多种类型的信息。1、术语频率：每个术语对美分文档的重要性；2、逆文档频率；3、流行度排名。文档相似性用于检索与一个示例文档相似的文档。余弦度量值用于定义相似度，它基于向量空间模型。PageRank和链接中心/权威页排名是基于指向页面的链接对页面威望度赋值的两种方法。PageRank度量可以用随机游走模型来直观地理解。锚文本信息也可以用来计算单个关键字意义上的流行度。信息检索系统需要整合多种因素（包括TF-IDF和PageRank）来获得对页面的全局评分。搜索引擎作弊试图使一个页面得到高的（但不是应得的）排名。同义词和多义词使信息检索的任务复杂化。基于概念的查询旨在找到含有指定概念的文档，而与指定该概念所使用的确切的词（以及语言）无关。本体利用诸如is-a或者part-of这样的关系将概念联系起来。倒排索引用来对关键字查询做出应答。查准率和查全率是信息检索系统有效性的两种度量。Web搜索引擎使用爬虫搜索Web找到网页，然后分析它们以计算其威望度度量，并为它们建立索引。目录结构和分类用来将文档和其他相似的文档归类到一起。特种数据库基于对象的数据库XML高级主题高级应用开发调整数据库系统参数和更高级别的数据库设计（如模式、索引和事务）对于实现高性能至关重要。查询可以进行调整以提高集合面向性，而批量加载功能可以大大加快数据导入到数据库中的速度。调整的最好方法就是确定瓶颈所在，然后消除瓶颈。数据库系统通常有多种可调参数，如缓冲区大小、内存大小和磁盘数量。可以选择适当的缩影和物化试图集合，以使总体代价达到最小。可以调整事务使锁竞争达到最小。快照隔离和支持早起锁释放的序号编号功能是减少读写和写写竞争的有用工具。性能基准程序在对数据库系统进行比较方面扮演了重要的角色，尤其在数据库系统变得越来越与标准兼容时。TPC基准程序集使用广泛，不同的TPC基准程序可以用于不同的工作负载下的数据库系统性能比较。应用程序在开发时和部署前需要进行大量大测试。测试用来捕获错误的，以及确保到达性能目标。遗产系统是基于老一代技术（如非关系数据库或甚至直接基于文件系统）的系统。当运行关键人物系统时，遗产系统与新一代系统之间的连接通常是很重要的。从遗产系统到新一代系统的移植必须非常小心以避免破坏，这种移植是非常昂贵的。由于数据库系统的复杂性和互操作的需要，标准对数据库系统来说很重要。SQL有其正式标准。事实标准（如ODBC和JDBC）和被行业组织所采纳的标准（如CORBA），在客户-服务器数据库系统的发展中发挥了重要作用。时空数据和移动性存储关于真实世界的时间经历状态的信息的数据库叫做时态数据库。时态关系中的事实与当它们有效时的时间相关联，而时间可以用时段的并来表示。时态查询语言简化了时间建模以及与时间相关的查询。设计数据主要以矢量数据的形式存储；地理数据包含矢量数据和光栅数据的结合。空间完整性约束对于设计数据库十分重要。光栅数据由二维或更高维的位图或像素图组成。矢量数据由基本集合对象构成，如点、线段、折线、三角形和其他二维多边形，以及圆柱体、球体、立方体和其他三维多面体。矢量数据库可以编码成第一范式，或者用非第一范式结构来存储，如列表。专用索引结构对于访问空间数据和处理空间查询尤为重要。R树是B树的多维扩展；它和它的变体（如R+树和R*树）在空间数据库中得到了广泛的应用。将空间以某种固定方式进行划分和索引结构（如四叉树）有助于处理空间连接查询。高级事务处理实例研究PostgreSQLOracleIBM DB2 Universal DatabaseMicrosoft SQL Server]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>DB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【笔记】领导力21法则]]></title>
    <url>%2F2020%2F04%2F20%2F%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91%E9%A2%86%E5%AF%BC%E5%8A%9B21%E6%B3%95%E5%88%99%2F</url>
    <content type="text"><![CDATA[盖子法则：领导力决定一个人或一个组织的办事效率领导力决定了成就的高度。相对外界施加更大的影响，就必须具备更大的影响力。要想改变一个组织的发展方向，那就换一个领导人。个人和组织的办事效力与领导力成正比。领导力主要体现在：人际交往能力；规划能力和战略思维；远见卓识；业绩。影响力法则：衡量领导力的真正尺度是影响力领导力的本质恰恰就是影响力。真正的领导力来自一个人的影响力，而影响力是无法被委任的。管理者不是领导者。领导是指影响他人，让他人追随自己，而管理关注的焦点是维持既定系统和流程。管理者把握既定的前进方向，无法改变这个方向。领导者负责带领方向。要成为领导者，一个人不仅要走在前面，还要有人愿意跟着他走，愿意服从他的领导，并且愿意采取行动去实现他描绘的愿景。不是职位造就了领导者，而是领导者造就了职位。衡量领导力的真正尺度只能是影响力，不可能是其他任何因素。所有影响力的本质都在于让别人参与其中。过程法则：领导力的提升是日积月累的结果，而非一日之功领导者都是善于学习的人。自我发展和不断提升自身的技能水平，这正是领导者和其追随者的最本质的区别。领导力提升的几个阶段：不知道你不知道（不知道领导力的价值与重要性）；知道自己需要知道；知道自己不知道；我知道，我成长，我发现（努力成长）；因为我知道（时刻做好准备，等待机会的到来）。导航法则：谁都可以掌舵，唯有领导者才能设定航线领导者就是看得比别人过，看得比别人远，在别人看到之前看到的人。导航者会依靠过去的经验；导航者在作出承诺前会考察各种情况；导航者会听从他人的意见；导航者会确定自己的结论是信念和事实的结合。完成事件的预先计划：预先制定行动计划列出目标设定优先次序告知关键人物预留时间征得同意开始行动预测将会出现的问题始终明白成功的方向每日对计划进行回顾增值法则：领导者为他人提升价值光想给自己邀功是不行的，因为一个组织的成功来自众人的共同努力。领导力的底线不在于我们自己能够走多远，而在于我们能够让别人走多远。为他人增加价值的三种基本方针：当真正重视他人的时候，我们增加了他人的价值；当使自己成为更加令人敬佩的人时，我们增加了他人的价值；当知道别人重视什么并且努力做到时，我们增加了他人的价值。没有经验的领导者往往在了解他们将要领导的人之前就急于开始工作，而成熟的领导者会去倾听、了解，然后再开展工作。优秀领导力的重要因素之一：与其他人没有尚未解决的关系矛盾。根基法则：信任是领导力的根基所在重要的不是决定，而是领导力。在领导方式上，无论你领导他们多久了，你都不能走捷径。要赢得信任，领导者必须表现出工作能力、亲和力和性格优势。品格是信任的根基，而信任是领导力的根基。这就是根基法则。品格彰显潜力。品格彰显尊重。领导者如何赢得尊重呢？通过做出英明决策，承认自己的错误，把追随者和组织的利益放在个人利益之前。领导人的优秀品质能够赢得追随者的信任。但如果一个领导者破坏了这种信任，那么他就丧失了领导的能力。没有一位领导者能够在失去追随者的信任之后仍然保持自己对他们的影响力。信任是领导力的根基。违反了根基法则，作为领导人的影响就会减弱。尊重法则：人们通常愿意追随比自己强的领导者一个人的领导力越强，就能越快发现别人的领导力潜质，或者发现别人领导力的不足。领导者赢得别人的尊敬的最重要的六个方面：1、天生的领导才能；2、尊重他人（如果坚持尊重他人，始终如一地好好领导他们，你就会一直拥有追随者）；3、勇气（作为领导者，除非他愿意偶尔孤军奋战，否则就是名不副实的）；4、成功（即领导者在某个领域的成功）；5、忠诚；6、为他人增加价值。领导力的衡量标准之一就是选择追随者的才干。直觉法则：领导者善用领导直觉评估每件事情每个人自己善长的直觉。领导者是当前情况的考察者。领导者是动向的考察者。领导者是自身资源的考察者（想要获取成功的领导者要最大限度地利用每一份资产和资源，从而实现整个组织的利益）。领导者是他人的考察者（读懂别人也许是领导者应该具有的最重要的直觉能力）。领导者是自身的考察者（领导者必须了解的不仅仅是自己的优势和弱势、能力和缺点，还有自己当前的心理状态）。思考一下问题：谁是负责这个问题的最佳人选？我们拥有何种资源能够帮助自己？解决这一问题需要多少资金？我们如何激励团队成员取得成功？吸引力法则：你只能吸引和你相似的人你所吸引的人不是由你的愿望决定的，而是由你的为人决定的。团队“必然”成为领导者个性的延伸。亲和力法则：领导者深知，得人之前必先得其心优秀的领导者总是设法与别人建立亲和力，不论他们是整个组织作为交流还是与单独的个人共事。与追随者的关系和感情越牢固，他们就越可能会去帮助领导者。在人群中建立亲和力的秘诀就是把他们当作不同的个体来看待。如何建立亲和力：展现真我坦率真诚了解对象身体力行身临其境（适应他人，而不是指望别人来适应我）关注他们，而不是你自己信任他人（向别人传达信息与和别人沟通不同。前者是因为你相信自己会说出一些有价值的话，后者是因为你相信他们有价值）主动与别人建立亲善关系，这就是领导者的职责。别人不会在乎你知道多少，除非他们知道你多么在乎他们。引领自己，要用脑；引领别人，要用心。核心圈法则：一个领导者的潜力，由最接近他的人决定只有在你发挥出作为领导者的潜力后，你的追随者才有机会发挥他们的潜力。考虑人选是否应当进入你的核心圈：他们对其他人是否有很大影响他们能否给团队带来互补性的才能他们在团队里是否担任要职他们能否增加我和团队的价值他们能否给核心圈的其他成员带来积极性的影响授权法则：有安全感的领导者才会授权予人最好的主管懂得找到人才来做好计划的工作，而且又能克制自己在过程中不横加干涉。成功的领导不是关乎充实自己——而是关乎授权给他人。人才是否能发挥潜能，决定于领导者的授权能力。授权的障碍：渴望工作上的安全感抗拒改变缺乏自己肯定（凡是最优秀的领导者都非常自信）伟大的领导者通过授予权利来获得权力。镜像法则：看到别人怎么做，大家也会怎么做伟大的领导者好像一直都表现出两种似乎截然不同的特质。他们很有思想但都非常实际。领导者通过对愿景的有效示范把镜像变成现实。下属总是在观察你的所作所为教正确的事总比做正确的事容易（领导者通常只是说教，只有在他们真正实践的时候，才算是授权）提升他人之前，应该首先改变自己领导者能给下属的最宝贵的东西就是一个好的榜样领导就是示范。接纳法则：人们先接纳领导者，然后接纳他描绘的愿景领导者先找到目标，然后才找到一群追随者。而普通人却是先找到领导者，然后才认同领导者的目标。制胜法则：领导者为他的团队找出一条制胜之路渴望获胜的领导者都是有不服输的决心。他们完全不能接受失败。胜利的要素：统一的目标多样化的技能一位愿为胜利而献身、致力于发挥队员潜能的领导者动势法则：动势是领导者最好的朋友在一个具有动势的组织内，即使是普通人也能超水平表现自我。只有领导者创造出动势（目标、激情、热忱）。领导者总是在想方设法找到那条通往成功的道路。激励是创造动势的关键因素。优先次序法则：领导者明白，忙碌不一定等于有效3R法则：必要的分内事情，回报效益高的事情，回报大的事情。领导者们应该走出那些他们感到舒适的领域，而去那些可以发挥他们优势的领域。舍得法则：领导者必须先“舍”后“得”出色领导的精髓就是牺牲。牺牲是一种持续的过程，而非一次性付出。如果领导者必须有所“舍”，才能有所“得”。那么你想继续留在高位就得有更多的舍弃。时机法则：掌握时机与善用策略同样重要良好的领导时机需要很多条件：认识——领导者必须对局势有清楚的认识成熟——领导者的动机不正确，也就不会有良好的时机信心——人们往往追随心里有谱的领导者果断——优柔果断的领导者培养出优柔果断的下属经验——如果领导者毫无经验，那么他们需要从其他有经验的人那里汲取经验直觉——时机通常是由一些抽象的东西决定的，比如动势和士气准备——如果条件不适合，领导者必须创造条件当正确的领导者遇上了正确的时机，就会产生令人振奋的结果。爆炸性倍增法则培养追随者，得到相加的效果培养领导者，得到倍增的效果传承法则：一个领导者的长久价值由其继承者决定传承乃是领导的一项主要责任。结凡事之兴衰成败皆系于领导力。人才决定组织的潜力关系决定组织的士气结构决定组织的规模目标决定组织的方向领导决定组织的成败读《领导力21法则》推荐指数：10 / 10两年后再读。]]></content>
      <categories>
        <category>read</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Golang 协程调度原理]]></title>
    <url>%2F2020%2F03%2F14%2FGolang-%E5%8D%8F%E7%A8%8B%E8%B0%83%E5%BA%A6%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[整体架构Golang协程整体架构如图：G：协程M：操作系统的抽象对象；P：逻辑处理器执行过程基本是：一个M，绑定一个P后，进入调度执行，不断执行P获取到的G。架构演进G-M 模型Golang在开始发布的时候采用了G-M模型缺点：限制了Go并发程序的伸缩性单一全局互斥锁（Sched.Lock）和集中状态存储 导致所有goroutine相关操作都需要上锁（比如创建、重新调度）goroutine传递问题，M之间传递可运行的G，导致调度延迟增大以及额外的性能损耗每个M做内存缓存，导致内存占用过高，数据局部性较差由于syscall调用而形成的剧烈的worker thread阻塞和解除阻塞，导致额外的性能损耗G-P-M模型计算机科学领域的任何问题都可以通过增加一个间接的中间层来解决。在G-M之间加入一个中间层解决，P代表逻辑CPU。缺点：不支持抢占式调度，导致一旦某个G中出现死循环或永久循环的代码逻辑，那么G将永久占用分配给它的P和M，位于同一个P中的其他G将得不到调度，出现“饿死”的情况Go1.2实现抢占式调度原理是在每个函数或方法的入口，加上一段额外的代码，让runtime有机会检查是否需要执行抢占调度缺点：局部解决了“饿死”问题，对于没有函数调用，纯算法循环计算的G，scheduler依然无法抢占NUMA调度模型暂未实现G-P-M 模型详细分析要搞懂G-P-M模型的详细架构，那么要解决接下来的这些问题：M的创建时间点？P的创建时间点？G的创建时间点？G的调度方式，如何保证公平？我们抱着这些疑问来详细分析。首先，Golang程序是怎么启动的呢？启动时做了如下这些事情：初始化固定数量的P（默认为cpu核心数）创建一个新的G来启动runtime.main创建全局 M0、全局 G0，启动 M0 进入第一个调度循环其中：M0：代表第一个启动的MGO：执行runtime调度，每个M都会绑定一个G0首先，对于一个Golang的程序，最多可以并发的线程数，是初始化的P的个数。在设计上，通过P的数量限制并发的线程数。第二点，在Golang中，首先启动的协程是通过runtime.main启动的，然后进行一些初始化和准备，最终调用main.main方法。M在哪些情况下回创建M呢？当P中存在没有绑定的M，且有需要支持的G时，则尝试绑定一个M（创建或者绑定已有）。M的启动过程：获取空闲的P尝试获取空闲的M，如果没有则新建一个（新建M的时候，会创建一个一个G0）将M和P绑定启动，进入调度循环从本地队列获取一个G，没有则从其他地方获取每处理一些任务之后，就优先从全局队列里获取任务，以保障公平性，防止由于每个P里的G过多，而全局队列里的任务一直得不到执行机会执行GPP代表逻辑处理器。P在初始化时，根据CPU的核心数或者环境变量GOMAXPROCS（有最大限制），创建对应个数的P。可以通过runtime.GOMAXPROCS()重新设置了最大 CPU 使用数量。G系统中一共有哪些G呢？gofunc创建创建的基本方式为：从当前P中找一个空闲的G，没有则新建一个；放入当前P的队列；唤醒M开始执行。epoll从内核中获取到一些事件，拿到了有收到就绪的 FD。再将对应的G唤醒标记为ready，同时将这些G放入全局的等待队列。每个M绑定的G0G是怎么创建并进入调度流程的呢？首先何为调度：调度就是决定何时哪个goroutine将获得资源开始执行、哪个goroutine应该停止执行让出资源、哪个goroutine应该被唤醒恢复执行等。G创建与进入调度流程如下：从当前P中复用一个G如果没有，则新建一个G给G的执行环境里的 pc 变量赋值了一个 goexit 的函数地址，也就是说G正常执行完退出时执行的是 goexit 函数（切换到G0下释放G，并放置回P的本地队列中）尝试将G添加到当前P的runnext中，作为下一个执行的G否则放到Local队列runq中(无锁)如果以上操作都失败，则添加到Global队列sched.runq中(有锁操作，因此也会顺便将当P.runq中一半的G转移到sched.runq)那么当前协程如何让出CPU？G正常退出G中会指定一个退出函数，当退出时调用该函数（退出函数是，将函数栈切换到了G0，释放G）主动让出即临时停止或阻塞，需要让出CPU（如time.sleep、IO阻塞等）（挂起当前G）(gopark进行调度让出CPU资源。切换到G0下，保存当前的G的函数栈等信息，并修改G的状态为等待（表明正在等待唤醒）)。主动抢占runtime.main中有一个监控任务，sysmon方法。超过10ms还在执行的G将会被抢占，只是做一个标记，实际抢占发生在栈扩张的时候（下个函数或方法调用时，判断是否栈不够，不够则扩张）（小函数优化：不进行校验）调用函数时，准确的说是在分配函数栈时抢占系统调用让出G进入系统调用时，会保存上下文，标记为“系统调用状态”，等待被抢占走。系统调用退出时，则通过G0下将G切回来，如果有可执行的P，则执行，没有则放全局队列，等待调度。上诉4种G让出CPU的方式。下面列出多种主动让出的场景：time.Sleep休眠：将计时器加入到timer管理器中，通过goparkunlock实现当前G的休眠唤醒：将休眠的G标记为可运行状态，并放入P的待运行队列中Mutex通过goparkunlock方法进入休眠，并加入到root.queue队列等待唤醒channel当给一个 chan 发送消息的时候，实质触发的方法是 chansend。在该方法里不是先进入休眠状态。如果此时有接收者收到这个消息，则直接将通过send方法直接发送给接收者，并唤醒接收者G，当前发送者G继续执行如果没有接收者，将数据copy到chan的临时内存中，且内存没有满则继续执行该G如果没有接收者且chan满了，通过goparkunlock进入休眠。休眠前把当前的G相关信息存到队列（sendq）以便有接收者接收数据的时候唤醒当前G。唤醒发送者：如果发送者被休眠，则取出数据然后唤醒发送者，当前接收者的G拿到数据继续执行如果没有休眠的发送者，则看一下是否有已经发送的数据没有被接收，有则直接取数据继续执行（直接从chan的内存取）如果既没有休眠的发送者，chan中也没有数据，则通过goparkunlock休眠，放入recvq队列中，等待唤醒在主动抢占中提到，通过监控任务sysmon来执行监控工作，协助抢占。那么sysmon究竟有哪些作用呢？sysmon是一个由runtime启动的M，监控线程，无需P也可以运行，每20us~10ms唤醒一次sysmon作用：释放闲置超过5分钟的span物理内存如果超过2分钟没有垃圾回收，强制执行将长时间未处理的netpoll结果添加到任务队列向长时间运行的G任务发出抢占调度收回因syscall长时间阻塞的P主动抢占发生在函数栈调用时，准确讲为栈扩张的时候。那么栈何时扩张，以及扩张是一个怎么样的流程？栈扩张：基本过程就是分配一个2x大小的新栈， 把数据拷贝到新栈，并用新栈替换到旧栈。栈缩容：由垃圾回收器在垃圾回收时主动触发的。基本过程是计算当前使用的空间，小于栈空间的1/4的话， 执行栈的收缩，将栈收缩为现在的1/2，否则直接返回。在 runtime 下会启动一个全程运行的监控任务，该任务用于标记抢占执行过长时间的G，以及检测 epoll 里面是否有可执行的G。netpoll是Go针对网络IO的一种优化，本质上为了避免网络IO陷入系统调用之中，这样使得即便G发起网络I/O操作也不会导致M被阻塞（仅阻塞G），从而不会导致大量M被创建出来。G的几种暂停方式：gosched: 暂停当前G，保存状态并将G设置为可运行状态放入Global队列，当前M继续执行。gopark: 暂停后，设置为等待状态，放入专门的等待队列notesleep: 既不让出M，也不让G与P重新调度，直接让线程休眠直到唤醒（notewakeup）,该方式更快，通常用于gcMark，stopm这类自旋场景附也谈goroutine调度器从源码角度看 Golang 的调度Head First of Golang Scheduler]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>Golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我]]></title>
    <url>%2F2020%2F02%2F27%2F%E6%88%91%2F</url>
    <content type="text"><![CDATA[我是一个无趣的人吧。回想起来，我从开始，是一个内向的人，不爱说话，其实只是没有话题，不知道说些什么，也不喜欢说一些没用的话。后来开始长大了吧，或许有些开始变得唠叨了，当然有时也更加不愿意说更多的话，不愿意发不同的言。在大三后，可能突然醒悟了，开始觉得，不管什么事，尽可能地用微笑去面对它，哪怕它让你有一种心碎了一地的感觉，以至于有人说我有点喜形不于色。其实我开始觉得我不应该生气的，不管遇到什么事，都不应该生气，淡然处之，或许是一种没有情调的表现，但些许时候，我明白真正看透因果。我受过伤，心里的伤，从没有一次表现出来。有时候觉得我自己很傻，为什么在同一个地方伤了后，却义无反顾地再次一头扎进伤痛里，笑着对别人说没事。别人总当我是一个没事的人。所以我很傻。但是像我这种从不会告诉别人我受伤的人，永远不会被同情的——人根本就不应该博取同情，对我而言，那是自己的一种软弱。在踏入这世间时，我才开始有点在乎，我与这世间有点不适应。人从来就不是跟从理想去做的事，而是跟从生活去做的事。这个社会，太过于浮躁，以至于在我在社会上待了半年后，也变得浮躁了。我发现我喜欢的事闲适的生活，我理解了阅读的重要性，不管是否是关乎自己的职业、技术等书籍，阅读都能够让我沉静下来，让我的思维在时间里停下来。我明白我不可能脱离这个世界的限制，我不可能做到不像着普通年轻人一样，负着高压、负着贷款，夜以继日的努力，并不是为了什么理想，而仅仅是为了活着，为了完成人所被这个社会强加的意愿。以前学过，“人固有一死，或重于泰山，或轻于鸿毛“。其实一直觉得，对我而言，人死了，就什么都没有了，我能过的就是这一个人生，并没有任何必须要去完成的义务，只是我们选择了一些我们想要去完成的事。这些应该称为理想。我现在是一个什么样的人，我总是在想，我应该成为什么样的人。我喜欢文学，却没有才华。喜欢码字，只是因为有情感。我曾说，我写的不是文，只是情，是一种我自己的诉说。我羡慕那种可以写出好文章的人，因为我写不出。我喜欢纯音乐，我或许是一种怪人，以前可以听着纯音乐到泪眼。我一直说，每一个偏好纯音乐的人，都是一个有故事的人。我喜欢吃美食，但没有吃出花样，不明白怎么才能更加美味。我喜欢哲学，并不是哲学上的那种辩论，而仅仅指那种对于哲学的思考，可以启发我的思维上的进化。我理解世间万事，终究所有道理都可以相通的。我是一个程序员，有着程序员的大多数的特点。我一直认为我专心写代码的时候很开心，后来才明白，我开心并非因为我在写代码，而是因为做一件事，并沉浸其中很开心。我是狮子座的，我看过只觉得有部分分析其实也挺符合我，有人说非常符合我，我可能身处青山不见山吧。我是一个比较宅的人，并不是喜欢宅。只是只有自己，不喜欢出去，有一种形单影只的独自悲伤。亟待一个能够带我出去浪的朋友。我记忆力不够，所以我从来都是用着笔记本以及手机同时记事的，不管是什么事，或许也是因为自己怕忘了。曾经的我喜欢历史，因为觉得历史很有趣，因为觉得历史里，总有一些精髓与要义能够在生活中使用。后来没那么喜欢历史里，因为没有一个历史是讲诉平凡人一生的。历史里，每一个波动，对于平凡人而已，都是悲惨的。我不会音律，没有一个擅长的乐器，是我一直挺遗憾的，想学葫芦丝。我喜欢打乒乓球，不在乎输赢，只在乎尽兴与运动时的优美。我应该是一个不喜笑的人，一个不发火的人。心里住着一个个人的世界吧。我好像还有很多特点，我都忘了。补上我的2020目标：]]></content>
      <categories>
        <category>other</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[读《黄鹤楼》]]></title>
    <url>%2F2020%2F02%2F23%2F%E8%AF%BB%E3%80%8A%E9%BB%84%E9%B9%A4%E6%A5%BC%E3%80%8B%2F</url>
    <content type="text"><![CDATA[黄鹤楼前《黄鹤楼》，倒却鹦鹉捶碎楼。不闻崔诗塞上榜，古吟今叹鹦鹉洲。]]></content>
      <categories>
        <category>read</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[走着，走着——19年过了]]></title>
    <url>%2F2019%2F12%2F31%2F%E8%B5%B0%E7%9D%80%EF%BC%8C%E8%B5%B0%E7%9D%80%2F</url>
    <content type="text"><![CDATA[前言，18年好像过去没多久，《例行总结——2018版》。2019年，这个是平凡的一年，也是有趣的一年。平凡，这一年，还是往常一样。工作，加班，读书……依然还是北漂，生活一层不变的过下去。有趣，这一年，也发生了许多事。加入了新公司，博客也迁移到github上，开始习惯了“10105.5”的生活，也开始被父母催促“我一个人”。2月13日，我年后再来了北京，也加入了新公司。今年，总的算下来，我读了13本书，其中十分推荐《人类简史》等。当然，这一年里，总共更新了20篇博客等。也开始学习课程，内部课程完成22个；也在MOOC上开始学习「唐诗经典」。这一年，更宅了，只不过也稍微动一点。夏天骑了辆摩拜从望京到中关村，算是我的巅峰了。今年也放弃了一些，放弃了使用网易云音乐，也放弃了看NBA。工作就不多说了，应该也算有成长吧。2020年，有点想回成都了。至少要读《数据库系统概念》、《追风筝的人》（英文版）、《经济学原理》（宏观经济学分册）。19年，就这样了吧。我的关键词：走着，走着。]]></content>
      <categories>
        <category>other</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[平凡世界里，平凡的活着]]></title>
    <url>%2F2019%2F12%2F25%2F%E5%B9%B3%E5%87%A1%E4%B8%96%E7%95%8C%E9%87%8C%EF%BC%8C%E5%B9%B3%E5%87%A1%E7%9A%84%E6%B4%BB%E7%9D%80%2F</url>
    <content type="text"><![CDATA[一本书，能够引起共鸣，触发感想，引导人继续前进，就是一本好书。这本书里，描述极其朴实，生活等场景都历历在目，生动形象。但在人物关系上有点过于巧合，让人觉得有点太凑巧了而显得不够自然。但这些都不妨碍这是一本好书，塑造了一个精神强悍的少平，这可以认为是一个时代里的偶像，平凡里的英雄。人生有几个永恒的词：物质、精神、苦难、爱情、出生、死亡。这些词交织在一起就是人生。晓霞死时，我哭了。或许不是读着以来第一次哭吧，但是我真心体会到那种悲惨。既可怜死者，更同情生者。一个不平凡的人，终究不能以不平凡的方式存在于平凡的世界，当这种人人所向往的美好，破碎了，还有谁能不感叹呢？逝者已矣，但生者还得继续过活下去，读到这时，我害怕，害怕少平终于承受不住，选择逃避；害怕少平突然间看淡了，精神世界里崩溃了。我始终害怕，这个平凡的人，在这个现实里，过不去了。或者我对于书中少平的害怕，正是我对自己的胆怯。在现实里，我想着用另一种东西来填补我的精神，我明白我是孤寂的，明白我没有那么大的一颗强大的内心，明白我很平凡，明白我缺少一颗有趣的灵魂。正是缺少，我想要去填补，我害怕哪天，我看开了，油腻了，像老一辈一样，空闲时选择混日子了，胆怯着。晓霞始终会“离开”。这是一个令人向往的精神体，是众多期望的非具象的凝聚。若晓霞没有离去，与少平无论以何种结局结束，都是不现实的、不平凡的，这便是现实，平凡的世界。每个人心中都有一个自己所期待着的“晓霞”，正因为是期望着，所以想等待下去，等着能够倾听我灵魂的那个“晓霞”，等着能够带领自己的精神突破的人。《平凡的世界》结尾得有点让人突然，没有一个是真的悲剧，没有一个是真的喜剧。语言里那一个句号时结束了，但生活、世界都没有停下，接下来会和前面生活一样，不停歇，有喜有悲、有爱有恨、有生命诞生有死亡降临。这一切都会这样一直持续不断的进行下去，生活会一直慢慢过下去。现实里也是一个平凡的世界，我是一个平凡的人，想平平凡凡的活下去。平凡的世界里，一切都那么地自然，一切都那么现实。而我们就处在这样一个世界里，“只能永远把艰辛的劳动看作是生命的必要；即使没有收获的指望，也心平气和地继续耕种”，只能继续不寻边界的寻找追求的精神与信仰，继续读书，继续追求精神，继续突破边界。这便是我们的选择，如此平凡又不平凡的活下去。《平凡的世界》：推荐分8分]]></content>
      <categories>
        <category>read</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[注重实效的程序员参考指南]]></title>
    <url>%2F2019%2F12%2F09%2F%E6%B3%A8%E9%87%8D%E5%AE%9E%E6%95%88%E7%9A%84%E7%A8%8B%E5%BA%8F%E5%91%98%E5%8F%82%E8%80%83%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[本文为读《程序员修炼之道——从小工到专家》的部分总结与摘要。关心你的技艺即关心自己的技术，考虑自己如何写更好的代码，考虑如何做一个完美的项目。思考！你的工作不断地批评和评估自己的工作。提供各种选项，不要找蹩脚的借口提供各种选项，而不是找借口。不要说事情做不到，应该说能够做什么。解决问题而并非推卸责任。不要容忍破窗户当你看到糟糕的设计、错误的决策和糟糕的代码时，修正它们。置之不理会加速腐烂的进程。对自己的设计与代码严格要求，才能延续得更久。当然，第一目的是实现目标，更好的设计与决策都是为了更好的支持目标。做变化的催化剂不能强迫人们做改变，但可以展示改变后的效果，以及帮助参与对未来的创造。记住大图景时刻需要记住目前的目的是什么，需要做什么，以及变化了什么，不能太沉浸于细节中。常常小事的积累会破坏士气和团队，学会让事情变得更美好。需要时刻提醒自己，目前做的事情是否偏离最终目的。当自己沉入太多时，则要停下来考虑自己是否偏离了方向。使质量成为需求问题质量也是一个需求，在需要质量时，则需要增加自测&amp;系统测试时间，在排期时也需要对质量留下保证时间。定期为你的知识资产投资和第一点「关心你的技艺」相关。让学习成为习惯，并非要求都与工作相关。保持学习，保持阅读，保持总结与写作。批判地分析你读到的和听到的不要被供应商、媒体炒作、或教条左右。要依照自己的看法和项目的情况区对信息进行分析。重点还是明确清楚自己想要什么（最终目的）。说什么和怎么说同样重要如果不能有效地向他人传达你的了不起的想法，这些项目就毫无用处。规划你想说的东西，写出大纲。同时，了解听众（了解别人需要什么，同时明白自己需要表达什么）。你想让他们学到什么？他们对你讲的什么感兴趣？他们有多富有经验？他们想要多少细节？你想让谁拥有这些信息？你如何促使他们听你说话？了解别人的交流风格。学会听别人说话，即使你掌握着全部信息。不能及时回复与处理时，都需要反馈。更多交流方案参照《工作沟通技巧笔记》不要重复自己系统中的每一项知识都必须具有单一、无歧义、权威的表示。强加的重复无意的重复无耐性的重复开发者之间的重复哪怕是最终破坏DRY原则，也不能暴露给外界。让复用变得容易如果复用很容易，人们就会去复用，创造一个支持复用的环境。复用时需要考虑：复用成本 VS 重做成本清除无关事物之间的影响设计自足、独立、并具有单一、良好定义的目的的组件。解耦，提高模块之间的正交性。改动得以局部化正交得途径还能够促进复用使用正交的组件进行组合，可以提高生产率编码中需要注意：使代码保持解耦。使得不用关心内部原理就可以使用避免使用全局数据避免编写相似的函数不存在最终决策没有决策是浇铸在石头上的。相反，要把每项决策都视为是写在沙滩上的，并为变化做好计划。需要考虑维持交个、部署及供应商集成等领域的灵活性。把第三方产品隐藏在定义良好的抽象接口后面。用曳光弹找到目标曳光弹能通过实验各种事物并检查它们离目标有多远来让你追踪目标。原型制作生成用过就扔的代码。曳光弹虽然简约，但却是完整的，并且构成了最终系统的骨架的一部分。为了学习而制作原型原型制作是一种学习经验。其价值并在于所产生的代码，而在于所学到的经验教训。原型应该遮盖细节，并聚焦于所考虑系统的某些具体方面。靠近问题领域编程用你的用户的语言进行设计和编码。选择更靠近问题解决方便的语言。估算，以避免发生意外在着手之前先进行估算，将提前发现潜在的问题。需求分析与方案确定后才能估算时间。并且学会理解估算对应的精度，进而明确出精确到哪个度量程度。对于一个项目，模型可以是你的组织在开发过程中所用的步骤、以及系统的实现方式的非常粗略的图景。每次项目完成后，需要终结每次估算不准的原因。通过代码对进度表进行迭代用在进行实现时获得的经验提炼项目的时间标度。用存文本保存知识从简单方便的东西记录知识。利用命令shell的力量当图形用户界面无能为力时使用shell。用好一种编辑器编辑器应该是你的手的延伸；确保你的编辑器都是可配置、可扩展和可编程。总是使用源码控制源码控制是你的工作的时间机器——你能够回到过去。要修正问题，而不是发出指责bug是你的过错还是别人的过错，并不是真的很有关系——它们仍然是你的问题，它仍然需要修正。不要恐慌做一次深呼吸，思考什么可能是bug的原因。慌也解决不了问题。“Select” 没有问题在OS或编译器、甚至是第三方产品或库中很少发现bug。bug很可能在应用中。多相信系统控件。不要假定，要证明在实际环境中——使用真正的数据和边界条件——证明你的假定。学习一种文本操作语言编写能编写代码的代码代码生成器能提高你的生产率，并有助于避免重复。不可能写出完美的软件软件不可能是完美的。保护你的代码和用户，使他们免于能够预见的错误。注重实效的程序员针对自己的错误进行防卫性的编码。通过合约进行设计使用合约建立文档，并检验代码所做的事情正好是它声明要做的。（输入什么，做了什么，输出了什么）。参数的改变必须是显示的，并不能隐藏。对在开始之前接受的东西要严格，而允诺返回的东西要尽可能少。早崩溃在错误发生时，第一时间中止。函数需要考虑异常输入并给出提示。（底层方法异常输入应该之间中止流程）。出错时需要偏向消费者。用断言避免不可能发生的事情断言验证你的各种假定。在一个不确定的世界里，用断言保护你的代码。保留某些异常检测流程。将异常用于异常的问题异常可能会遭受经典意大利面条式代码的所有可读性和可维护性问题的折磨。将异常保留给异常的事物。要有始有终分配某资源的例程或对象也应该负责解除其分配。以与资源分配次序相反的次序解除资源的分配在代码的不同地方分配同意组资源时，总是以相同的次序分配它们。（降低发生死锁的可能性）无论时谁分配的资源，都应该负责解除该资源的分配使模块之间的耦合减至最少通过编写“羞怯的”代码并应用得墨忒耳法则来避免耦合。得墨忒耳法则：每个单元对于其他的单元只能拥有有限的知识：只是与当前单元紧密联系的单元每个单元只能和它的朋友交谈：不能和陌生单元交谈只和自己直接朋友交谈平衡你的规定应用的各种正面因素和负面因素。要配置，不要集成要将应用得各种结束选择实现为配置选项，而不是通过集成或工程方法实现。配置方式，方便修改，统一维护。将抽象放进代码，细节放进元数据为了一般情况编程，将细节放在被编译的代码库之外。尽可能编写通用的代码。分析工作流，以改善并发性利用你的用户的工作流的并发性。用服务进行设计根据服务——独立性、在良好定义、一致的借口之后的并发对象——进行设计。总是为并发进行设计容许并发，你将会设计出更整洁、具有更少假定的接口。使视图与模型分离要根据模型和视图设计你的应用，从而低廉的代码获得灵活性。相当于MVC中的view层和model层进行分离。用黑板协调工作流用类似黑板的画图方式总结和协调工作流。不要考巧合编程只依靠可靠的事物。注意偶发性的复杂性，不要把幸运的巧合与有目的的计划混为一谈。总是意识到你在做什么。不要盲目地编程。视图构建不完全理解的应用，或是使用不熟悉的技术，就是希望自己被巧合误导。按照计划行事，不管计划时在你的头脑中。依靠可靠的事物。为“假定”或“合约”建立文档。不要只是测试你的代码，还需要测试你的假设。为你的工作划分优先级。不要做历史的奴隶，不要让已有的代码支配将来的代码。不要让已经做完的事情约束下一步要做的事情——准备好进行重构。（以最小的成本与影响进行重构）估算算法的阶在编写代码之前，先大致估算事情需要多长时间。测试你的估算对算法的数学分析并不会告诉你每一件事情。在代码的目标环境中测定它的速度。早重构，常重构就和你会在花园里除草、重新布置一样，在需要时对代码进行重构、重做和重新架构。要铲除问题的根源，控制演化方向。重构与需求应该分开进行（至少分为不同步骤）。不要试图在重构的同时增加功能。重构前列出测试case。保证重构后拥有良好的测试。采取短小、深思熟虑的步骤。如果某个代码与设计现在又损害，但以后损害会更大，也许最好一劳永逸的修正它。不要容忍破窗户。为测试而设计代码与系统设计时需要考虑测试。日志中必须带有必要的信息，方便跟踪问题。日志消息的格式应该是正规、一致。测试你的软件，否则用户就得测试测试是技术、更是文化；不管所用的语言是什么，我们都可以让这样的测试文化慢慢渗入项目中。不要使用你不理解的向导代码不要收集需求——挖掘它们挖掘潜层需求，理解需求背后的目的。需求分析是指了解具体的需要。找出用户为何要做特定事情的原因，而不只是它们目前做这个事情的方式。开发解决的最终是商业问题，而不只是满足他们陈述的需求。用文档记录需求背后的原因。与用户一同工作，以像用户一样思考要了解系统实际上将如何被使用，这是最好的方法。开采需求的过程也是开始与用户群建立和谐关系、了解他们对正在构建的系统的期许和希望。抽象比细节活得更长久“投资”于抽象，而不是实现。抽象能在来自不同的实现和新技术的变化的“攻击”之下存活下去。不要做任何表示方法的奴隶；只要是与你的听众交流需求的最好的方法，都可以加以使用。使用项目词汇表创建并维护项目中使用的专用术语和词汇的单一信息源。文档需要方便阅读与分享。不要在盒子外面思考——要找到盒子在遇到不可能解决问题时，要确定真正的约束。问问自己：“它必须以这种方式完成吗？它真的必须完成吗？”回头考虑自己的最终目的，需求最后的需要，自己是否被限制住了。有更容易的方法吗？你是在设法解决真正的问题，还是被外围的技术问题转移了注意力？这件事为什么是一个问题？是什么使它如此难以解决？它必须以这种方式完成吗？它真的必须吗？等你准备好再开始你的一生都在积累经验。不要忽视返回出现的疑虑。将特殊点训练成意识、习惯。对有些事情“做”胜于“描述”不要掉进规范的螺旋——在某个时刻，你需要开始编码。不要做形式方法的奴隶如果你没有把某项技术放进你的开发实践和能力的语境中，不要盲目地采用它。昂贵的工具不一定能制作出更好的设计小心供应商的炒作，行业教条、以及价格标签的诱惑。要根据工具的价值判断它们。围绕功能组织团队不要把设计师和编码员分开，也不要把测试员与数据建模员分开。按照你构建代码的方式构建团队。质量是一个团队问题。如果团队主动鼓励开发者不要把时间花费在这样的修正上，问题就会进一步恶化。确保每个人都主动地监视环境的变化。创建品牌，建立信任机制。对外界而言，看上去沉闷寡言的项目团队是最糟糕的图团队。无章次的会议、混乱的文档、不统一的术语都是要避免的。把团队划分为小团队，分别负责最终系统的特定方面的功能。让各团队按照个人的能力，在内部自行进行组织。不要使用手工流程shell脚本或批文件会一次次地以同一顺序执行同样的指令。自动化是每个项目团队的必要组成部分。确保项目的一致性和可重复性。人的重复性可能存在很大问题（不要基于记忆），应该使用文档来规束，代码进行负责自动化。早测试，常测试，自动测试与待在书架上的测试计划相比，每次构建时运行的测试要有效得多。要到通过全部测试，编码才算完成单元测试是对某个模块进行演练的代码。性能测试、压力测试或负载测试也可能会是项目的一个重要方面。回归测试是把当前测试的输出与先前的（或者已知的）值进行对比。单元测试集成测试验证和校验资源耗尽、错误及恢复性能测试可用性测试对测试自身进行测试通过”蓄意破坏“测试你的测试在单独的软件副本中故意引入bug，以检验测试能够抓住它们。测试状态覆盖，而不是代码覆盖确定并测试重要的程序状态，只是测试代码行是不够的。一个bug只抓一次一旦测试员找到一个bug，这应该是测试员最后一次找到它。此后自动测试应该对其进行检查。英语就是一种编程语言像你编写代码一样编写文档：遵循DRY原则、使用元数据、MVC、自动生成，等等。把文档建在里面，不要拴在外面与代码分离的文档不太可能被修正和更新。在必要的地方添加注释，代码即是文档，避免多余的注释。比无意义的名称更糟糕的是误导人的名称。文档需要写下文档创作的时间。温和地超出用户的期望要理解用户的期望，然后给他们的东西要多那么一点。在你的作品上签名]]></content>
      <categories>
        <category>tool</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[笔记整理——计算机操作系统（笔记整理三之三）]]></title>
    <url>%2F2019%2F11%2F25%2F%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86%E2%80%94%E2%80%94%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%EF%BC%88%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86%E4%B8%89%E4%B9%8B%E4%B8%89%EF%BC%89%2F</url>
    <content type="text"><![CDATA[操作系统的五大功能：处理机管理、存储器管理、设备管理、文件管理、向用户提供方便的用户接口。操作系统共有的特征：并发、共享、虚拟、异步。（并发与共享是最基本的特征）。操作系统分为单道批处理、多道批处理；分时、实时系统。进程：系统中能独立运行并作为资源分配的基本单位，由一组机器指令、数据、堆栈等组成。线程：作为独立运行的调度的基本单位。进程控制块：PCB，进程存在的唯一标志，系统利用PCB进而控制和管理进程（常驻内存）。进程和程序的最根本的区别是，进程是动态的，而程序是静态的。进程的特征：并发性（重要特征）、动态性（最基本的特征）、独立性、异步性。进程由独立的地址空间；线程由自己的堆栈和局部变量，但线程之间没有单独的地址空间，一个线程死掉就等于整个进程死掉（每个进程最少有一个线程）。进程之间的地址空间独立。挂起状态 —&gt; 活动就绪、静止就绪、活动阻塞、静止阻塞。终止状态后，除PCB之外其他都被释放。临界资源：在一段时间内只允许一个进程访问的资源。每个进程中访问临界资源的那段代码称为临界区。关中断：屏蔽中断，系统不响应中断，从而不会引发调度，也就不会发生进程或线程切换。调度算法：FCFS：先来先服务（不利于短作业）SJF：短作业优先（平均周转时间最短的算法）PSA：优先级调度算法（优先级数越大，优先度越高）HRRN：高响应比优先调度算法。响应比 Rp = 响应时间 / 要求服务时间 = （等待时间 + 要求服务时间） / 要求服务时间RR：轮转调度算法（主要用于分时系统）抢占式调度算法：1、基于时钟中断的抢占式优先级调度算法；2、立即抢占。EDF：最早截止时间优先算法LLF：最低松弛度优先算法。 松弛度 = 完成截止时间 - 剩余运行时间 - 当前时间死锁的必要条件：1、互斥条件；2、请求和保持条件；3、不可抢占条件；4、循环等待条件。处理死锁的方法：1、预防死锁；2、避免死锁（银行家算法，在资源分配过程中，防止系统进入不安全状态）；3、检测死锁；4、解除死锁。产生死锁的原因主要有：1、系统资源不足；2、进程运行推进的顺序不合适；3、资源分配不当等。死锁的预防措施：1、静态资源分配法；2、资源顺序分配法；3、剥夺控制法。程序装入：1、编译；2、链接（逻辑地址变物理地址）；3、装入。（绝对装入方式、可重定位装入方式、动态运行时的装入方式）。基于顺序搜索的动态分区分配算法：首次适应算法（FF）循环首次适应算法（NF）最佳适应算法（WF）：总是挑选一个最大的空闲区，从中分割一部分存储空间给作业使用。基于索引搜索的动态分区分配算法：快速适应算法伙伴系统动态可重定位分区分配。紧凑：解决了碎片问题。分页 / 分段 / 段页式。页是信息的物理单位，以消减内外零头（系统行为）；段时信息的逻辑单位，满足用户的需要。内存分配策略：固定分配局部置换（只能从分配给改进程n个页面中选出一页换出）（固定分配全局置换不能组合）可变全局置换可变分配局部置换（只交换该进程的页面，分配若干物理块）物理块分配算法：平均分配算法按比例分配算法考虑优先权的分配算法页面调入：预调页策略，请求调页策略。请求分页系统中的外存分为：1、用于存放文件的文件区；2、用于存放对换页面的对换区。页面置换算法：最佳置换算法（无法实现）FIFO算法，有Belady现象LRU，最近最久未使用。需要较多硬件支持；管理虚拟内存的分配，物理内存的释放。LFU，最少使用置换算法Clock置换算法页面缓冲算法PBA抖动：同时在系统中运动的进程太多，从而分配每一个进程物理块太少，导致频繁缺页。工作集指某个时间间隔∆里，进程实际所要访问页面的集合。块设备接口是块设备管理程序与高层之间的接口。设备控制器，控制一个或多个I/O设备，以实现I/O设备和CPU之间的数据交换。I/O通道，通道与CPU共享内存磁盘调度算法：1、先来先服务（FCFS）；2、最短寻道时间优先（SSTF）；3、扫描算法（SCAN），电梯调度算法；4、循环扫描算法（CSCAN）文件组织方式：顺序文件、索引文件、索引顺序文件。文件的逻辑结构：连续结构、多重结构、转置结构、顺序结构；（流式文件属于逻辑结构的文件）。文件的物理存储：顺序结构、链接结构、索引结构。文件的目录结构：一级目录结构、二级目录结构、树形结构、无环图。文件存储空间的管理：1、空闲法和空闲链表法；2、位示图法；3、成组链接法。数据传输率 = 记录密度 X 线速度。系统对每一块数据的处理时间：1、单缓冲区 Max（C，T）+ M；2、多缓冲区 Max（C，T）。（CPU处理时间C、缓冲区时间T、传送到用户时间M）作业调度JCB：后备队列，优先级调度可能产生饥饿。内存管理中常用区间和区间中的数据：静态区：存放（初始化的）全局变量、静态变量，和（未初始化）全局变量和静态变量。栈区：存放局部变量和函数的形参。栈中的内存空间由编译器自动申请和释放。堆区：存放动态分配内存函数申请的变量。堆中的内存空间需要程序员手动释放，否则会发生内存泄露。（易产生内存碎片）虚拟设备（Spooling技术），将独占设备变为共享设备，实现设备的虚拟分配，提高独占设备的利用率。（只能用软件实现）线程共享的内容包括：1、进程代码段；2、进程数据段；3、进程打开的文件描述符；4、信号的处理器；5、进程的当前目录；6、进程用户ID与进程组ID。线程独有的内容包括：1、线程ID；2、寄存器组的值；3、线程的堆栈；4、错误返回码；5、线程的信号屏蔽码。用于进程间通信（IPC）的四种不同技术：消息传递（管道、FIFO、Posix和System v消息队列）同步（互斥锁、条件变量、读写锁、文件和积累锁，Posix和System v信号灯）共享内存区（匿名共享内存区，有名Posix共享内存区，有名System v共享内存区）过程调用（Solaris门、SunRPC）实现线程同步：事件、临界区、互斥量、信号量。外部中断处理过程，PC值由中断隐指令自动保存，而通用寄存器内容由操作系统保存。虚拟存储的实现是基于程序局部性原理，其实质是借助外存将内存较小的物理地址空间转化为较大的逻辑地址空间。用户级线程的管理由用户应用程序来完成，内核是不知道用户线程的。删除文件，文件的关联目录项和文件控制块需要随着文件一同删除，同时释放文件的关联缓冲区。管道是指用于连接一个读进程和一个写进程以实现进程之间通信的一种共享文件。数据格式是字符流。虚拟存储器最大实际容量 = min（计算机地址，内存 + 辅存）在分段存储管理中，地址转换公式：物理地址 = 界限寄存器值 + 逻辑地址。fork子进程，但父子进程二者的地址空间是各自独立的，子进程无法读取父进程的数据。文件目录：把所有FCB组织在一起，就构成了文件目录，即文件控制块的有序集合。目录文件：为了实现对文件目录的管理，通常将文件目录以文件的形式保持在外存，这个文件就是目录文件。进程上下文实际是进程执行活动全过程的静态描述。进程被抢占需要保存内容：1、所有CPU寄存器的内容，2、页表，3、程序计数器。在请求分页管理中，一个首次装入内存的页面可能来自：1、磁盘文件区；2、后备作业区；3、I/O缓冲池。逻辑地址到物理地址的映射，是由处理机中设置的专门硬件完成，即地址管理部件。页式的地址是一维的，段式的地址是二维的。用户程序引发磁盘I/O请求后，系统处理流程：用户程序 -&gt; 系统调用处理流程 -&gt; 中断处理程序 -&gt; 设备驱动程序。减少缺页中断（缺页错误、换页错误）：内存页框数，增加作业分得得内存块数页面大小。页面划分越大，中断率越低。替换算法的优劣影响缺页中断次数。程序局部性。程序局部性好可减少中断。总线是用于连接CPU、内存、外存和各种I/O设备并在它们之间传输信息的一组共享的传输线及控制电路。总线按功能和规范可分为五大类型：数据总线：在CPU与RAM之间来回传送需要处理或是需要储存的数据地址总线：用来指定在RAM之中储存的数据地址控制总线：将微处理器控制单元的信号，传送到周边设备，一般常见为USB Bus和1394 Bus扩展总线：可连接扩展槽和电脑局部总线：取代更高速数据传输的扩展总线各种虚拟存储都是时间换空间，缓冲是用空间换时间。利用通道实现了内存与外设之间数据的快速传输。sleep方法会给其它线程运行的集合，而不管其优先级。yield只会给优先级相同的或者比自己高的线程运行的机会。sleep会使线程进入阻塞状态，yield进入就绪。进程挂起的原因：1、终端用户的请求；2、父进程的请求；3、符合调节的需要；4、操作系统的需要。一般来说，磁盘I/O进程的优先权要高于计算进程。上下文切换需要完成：1、内存管理上下文；2、页表切换；3、切换内核态堆栈上下文数据；4、硬件上下文，主要部分为进程和CPU的任务状态寄存器。硬件的存取访问时间分为三个部分：寻道时间Ts，旋转延迟时间Tr，传送时间Tt。多关键字文件的特点是，在文件进行检索操作时，不仅仅对主关键词进行简单询问，还经常需要对次关键字进行其它类型的询问检索。（常见的有多重文件、倒排文件）管态，又叫特权态，系统态或核心态。当CPU处理系统程序的时间，CPU会转为管态，CPU在管态下可以执行指令系统全集（特权指令、非特权指令）。主存地址寄存器MAR和程序计数器PC的位数都取决于主存储器的容量，二者位数相等。文件操作是唯一依据是文件句柄。附笔记整理——算法（笔记整理三之一）笔记整理——计算机网络（笔记整理三之二）]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>computer os</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[笔记整理——计算机网络（笔记整理三之二）]]></title>
    <url>%2F2019%2F11%2F23%2F%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86%E2%80%94%E2%80%94%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%EF%BC%88%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86%E4%B8%89%E4%B9%8B%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[计算机网络的功能：1、数据交换与通信；2、资源共享；3、提高系统的可靠性和可用性；4、分布式网络处理。计算机网络中可以共享的资源包括：硬件、软件、数据、通信信道。应用层、运输层、网络层、链路层、物理层应用层、表示层、会话层、运输层、网络层、链路层、物理层应用层：HTTP、SMTP、FTP、（DNS）协议。网络应用程序及它们的应用层协议存留的地方。运输层：在应用程序端点之间传送应用层报文（不同主机应用进程之间的逻辑通信）。TCP、UDP协议。网络层：将数据报从一台主机移动到另一台主机。分组，不可靠服务。IP协议、OSPF协议（路由选择协议：转发和路由选择）。链路层：数据帧物理层：比特流TCP/IP协议包括：应用层、传输层、网络层、网络接口层。应用层应用层负责处理网络应用。（HTTP、FTP、SMTP）应用层协议定义了运行在不同端系统上的应用程序如何相互传递报文。报文定义为：报文类型、语法、语义、一个进程何时以如何时序发送报文，对报文的响应规则。HTTP使用TCP作为运输层协议，也是无状态协议：HTTP服务器并不保存关于客户的任何信息。并分为持续连接：HTTP默认使用带流水线的持续连接；非持续连接：必须为每一个请求的对象建立和维护一个全新的连接。FTP使用两个并行的TCP连接来传输文件，分为控制连接、数据连接（21、20端口）。一个控制连接可以对应多个数据连接，即控制连接贯穿了整个用户回话期间，但是对会话中的每一个文件传输都需要建立一个新的数据连接。DNS（域名系统）：1、一个由分层的DNS服务器实现的分布式数据库；2、一个使得主机能够查询分布式数据库的应用层协议。DNS协议运行在UDP之上，使用53端口号。DNS域名正向查询：通过域名得到IP的查询；反向查询：通过IP得到域名。迭代查询、递归查询。根DNS服务器、顶级域DNS（TLD）服务器、权威DNS服务器、本地DNS服务器。1、HTTP 2.x 相对于 HTTP 1.x 的区别：多路复用：允许同时通过单一的HTTP/2连接发起多重请求——响应消息。二进制分帧：改进传输性能，实现低延迟和高吞吐量。首部压缩服务端推送2、HTTP 1.1 相对于 HTTP 1.0 的区别：缓存处理：可以选择更多缓存控制策略。带宽优化和网络连接的使用错误的通知管理（新增24个错误状态响应码）Host处理长连接（keep alive）Cookie存在客户端，Session存在服务端。Http下cookie是明文传输的，Https下是密文传递的。子域名可以访问根域名的cookie，反之则不可。对于不同的浏览器，cookie大小由不同的限制。HTTP会话的四个过程：1、连接；2、请求；3、应答；4、关闭。运输层传输层负责端到端连接。进程通过socket的软件接口向网络发送报文和网络接收报文。（TCP、UDP、SPX）TCP面向连接服务，可靠数据传输、拥塞控制、流量控制、自动重传请求（ARQ）协议、rdt3.0停等协议（累计确认）。建立TCP连接需要三次握手，（三次握手）建立连接 -&gt; 传输报文 -&gt; 拆除连接。断开连接需要四次握手。客户端状态变化：CLOSED -&gt; SYN_SENT -&gt; ESTANBLISHED -&gt; FIN_WAIT_1 -&gt; FIN_WAIT_2（半关闭状态，有接收数据能力，但已经无法发送数据） -&gt; TIME_WAIT（等待状态，2MSL等待状态，第四次握手的保险状态） -&gt; CLOSED。服务端状态变化：CLOSED -&gt; LISTEN -&gt; SYN_RCVD -&gt; ESTABLISHED -&gt; CLOSE_WAIT -&gt; LAST_ACK -&gt; CLOSED。回退N步（GBN）、选择重传（SR）。慢启动、拥塞避免、快速恢复（AIMD：加增倍减）。带宽 X 时延 = 缓冲区大小。在一般的操作系统中TCP发送缓冲区默认值是4MB左右（有一定的自调节能力）。TCP中用16bit来表示窗口大小。滑动窗口提供TCP的可靠性，提供TCP的流控特性。（确认重传机制，重传情况下采用一种“指数退避”的方式）。（RST：表示重置连接、复位连接；RTT：连接的往返时间；RTO：重传超时时间）。1、一个连接中，有且仅有一个测量定时器被使用。也就是说如果TCP连续发出3组数据，只有一组数据会被测量。2、ACK数据报不会被测量，原因是没有ACK的ACK回应可以供结束定时器测量。TCP为了提高效率，允许重新传输的时候，只要传输包含重要数据报文就可以，而不用重传需要传输的报文。如果发送方收到接受方的窗口大小为0的TCP数据报文，发送端将会停止发送数据，等到接受方发送窗口大小不为0的数据报的到来。发送窗口上限值 = Min[接收窗口，拥塞窗口]SSL是一种对TCP的强化socket，强化是在应用层实现的。UDP无连接、不可靠数据传输，没有拥塞控制机制，不提供时延保证。伪头部用于检验和差错检测功能。TCP/UDP传输段中，源端口地址和目的端口地址不能相同，相同则是LAND攻击。DNS服务器之间传输时使用TCP，而客户端与DNS服务器之间传输时使用UDP。网络层网络层负责寻址和最短路径。（IP、IPX、APPLETALK、ICMP）路由选择算法：1、全局式路由选择算法；2、分散式路由选择算法。（LS算法：链路状态；DV算法：距离向量）自治系统内部的路由选择：路由选择信息协议（RIP协议：基于距离矢量的路由协议，一种DV算法）；开放最短路优先（OSPF：开放最短路径优化协议，一种LS算法）。自治系统间的路由选择：BGP（边界网关协议：一种DV算法）。RIP最多支持的跳数为15，即在源和目的的网间所要经过的最多路由器的数目为15，跳数为16表示不可达。ICMP：Internet控制报文协议，用于IP主机、路由器之间的传输控制消息（指网络通不通、主机是否可达、路由是否可用等网络本身的消息）；让其他所有需要知道自己处于哪个多播组的主机和路由器知道自己的状态。是TCP/IP协议族的一个子协议，用在网络层。PING使用的是ICMP协议。Traceroute：用于侦测主机到目的主机之间所经由路由情况（windows下是tracert)。查询报文：Ping查询、子网掩码查询、时间戳查询；差错报文：产生在数据传送发送错误时。IP地址：网络号 + 主机号。IP地址匹配遵循最长前缀匹配原则。IP数据报分片可能发生在信号源/路由器，而重组必须在目的主机。一般操作系统默认是没有路由功能的（需要自己配置）。ICMP的IP重定向报文：重定向报文只能由路由器发出；重定向报文为主机所用，而不是为路由器所用。集线器共享带宽，交换机独占带宽。路由器的每一个接口是一个广播域；交换机的每个接口是一个冲突域，交换机在未配置策略前是所有接口是一个广播域。集线器的所有接口是一个冲突域。链路层链路层为介入介质。提供服务：成帧、链路接入、可靠交付、差错检测与纠正（比特级）。（802.2、802.3、ATM（电路交换和分组交换的组合，53个字节，前5个为信头，完成寻址，后48为信息端）、HDLC、FRAME、RELAY、PPP）链路接入：媒体访问控制协议（MAC），规定帧在链路上传输规则。奇偶校验、二维奇偶校验（前向纠错）、循环冗余检测（CRC）。地址解析协议（ARP）：IP地址到MAC地址的转换。（RARP：逆地址解析协议）以太网中的最小帧长是根据网络检测冲突的最长时间来确定的。物理层二进制传输。物理层电路交换在发送数据前要建立一条端到端的路径。其他NAT地址转换实现了对用户透明的网络内部地址分配。QoS：服务质量。是网络的一种安全机制，是用来解决网络延迟和阻塞等问题的一种技术。（正常不需要）但对关键应用和多媒体应用就十分必要。当网络过载或拥塞时，QoS能确保重要业务量不受延迟或丢弃，同时保证网络的高效运行。数据网络中经历的总时延包括：发送时延、传播时延、排队时延、处理时延。负载均衡一般由第四层或第七层实现。VPN是互联网内用软件建立的安全隧道。附笔记整理——算法（笔记整理三之一）笔记整理——计算机操作系统（笔记整理三之三）]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[笔记整理——算法（笔记整理三之一）]]></title>
    <url>%2F2019%2F11%2F20%2F%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86%E2%80%94%E2%80%94%E7%AE%97%E6%B3%95%EF%BC%88%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86%E4%B8%89%E4%B9%8B%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[穷举法递推法迭代法辗转法，不断用变量的新值代替旧值的过程。分治法划分。把规模为N的原问题划分为K个规模较小的子问题，并尽量使K个字问题的规模大致相等。求解子问题。子问题的解法通常与原问题是相同的，可以用递归的方式求解，当子问题较小时，可以直接求解（或更快方式求解）。合并。把各个子问题的解合并起来。分治算法有效性很大程度上依赖于合并的实现。贪心法每一次获得局部最优解，若下一个数据与局部最优解连在一起不再时可行解，就不把该数据添加到局部解中，直到所有数据枚举完，或者不再添加为止。（需要选择度量方式）多阶段决策：指解决问题过程可分为若干阶段，在每一个阶段都做出相应的决策，所有的决策构成序列就是问题的解决方案。无后向性：指每一个阶段面临的问题都是原问题的一个子问题，并且子问题的解决只与当前阶段和以后的决策有关，与以前各阶段的决策无关。最优化原理：指一个问题的最优策略有这样一个性质，即不论以前的决策如何，对于当前的子问题，其余决策一定构成最优策略。动态规划法求解的问题必须满足：问题的状态必须满足最优化原理问题中的状态必须满足无后向性（下一个状态只与当前状态有关，与当前状态之前的状态无关）划分阶段：按照问题的时间或空间特征，把问题分为若干阶段。在阶段划分时，注意划分后的阶段一定要是有序或者时可排序的，否则问题就无法求解。确定状态和状态变量：将问题发展到各个阶段时所处的客观情况用户不同的状态表示出来。当然状态的选择要满足无后效性。确定决策并写出状态转移方程：因为决策和状态转移有着天然的联系，状态转移就是根据上一阶段的状态和决策来导出本阶段的状态。做法时根据相邻两阶段各状态之间的关系来确定决策。寻找边界条件：给定状态转移方程时一个递推式，需要一个递推的终止条件或边界条件。回溯法若当前位置探测到一条通路则继续向前，若在当前位置探测不到一条通路则回溯至前一位置继续探测尚未探测的方向，直到找到一条通路或探测出无通路存在为止。定义一个解空间，它包含问题的解利用适于搜索的方法组织解空间利用深度优先法搜索解空间利用限界函数避免移动到不可能产生解的子空间问题的解空间通常时在搜索问题的解的过程中动态产生的。适用于解一些组合数较大的问题。分支限界法一般采用广度优先策略或者最大收益（或者最小损耗）策略，同时利用最优解属性的上下界来控制搜索的分支。基本思想是对有约束条件的最优化问题的所有可行解空间进行搜索。具体执行时，把全部可行解空间不断分割为越来越小的子集（称为分支），并为每个子集内的解的值计算一个下界或上界，每次分支后，对凡是界限超出已知可行解值的那些子集不再做进一步分支。附笔记整理——计算机网络（笔记整理三之二)笔记整理——计算机操作系统（笔记整理三之三）]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>Algo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[工作沟通技巧笔记]]></title>
    <url>%2F2019%2F10%2F27%2F%E5%B7%A5%E4%BD%9C%E6%B2%9F%E9%80%9A%E6%8A%80%E5%B7%A7%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[问题分类封闭式问题：以动词开头，回答为有限选项。（拿自己的信息出来核对）校验自己的信息过滤器/观点等是否正确自己为信息的唯一提供者，只能核对自己掌握的信息可使目标信息更容易定位开放式问题：以谁/为什么/哪一个/什么/哪里/何时/如何开头，回答开放不定方向。（获得别人的信息）着眼于对方，将对方视为资源中心对方表达信息较多为自己提供更多信息，更宽广的视野技巧反馈：我看见/听见……（观察到的行为及事实）我认为……（观点和感受）你是怎么想的呢？/你觉得呢？/你能理解么？我建议/希望……会议：形成结论与总结形成todo并以邮件方式周知各位参加者倾听：目光接触关注，不做别的事回应（点头、嗯、肯定、提问）同理心倾听/共情不要抢话头总结：让别人知道你在倾听鼓励他们更多表达核对理解是否正确，减少误解梳理架构与思路使对方停止谈话（谈话松散等较多时）拉近彼此距离事情 -&gt; 结果 -&gt; 反馈， 形成闭环接到任务 -&gt; 善于提问项目启动 -&gt; 降低过滤器影响参加会议 -&gt; 随时反馈会议总结 -&gt; 使用合适的工具日常沟通 -&gt; 倾听与总结打破困境 -&gt; 3A（找对对方的关注点；能量场一致；果敢表达，观点明确）闭环反馈 -&gt; 做一个靠谱的人对一沟通：通过拉上相关同学拉一个较小的群沟通对多沟通：拉群和相关同学逐一私下约时间组织会议会议后总结发群（涉及todo等发送邮件）]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>Communicate</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[发发牢骚——读《白鹿原》]]></title>
    <url>%2F2019%2F09%2F08%2F%E5%8F%91%E5%8F%91%E7%89%A2%E9%AA%9A%E2%80%94%E2%80%94%E8%AF%BB%E3%80%8A%E7%99%BD%E9%B9%BF%E5%8E%9F%E3%80%8B%2F</url>
    <content type="text"><![CDATA[《白鹿原》被誉为一个民族的秘史。在读完后，能够明显感受到名不虚传。白鹿原讲述了半个世纪里在白鹿原上发生的事情。我已经很长一段时间里，不涉及与历史相关的事情了，或许是因为我在看了《明朝那些事儿》后，开始明白，我讨厌那些史书上讲述简短几句，描述平平无奇的一场变动。每本书都有自己所处于的角度，只是我无法适应这种角度罢了。读完一本书后，我总是在考虑我从这本书中得到了什么？不停的思考。就这本书中，确实有多处都让我得到了一些。比如终于找到了一本，以平凡人的一生来描述的历史了。终于明白需要更加清醒的认识问题，书中所树立的朱先生的偶像，或许正是多数人所崇拜的，刚正不阿。在不断思考我获得从书中获得了什么时，突然发现，我一直考虑掉了，我期望获得什么？我内心究竟期望从书中获得什么？我是抱着怎么一种心态来看这本书的呢？其实，我只是感觉这本书有趣，所以看这本书并不应该在意获得了什么？看书就应该当作闲时来的味剂。每次看到别人的一辈子如何去过活时，我也开始思考，我的这辈子怎么过活。我终究现在还不明白我究竟要选择怎样的一种生活？从小到大以来，我的选择都是顺从着现实而来的，没有换一个角度，顺从心的角度来选择。我的心里依然迷惘，我该选择如何过活下去？我顺其自然的成为了一名程序员，顺其自然的开始写代码，并且顺其自然的喜欢代码。但是我不明白，我选择代码是否正确。正如我有时候在提醒自己，不能太沉入代码了？换一个角度或者提升一个高度可以看到另一个问题，或者可以更加明白问题的本源。顺其自然的成为现在的我的状态。其实也有本质原因，没有财富自由，也没有那种为了财富自由的拼命三郎的精神。总之，我还不明白我究竟想做什么。已经不会写读后感了，只是我随便发的牢骚。]]></content>
      <categories>
        <category>read</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[以一颗艺术的心做事]]></title>
    <url>%2F2019%2F07%2F22%2F%E4%BB%A5%E4%B8%80%E9%A2%97%E8%89%BA%E6%9C%AF%E7%9A%84%E5%BF%83%E5%81%9A%E4%BA%8B%2F</url>
    <content type="text"><![CDATA[在理发时，突然想到，对于理发师来说，理发究竟是什么？他们是一种什么样的心来理发的呢？是敷衍了事，还是精益求精，还是有一定的心情波动呢？其实可以类推，对我来说，写代码是一种生活必要的工作技能。写代码的时候都是严谨并全身心的投入的。以一种设计的方式来实现功能。以一颗艺术的心做事。其中有两个要点，第一点是做事，第二点是以艺术的心来做。做事，就是实现原本的目的。比如理发，第一目的是将头发以某种方式剪短，如果不管以什么方式来设计或者什么手法来表演，没有讲头发剪短都不能称为理发。不能实现目的的设计或艺术都是没有意义的。因此不管自己拥有多高的设计灵感，没有实现本来目的都没有意义。以艺术的心做事。为何以艺术的心做事？如何能将一件事做的很好，那便是有技巧的且仔细的去做。那么和别人来做有什么差别呢？因此需要找到自己做事情的特色，我认为艺术便是一种特色。每个人都有自己的特色，因此在事情上也会体现出自己相对应的特色。比如理发，理发师会表现出自己对于别人头型适用哪种发型做自己建议，以及哪种方式的剪法会看起来优美。正如设计代码一样，如何写出一份自己特色的代码，并且让别人看着赏心悦目。艺术的心做事，其实主要在于自己对于“事”本身的理解会有多深了。刚开始只能做到做事的这个程度，随着自己对于做事的深入了解，明白如何更加严谨的做事。再后来，就开始考虑如何设计“事”这个本身，以及按照自己的喜好来做事。总的来讲，需要加深自己对于做事的理解。我有时候会偏离自己做事的主题，在不断的考虑如何“做好”这件事，太过于注重设计与优美，而有时候忘了做事的本身。自己在考虑以一颗艺术的心做事时，需要多考虑事这个本身，自己这样做是否事真的围绕着做事这个本身来进行的。或者多问自己几遍——“你真的想做的是什么？真的想做的是这个吗？”。以一颗艺术的心做事，首先是做事，其次是以艺术的心来做。]]></content>
      <categories>
        <category>other</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[读《杀死一只知更鸟》]]></title>
    <url>%2F2019%2F07%2F13%2F%E8%AF%BB%E3%80%8A%E6%9D%80%E6%AD%BB%E4%B8%80%E5%8F%AA%E7%9F%A5%E6%9B%B4%E9%B8%9F%E3%80%8B%2F</url>
    <content type="text"><![CDATA[知更鸟代表什么为什么书名为“杀死一只知更鸟”？知更鸟代表的是什么？阿蒂克斯有一天对杰姆说：“我宁愿你在后院射易拉罐，不过我知道，你肯定要去打鸟的。你射多少蓝鸟都没关系，但要记住，杀死一只知更鸟就是一桩罪恶。”为什么杀死一只知更鸟就是一桩罪恶呢？首先这种事需要反过来考虑，为什么要杀死知更鸟，对孩子来说，只是为了好玩。并且知更鸟是一种无害的鸟。因此杀死一只知更鸟就象征着杀死一个无辜的人。在书中三十章，经历尤厄尔先生的死后，斯库特同意泰特先生的做法。“噢，如果是那样做，差不多就像杀死一只知更鸟，不是吗？”在这儿，虽然拉德利保护杰姆和斯库特而杀了尤厄尔。不管如何理清这件事情，都会打破拉德利的隐居生活。在我看来，一个对你和全镇做过这么大贡献的人，无视他的隐居习惯，把他硬拉去曝光——对我来说，这就是犯罪。做孩子的榜样从书中而来，领悟最多的就是，如何做孩子的榜样。有人说过，孩子就是父母的影子，会参照父母做的去做。做孩子的榜样，需要有书中所描述的教养、勇气、平等。曾看到一张图，一家人在地铁排队给孩子做榜样。教养便是一些潜移默化的事情影响，以及父母对孩子的引导。在现代里，越来越多的父母对孩子只注重成绩，并不在意其他思维、个性等成长。就我来说，从小在个性上就有很大的缺陷，在交流上一直不够好，便一直影响自己。当你还未开始就已经知道自己会输，可你依然要去做，而且无论如何都要把它坚持到底。你很少赢。但有时也会。对孩子，需要培养他们的勇气，当然需要好好区分出勇气与胆大妄为。当两个孩子发生矛盾后，你该如何做？不管怎样，都应该首先听两个孩子的所有诉说，不应该只听某一个孩子的片面之词。也不应该说什么年龄大的孩子就应该迁就着小的孩子。对孩子来说，期望得到的就是公平。他们希望得到的是公平的对待。当然，需要向孩子展现出对正义的向往。当你最终了解他们时，你会发现，大多数人都是好人。总结来说，做好榜样有太多需要注意了，最重要的还是需要培养一颗有趣且爱着这个世界的心。]]></content>
      <categories>
        <category>read</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Redis总结]]></title>
    <url>%2F2019%2F06%2F03%2FRedis%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[背景为什么我会学习Redis？原因很简单，因为工作上需要使用。因此在不懂其原理以及其特性的情况下使用，会在一些情况下使用错误，以及造成一些错误的影响。理解工具的原理才能更好的使用工具。本文主要为读《Redis开发与运营》的总结，以及一些扩展。本文总结较长，建议使用电脑，按照目录择章阅读。基础Redis中主要提供5种数据结构：string（字符串）、hash（哈希）、list（列表）、set（集合）、zset（有序集合）。并且基于字符串的基础上演变出了Bitmaps（位图）、HyperLogLog。随着LBS（基于位置服务）发展，在Redis3.2中加入了GEO（地理信息定位）。同时，Redis支持键过期、发布订阅、Lua脚本、简单事物、流水线（Pipeline）功能。Redis为什么速度快？1、Redis中所有的数据都是存储在内存中；2、Redis使用C语言实现；3、Redis使用单线程架构，预防多线程可能产生的竞争问题。Redis中每个类型有多种的内部编码，通过object ebcoding命令查询内部编码。Redis中对每个数据结构，在内部根据不同的情况，使用不同的内部编码实现，可以在不同情况下发挥自己各自的优势。string（字符串）常用命令设置值：set key value [ex seconds] [px millesenconds] [nx|xx]（nx：键必须不存在才能设置成功，xx反之）。setex = set ex，setnx = set nx。批量设置值：mset key value [key value ...].获取值: get key。批量获取值：mget key [key ...]。注意：每次批量操作所发送的键数不是无节制的，如果数量过多可能造成Redis阻塞或者网络拥塞。自增: incr key。内部编码int 8个字符的长整型embstr 小于等于39个字节的字符串raw 大于39个字节的字符串hash（哈希）常用命令设置值：hset key field value。批量设置值：hmset key field value [field value...]。获取值：hget key field。批量获取值：hmget key field [field ...]。内部编码ziplist（压缩列表）hashtable（哈希表）当field个数较少且没有大value时，内部编码为ziplist；当value大于64字节，转变为hashtable；当field个数超过512，内部编码变为hashtable。扩容扩容是一个很有趣的地方。相对于ConcurrentHashMap的多线程协同式rehash，Redis采用单线程渐进式rehash。多线程协同rehash可以参照《ConcurrentHashMap 源码分析（Java version 1.8）》的扩容部分。而单线程渐进式rehash，主要是将拷贝节点数据的过程平摊到后续的操作中，而不是一次性拷贝。其过程是，在写的时候，当发现正在扩容，则负责将目前元素执行的老的哈希桶的元素，迁移到新的hash中，如果发现已经迁移完成则不操作。而在读的时候，则先查询老的hash中是否有数据，没有则查找新的hash中。单线程渐进式rehash和多线程协同式rehash对比：ConcurrentHashmap的整个扩容操作，消耗时间短，因此对内存的占用也更短；写操作中，Redis会更快返回，因此多线程协同会去协助扩充操作；读操作中两者基本相似。在Redis的本身是单线程执行中，采用了这种设计方式，刚好使用空间兑换了时间的做法，完美避免了阻塞。而ConcurrentHashmap中，实现了多线程下的安全性，并通过多线程协作的方式，减短了在写操作时为了保证线程安全性的阻塞时长。list（列表）列表中的元素是有序的；列表中的元素可以是重复的。常用命令设置值：rpush key value [value ...]; lpush key value [value ...]。插入元素：linsert key before|after pivot value。顺序找到第一个等于该值的元素，在前面或者后面插入元素。获取值：lrange key start end: 获取key对应value内指定范围的元素列表（左右都取闭区间）。修改值：lset key index rewValue，修改指定索引下标的元素。删除元素：lrem key count value，从列表中找到等于value的元素进行删除。count &gt; 0，从左到右，删除最多count个元素；count &lt; 0，从右到左，删除最多count绝对值个元素；count = 0，删除所有。lpop key; rpop key.blpop key [key ...] timeout; brpop key [key ...] timeout。如果存在则直接返回，如果不存在则等待timout时间，timeout为0则代表一直阻塞。内部编码ziplist（列表元素个数小于512，同时值都小于64字节）linkedlistquicklist（Redis 3.2版本提供。简单说是一个以ziplist为节点的linkedlist，结合了两者的优势）set（集合）常用命令增加值：sadd key element [element ...]删除值：srem key element [element ...]随机弹出元素：spop key，需要注意这个并不删除元素。集合操作：求交集：sinter key [key ...]求并集：sunion key [key ...]求差集：sdiff key [key ...]（相当于并集减交集）使用sinterstore destination key [key ...]、sunionstore ...、sdiffstore ...运算交集、并集、差集的结果并保存。（集合间操作在元素比较多的情况下会比较耗时，因此Redis提供计算并存储命令，计算结果保存到destination key中）。内部编码intset（整数集合），当集合元素是整数且元素个数小于512时hashtablezset（有序集合）常用命令增加值：zadd key score member [score member ...]，集合通过score排序。注意：Redis 3.2中添加了nx（不存在才能设置成功）、xx（与nx相反）、ch（返回此次操作后集合中的元素和分数发生变化的个数）、incr（对score增加，相当于zincry）选项。返回指定排名范围的成员：zrange key start end [withscores]，按照分数从低到高返回; zrevrange key start end [withscores]，按照分数从高到低返回。start和end都是闭区间。返回指定分数范围的成员：zrangebyscore key min max [withscores] [limit offset count]，按照分数从低到高返回；zrevrangebyscore反之。[limit offset count]可以限制输出的起始位置和个数。min和max支持开区间（小括号）和闭区间（中括号），-inf和+inf分别代表无限小和无限大。集合操作：交集：zinstore destination numkeys key [key ...] [wights weight [weight ...]] [aggregate sum|min|max]。numkeys：需要做交集计算键的个数；key [key ...]：需要做交集计算的键；wights weight [weight ...]：每个键的权重，在做交集计算时，每个键中的每个member会将自己的分数乘以这个权重，每个键的权重默认时1。aggregate sum|min|max：计算成员交集后，分值按照sum、min、max做汇总，默认值是sum。并集：zunionstore destination numkeys keu [key ...] [weights weight [weight ...]] [aggregate sum|min|max]。内部编码ziplist，有序集合元素个数小于128，且每个元素的值都小于64skiplist其他键重命名rename key newkey、renamenx ...由于重命名健期间会del命令删除旧的键，如果键对应的值比较大，会存在阻塞Redis的可能。键过期expire key seconds: 键在seconds秒后过期；expireat key timestamp: 键在秒级时间戳timestamp后过期。对于字符串类型键，执行set命令会去掉过期时间；set时需要重新设置过期时间。setex是set + expire的组合，原子操作，并且减少了一次网络通讯时间。注意：Redis不支持二级数据结构（例如哈希、列表）内部元素的过期功能。迁移键move（基本废弃）dump + restore整个迁移过程中不是原子性的，而是通过客户端分步完成的；迁移过程中的是开启了两个客户端的连接，所以dump的结果不是在源Redis和目标Redis之间进行传输（通过客户端）。migrate实际上migrate就是将dump、restore、del三个命令进行组合，简化了操作流程。migrate具有原子性migrate命令的数据传输直接在源Redis和目标Redis上完成。目标Redis完成Restore后发送OK给源Redis，源Redis会根据migrate对应的选项来决定是否在源Redis上删除对应的键。遍历键keys支持pattern匹配，进行全量遍历。会阻塞Redis。scan采用渐进式遍历来解决keys命令可能带来的阻塞问题，每次执行scan命令的时间复杂度是O(1)，真正要实现keys的功能需要多次scan。对于可能产生阻塞问题的hgetall、smembers、zrange等，都用对应的hscan、sscan、zscan命令。注意：scan并不能保证遍历出所有的键。（遍历过程中某些键发生变化时，可能会有没遍历出来某个键或者遍历出重复键情况）扩展功能慢查询分析slowlog-log-slower-than配置（单位微秒）：通过这个配置，如果命令执行时间大于这个预设值，则记录到慢查询日志中。注意，slowlog-log-slower-than=0会对记录所有的命令，而小于0则代表对任何命令都不进行记录。slowlog-max-len：代表慢查询日志最多存储多少条，这是一个先进先出队列。配置建议：可以增大slowlog-max-len的配置，并不会占用大量内存。slowlog-log-slower-than的默认配置是10ms。对于高QPS场景的Redis建议设置成1ms。（实际客户端执行的时间等于命令执行时间以及网络传输等时间，因此大于实际执行时间）Redis Shellredis-cli（及相关参数）redis-serverredis-benchmark（为Redis做基准性能测试）PipelinePipeline（流水线）操作可以减少网络传输，实现通过一次网络传输执行多个Redis命令。目前如mget、mset等批量操作也可以有效减少网络延时（RTT）。不得不说其区别，mget、mset是只能在一个批量操作中执行get、set的一类操作，并且其执行是原子性的，而Pipeline没有对执行命令的限制，而执行也不是原子性的。后续会讲到在Redis Cluster中建议都使用Pipeline的操作。Pipeline执行时，需要注意其中命令的数量，命令数量过多，会加大客户端等待时间，也会造成一定的网络阻塞。建议将一个大的Pipeline操作拆分成几个小的Pipeline完成。事务与Lua事务：multi、exec、discard。Redis提供watch命令来确保事务中的key没有被其他客户端修改过。Lua脚本优点：原子性，Lua脚本在Redis中的执行是原子性的开发人员可以自定义命令可以将多条命令一次性打包，有效减少网络开销注意：在执行中，如果Lua脚本已经执行过写操作，那么script kill将不会生效。（这种情况下只能等待执行结束，或者停掉Redis服务）Bitmaps和HyperLogLogBitmaps本质是字符串，但是可以对字符串的位进行操作。HyperLogLog是一种基数算法，可以利用极小的内存空间完成独立总数的统计。Redis官方给出0.81%的失误率。发布订阅subscribe、psubscribe、unsubscribe、punsubscribe。Redis不会对发布的消息进行持久化，无法实现消极堆积、回溯等。不够专业但足够简单。GEORedis 3.2中提供了GEO功能，用来实现基于地理位置信息的应用，底层实现是zset。客户端客户端与服务端之间的通信协议是基于TCP协议构建的。通过RESP（Redis系列化协议）实现客户端与服务端的正常交互。通过直连的方式无法限制Redis客户端对象的个数，在极端情况下可能造成连接泄露，而连接池的形式可以有效的保护和控制资源的使用。（直连的方式，适用与少量长期连接的场景；连接池的方式，降低了开销，并且对资源的使用进行了保护和控制）。Redis提供maxclients参数限制客户端连接数，默认值是1000，如果连接数超过，则新的连接将被拒绝。Jedis连接池使用时，将连接池大小设置为比默认最大连接数（8个）多一些即可。Redis为每个客户端分配了输入缓存区，作用是将客户端发送的命令临时保存，通过Redis会从输入缓存区拉取命令并执行，输入缓存区为客户端发送命令到Redis执行命令提供缓冲功能。要求每个客户端缓冲区的大小不能超过1G，超过后客户端将被关闭。Redis为每个客户端分配了输出缓冲区，作用是保存命令执行的结果返回客户端，为Redis和客户端交互返回结果提供缓冲。输出缓冲区分为3种：普通客户端、发布订阅客户端、slave客户端。输出缓冲区由两部分组成：固定缓冲区（16KB）、动态缓冲区。固定缓冲区使用的是字节数组，动态缓冲区使用的是列表。持久化Redis支持RDB和AOF两种持久化机制。RDBRDB持久化是把当前进程数据生成快照保存到硬盘的过程，触发RDB持久化过程分为手动触发和自动触发。手动触发对应save和bgsave命令。save会阻塞当前Redis服务，直到RDB过程完成为止，已经废弃。`bgsave是在Redis进程执行fork操作创建子进程，然后由子进程负责RDB过程，并自动结束，阻塞只发生在fork阶段。Redis默认采用LZF算法对RDB文件进行压缩处理。RDB的优缺点优点：RDB是一个紧凑的压缩的二进制文件，代表Redis在某个时间点上的数据快照。非常适用于备份，全量复制等。Redis加载RDB恢复数据远远快于AOF的方式缺点：RDB方式数据没办法做到实时持久化/秒级持久化。RDB文件使用特定的二进制格式保存。因版本演进过程中有多个格式的RDB版本，存在老版本Redis服务无法兼容新格式的问题。AOFAOF：以独立日志的方式记录每次写命令，重启时再重新执行AOF文件中的命令达到恢复数据的目的。主要解决了数据持久化的实时性。所有的写入命令都会追加aof_buf（缓冲区）中。AOF缓冲区根据对应的策略向硬盘中做同步操作。随着AOF文件越来越大，需要定期对AOF文件进行重写，达到压缩的目的。当Redis服务器重启时，可以加载AOF文件进行数据恢复。AOF采用文本协议格式，并将命令直接追加在aof_buf中。先写入缓冲区aof_buf中，Redis可以提供多种缓冲区同步到硬盘的策略，在性能和安全性方面做出平衡。aways：命令写入aof_buf中后调用系统fsync操作同步到AOF文件，fsync完成后线程返回。erverysec：fsync同步文件操作由专门线程每秒执行一次no：同步操作由操作系统负责，通常同步周期最长30秒AOF重写机制用来压缩文件体积。重写过程可以手动触发和自动触发。在AOF重写中，会从父进程fork出子进程，子进程执行AOF重写。这段时间主进程继续响应命令，Redis使用“AOF重写缓冲区”保存这部分新数据，防止新AOF文件生成期间丢失这部分数据。Redis使用另一条线程每秒执行fsync同步硬盘，当系统硬盘资源繁忙时，会造成Redis主线程阻塞。由上图刷盘策略发现：erverysec配置最多可能丢失2秒数据，不是1秒。如果系统fsync缓慢，将会导致Redis主线程阻塞影响效率。注：单机下部署多个实例时，为了防止出现多个子进程执行重写操作，建议做隔离控制，避免CPU和IO资源竞争。复制复制功能是高可用Redis的基础。salveof: 从从节点发起，当前服务丢弃旧有数据集，同步新数据集。slave no one：断开复制。如果要求低延迟时，建议同机架或同机房部署并关闭repl-disable-tcp-nodelay；如果考虑高容灾性，可以同城跨机房部署并开启repl-disable-tcp-nodelay（在主节点设置）。拓扑拓扑可以分为三种：一主一从、一主多从、树状主从结构。一主一从：主节点出现宕机时从节点提供故障转移支持。当应用写命令并发量较高且需要持久化时，可以只在从节点上开启AOF。（需要避免主节点脱机重启，重启前需要断开主从关系，避免从节点的数据被清空）。一主多从：主要用于读多写少的读写分离场景。树状结构：引入复制中间层，可以有效降低主节点负载和需要传送给从节点的数据量。原理首先，执行slaveof的复制过程：保存主节点信息主从建立socket连接发送ping命令（检测主从之间网络嵌套字是否可用；检测主节点当前是否可接受处理命令。）权限验证同步数据集（首次建立复制的场景，主节点会把持有的数据全部发送给从节点，这部分操作时耗时最长）命令持续复制从节点（slave）内部通过每秒运行的定时任务维护复制相关逻辑，当定时任务发现存在新的主节点后，会尝试与该节点建立网络连接。数据同步分为全量复制和部分复制。全量复制一般用于初次复制场景，当数据量较大时，会对主从节点和网络造成很大的开销。部分复制，用于处理在主从复制中因网络闪断等原因造成的数据丢失场景。部分复制命令psync需要哪些组件支持呢？主从节点各自的复制偏移量主节点（master）在处理完写命令后，会把命令的字节长度做累加记录，统计信息在info replication中的master_repl_offset指标中。从节点（slave）每秒上报自身的复制偏移量给主节点。（主节点也会保存从节点的复制偏移量）通过比较主从节点的复制偏移量，可以判断主从节点数据是否一致。同时判断当前复制的健康度。主节点复制积压缓冲区复制积压缓冲区是保存在主节点上的一个固定长度的队列，默认大小为1MB。（先进先出的固定长度队列）主节点运行id每个Redis节点启动后都会动态分配一个40位的十六进制字符串作为运行ID。主要用来唯一识别Redis节点。主节点重启变更了整体数据集（如替换RDB/AOF文件）从节点再基于偏移量复制数据将是不完全的，因此当运行ID变化后从节点将做全量复制。（需要注意Redis关闭再启动后，运行ID会变，因此会全量复制。）psync {runId} {offset}：runId指从节点所复制主节点运行id，默认值为?；offset指从节点已复制的数据偏移量，默认值为-1。主节点根据psync参数和自身数据情况决定响应结果。+FULLRESYNC {runId} {offset}：从节点进行全量复制+CONTINUE：部分复制+ERR：主节点版本低于Redis 2.8。无法识别psync命令，从节点将发送旧版sync命令触发全量复制流程。全量复制在传输RDB文件这步上非常耗时，可以通过日志算出RDB文件从创建到传输完成消耗的总时间。如果总时间超过repl-timeout所配制的时间（默认60秒），从节点将放弃接受RDB文件并清理已经下载的临时文件，导致全量复制失败。无盘复制：为了降低主节点磁盘开销，Redis支持无盘复制，生成的RDB文件不保存到磁盘而直接通过网络发送给从节点。适用于主节点所在机器磁盘性能较差但网络带宽较充裕的场景。在RDB文件创建到传输完成这段时间内的写命令，主节点将这些命令数据存在复制缓冲区。如果这段时间过长，对于高写入的场景容易造成主节点复制客户端缓冲区溢出。（默认为60秒缓冲区消耗持续大于64MB或者直接超过256MB）。运维人员需要根据主节点数据量和写命令并发量调整client-output-buffer-limit slave配置，避免全量复制期间客户端缓冲区溢出。对于读写分离场景，Redis复制提供slave-server-stale-data参数（默认开启），复制期间，冲节点依然可以响应所有命令。总结，全量复制整体时间分为几个部分。主节点bgsave时间RDB文件网络传输时间从节点清空数据时间从节点加载RDB时间可能的AOF重写时间部分复制当主从节点间网络出现中断，如果超过repl-timeout时间。主节点会认为从节点故障并中断复制连接。部分复制中，主节点内部存在复制积压缓冲区，可以保存最近一段时间的写命令数据，默认最大缓存1MB。心跳主从节点都有心跳检测机制，各自模拟成对方的客户端进行通信。主节点默认每隔10秒对从节点发送ping命令，判断从节点的存活性和连接状态。从节点在主线程中每隔1秒发送replconf ack {offset}}命令，上报自身的复制偏移量。其主要作用有：1）实时监测主从节点网络状态；2）上报自身复制偏移量，检查复制数据是否丢失，如果从节点数据丢失，再从主节点的复制缓冲区中拉取丢失数据；3）实现保证从节点的数量和延长性功能。为了降低主从延迟，一般把Redis主从节点部署在相同的机房/同城机房，避免网络延迟和网络分区造成的心跳中断等情况。Redis主节点不但负责数据读写，还负责把写命令同步给从节点。写命令的发送过程是异步完成的。其他读写分离：将读流量分摊到从节点上，只对主节点执行写操作。其中可能会遇到一些问题：1）复制数据延迟；2）读到过期数据；3）从节点故障。注意：避免复制风暴。复制风暴指大量从节点对同一主节点或者对同一台机器的多个主节点短时间内发起全量复制。内存mem_fragmentation_ratio表示内存碎片，当大于1时，代表有内存碎片。如果这个值特别大，说明碎片率相当严重。当小于1，一般出现在操作系统把Redis内存交换（Swap）到硬盘导致，这种情况需要格外注意，由于硬盘速度远远慢于内存，Redis性能会变得很差，甚至僵死。消耗Redis进程内消耗主要包括：自身内存 + 对象内存 + 缓冲内存 + 内存碎片。一个空的Redis进程消耗内存可以忽略不计。对象内存，存储用户所有的数据。在使用Redis时很容易忽略键对内存消耗的影响，应当避免使用过长的键。缓冲内存主要包括：客户端缓冲、复制积压缓冲区、AOF缓冲区。客户端缓冲区指所有接入到Redis服务器TCP连接的输入输出缓冲。其中分为多种客户端。1）普通客户端：指除了复制和订阅的客户端之外的所有连接，Redis默认没有对普通客户端的输出缓冲区做限制，一般普通客户端的内存消耗可以忽略不计；2）从客户端：主节点为每个从节点单独建立一条连接用于复制命令，建议主节点挂载从节点不要多于2个，主节点不要部署在较差的网络环境下；3）订阅客户端。复制积压缓冲区在整个主节点只有一个，所有从节点共享此缓冲区。可以设置较大的缓冲区空间，这个部分投入可以有效避免全量复制。内存碎片：在 1）频繁做更新操作和2）大量过期键删除，键对象过期删除后，释放的空间无法得到充分的利用的情况下，容易出现高内存碎片问题。其中解决方式有数据对齐和安全重启。子进程内存消耗：子进程内存消耗主要指执行AOF/RDB重写时Redis创建的子进程内存消耗。Redis产生的子进程并不需要消耗1倍的父进程内存，实际消耗根据期间写入命令量决定，但是依然要预留一些内存防止溢出；需要设置sysctl vm.overcommit_memory=1允许内核可以分配所有的物理内存，防止Redis进程执行fork时因系统剩余内存不足而失败；排查系统是否支持并是否开启THP。管理maxmemory最大可用内存。主要用于缓存场景（超过后使用LRU释放空间），防止内存超过服务器物理内存。Redis支持动态修改maxmemory值，可以动态伸缩Redis内存。（Redis默认无限使用服务器内存，为了防止极端情况，建议所有的Redis进程都配置该值）Redis内存回收机制分为两种：删除过期对象，达到maxmemory溢出策略。Redis中过期数据删除策略分为两种：惰性删除，从节点不会主动删除超时数据，主节点每次处理读取命令时，都会检查键是否超时；定时删除：Redis主节点进行定时任务采样一定数据量的键，当发现采样的键过期，则删除（默认每秒10次）。在Redis 3.2中增加了，从节点读取数据之前检查键的过期时间来决定是否返回数据。为什么在慢模式下执行超时后，需要改为快模式执行呢？在快模式下，超时时间为1毫秒，且2秒内只能运行一次。其中减少了超时时间，并且降低了执行频率。目的是为了保证对主线程不造成性能的影响。内存溢出控制策略：noeviction：默认策略，不会删除任何数据，达到上限时返回OOMvolatitl-lru：达到上限时根据LRU删除设置了超时属性的键allkeys-lru：根据LRU算法删除键（不考虑是否设置了超时属性）allkeys-random：随机删除所有键，直到腾出足够空间为止valatile-random：随机删除有超时属性的键valatile-ttl：根据键值对象ttl属性，删除最近将要过期数据。可以通过设置成allkeys-lru策略把Redis变为纯缓存服务器使用。每次Redis执行命令时，如果设置了maxmemory参数，都会尝试进行内存回收操作（不一定执行），如果使用内存大于上限值，则会根据一定当前策略进行回收。优化redisObject对象结构如下：缩减key和value的长度，value可以通过压缩降低内存占用。（当频繁压缩解压时，需要考虑压缩和解压的开销成本）共享对象池是指Redis内部维护[0-9999]的整数对象池。当设置了maxmemory并启用了LRU相关淘汰策略，Redis禁止使用共享对象池。对于ziplist编码的值对象，即使内部数据为整数也无法使用对象池，因此ziplist使用压缩且内存连续的结构。对象共享判断成本过高。Redis自己实现了字符串结构，内部简单动态字符串（SDS）。尽量减少字符串频繁修改操作，如append、setrange，改为直接使用set修改字符串，降低预分配带来的内存浪费和内存碎片化。使用二级存储也能帮我们节省内存。编码编码就是具体使用那种底层数据结构来实现。通过不同的编码实现效率和空间的平衡。编码类型转换在Redis写入数据时自动完成，这个转换过程时不可逆的，转换规则只能从小内存编码向大内存编码转换。可以使用config set命令设置编码相关参数来满足使用压缩编码的条件。对于已经采用非压缩编码类型的数据，如hashtable`linkedlist`等，设置参数后即使数据慢煮编码条件，Redis也不会做转换，需要重启Redis重新加载数据才能完成转换。ziplist主要目的是为了节约内存，采用线性连续的内存结构。ziplist其数据结构特点如下：一块连续内存数组可以模拟双向列表结构，以O(1)实际复杂度入队出队新增、删除操作涉及内存重新分配或释放，加大操作的复杂性读写超过涉及复杂的指针移动，最坏时间复杂度为O(n^2)适合存储小对象和长度有限的数据针对性能要求较高的场景使用ziplist，建议长度不要超过1000，每个元素大小控制在512字节以内。intset：存储有序、不重复的整数集。intset编码结构包括encoding`lengthcontents`。其中类型是根据长度划分，当保存的整数类型超过当前类型，会自动触发升级并且升级后不再回退。使用intset编码的集合时，尽量保持整数范围一致，防止个别大整数导致集合元素类型升级，产生内存浪费。其他Redis内存不足时，首先考虑的问题不是加机器做水平扩展，应该先尝试做内存优化，当遇到瓶颈时在去考虑水平扩展。Redis SentinelRedis Sentinel（哨兵）是一种Redis高可用实现方案。其中包括若干个Sentinel节点和Redis数据节点。每个Sentinel节点会对数据节点和其余Sentinel节点进行监控。当发现节点不可达时，进行标记。如果该节点是主节点，该Sentinel节点将和其他Sentinel节点进行协商，如果大多数节点认为主节点不可达，会选举出一个Sentinel节点来完成自动故障转移。Sentinel节点本质是一个特殊的Redis节点。Redis Sentinel中的数据节点和普通的数据节点在配置上没有区别，只增加了一些Sentinel节点对它们进行监控。生产环境中建议Redis Sentinel的所有节点应该分布在不同物理机上。Sentinel节点数和数据节点的数量没有关系。只至少需要3个Sentinel节点来保障系统的健壮性。配置中&lt;quorum&gt;用于故障发现和判定，至少有quorum个Sentinel节点认为主节点不可达，则认为该节点客观不可达。一般建议设置为Sentinel节点的一半加1。down-after-milliseconds配置代表用于判断超过时间并有有效回复则判定节点不可达。其对于Sentinel节点、主节点、从节点的失败判定同时有效。parallel-syncs用来限制在一次故障转移后，每次向新的主节点发起复制操作的从节点个数。failover-timeout的作用较多。1）当对一个主节点故障转移时，下次转移起始时间是failover-timeout的两倍；2）在晋升选出的从节点为主节点时，如果在选出的从节点上执行slaveof no one一直失败，如果超过这个时间，则故障转移失败；3）Sentinel节点执行info命令来确实选出的从节点晋升主节点，这个阶段超时则故障转移失败；4）在命令其余从节点复制新的主节点时，如果超过这个时间（不包含复制时间）则故障转移失败。注意：即使从节点复制主节点阶段超过这个时间，Sentinel节点也会最终配置从节点去同步最新的主节点。一套Sentinel可以监控多个主节点，一般根据是否是同一个业务的多个主节点集合来判断是否监控多个主节点。原理每隔10秒，每隔Sentinel节点向主节点和从节点发送info命令获取最新的拓扑结构每隔2秒，每隔Sentinel节点向Redis数据节点__sentinel__:hello频道上发送该Sentinel节点对主节点的判断以及当前Sentinel节点的信息，同时每个Sentinel节点也会订阅该频道，用于了解其他Sentinel节点以及它们对主节点的判断。（发现新的Sentinel节点，交换主节点的状态）每隔1秒，每个Sentinel节点会向主节点、从节点、其余Sentinel节点发送ping命令做一次心跳检测，确认这些节点当前是否可达。下线主观下线：在每个Sentinel节点每隔1秒对其他所有节点发送ping命令做心跳检测，如果这些节点在down-after-milliseconds没有进行有效回复，则该Sentinel节点对该节点做失败判定。客观下线：当判断主观下线时，该Sentinel节点通过sentinel is-master-down-by-addr命令向其他Sentinel节点询问对主节点的判断，当超过&lt;quorum&gt;时，则认为主节点确实有问题，这时做出客观下线的决定。选举Redis在进行客观下线后，Sentinel节点通过选举选出领导者，领导者进行故障转移工作。其中使用Raft算法实现领导者选举。故障转移从列表中选出一个节点作为新的主节点Sentinel领导者节点对选出的节点执行slaveof no one命令Sentinel领导者节点向其他从节点发送命令，让它们成为新主节点的从节点原来的主节点更新为从节点，当恢复后命令它复制主节点其他部署各个节点的机器时间尽量要同步，否则日志的时序性会混乱。（NTP服务）Sentinel节点依然会对这些下线节点进行定期监控。Redis Sentinel实现读写分离高可用可以依赖Sentinel节点的消息通知，获取Redis数据节点的状态变化。集群Redis分布式方案一般有两种：客户端分区方案，代理方案。官方提供Redis Cluster。数据分布式数据库需要解决将数据集划分到多个节点上，每个节点负责整体数据的一个子集。常见分区规则有哈希分区、顺序分区。节点取余当节点扩容或收缩节点，数据节点映射关系需要重新计算，导致数据的重新迁移。一致性哈希：为系统中的每个节点分配一个token（0～2^32），这些token组成哈希环。数据读写操作时，根据key计算hash，然后顺时针找到第一个大于等于该哈希值的token节点。加减节点会造成哈希环中部分数据无法命中，需要手动处理或忽略，常用于缓存场景少量节点时，节点的变化将大范围影响哈希环中数据映射，不适合少量数据节点方案需要增加一倍或者减半才能保证数据和负载的均衡虚拟槽：使用分散度良好的哈希函数把所有数据映射到固定范围的整数集合中，整数定义为槽，这个范围远大于节点数，Redis Cluster中的范围是0～16383。每个节点负责一定数量的槽。Redis Cluster采用虚拟槽分区。解耦数据和节点之间的关系，简化了节点扩容和收缩难度；节点自身维护槽的映射关系，不需要客户端或者代理服务维护槽分区元数据；支持节点、槽、键之间的映射查询，用于数据路由、在线伸缩等场景。限制：key批量操作支持有限key事务操作支持有限key作为数据分区的最小粒度，因此不能将一个大的键值对象映射到不同的节点不支持多数据空间复制结构只能支持一层通信Redis集群采用Gossip协议进行通信，原理是节点彼此不断通信交换信息，一段时间后所有的节点都会知道集群完整信息。常见的Gossip消息分为下面几种：meet：通知新节点加入ping：集群内每个节点每秒向多个其他节点发送ping消息，监测节点是否在线并交换彼此状态信息pong：接受meet和ping消息时，回复给发送方确认消息正常通信，其中封装了自身的状态数据（节点也可以向集群内广播自身pong消息来通知整个集群对自身状态更新）fail：当节点判定集群内另一个节点下线时，向集群内广播一个fail消息，其他节点接受不了fail消息后，将对应的节点更新为下线状态Redis集群内节点通信采用固定频率（定时任务每秒执行10次）。每个节点维护定时任务默认每秒执行10次，每秒会随机选取5个节点找出最久没有通信的节点发送ping消息。（每100毫秒都会扫描本地节点列表，如果发现节点最久一次接受pong消息的时间大于cluster_node_timeout/2，则立即发送ping消息。cluster_node_timeout参数默认15秒。集群伸缩集群伸缩，即扩容和缩容，原理是槽和数据在节点之间的移动。在数据迁移过程中，集群可以正常提供读写服务。在集群下添加从节点，使用cluster replicate {masterNodeId}，slaveof命令在集群模式不在支持。执行添加从节点命令后，从节点会对主节点发起全量复制，并且更新本地节点的集群相关状态。注意：对于主从节点都下线的情况，建议先下线从节点再下线主节点，避免不必要的全量复制。请求Redis Cluster没有采用代理方式，而是采用客户端直连的方式。Redis 接收任何键相关命令时首先计算键对应的槽，再根据槽找出所对应的节点，如果节点是自身，则处理命令；否则回复MOVED重定向错误，通知客户端请求正确的节点。使用redis-cli命令时，加入-c参数支持自动重定向。其本质是client收到了MOVED信息后再次发起请求。Smart客户端通过在内部维护slot-&gt;node的映射关系，本地就可实现键到节点的查找，从而保证IO效率最大化，而MOVED重定向复制协助Smart客户端更新slot-&gt;node映射。ASK重定向说明集群正在进行slot数据迁移，客户端无法知道什么时候迁移完成，因此只能临时性的重定向，客户端不会更新slot缓存。注意：当在集群环境下使用mget、mset等批量操作时，slot迁移数据期间由于键列表无法保证在同一节点，会导致大量错误。集群环境下对于使用批量操作的场景，建议优先使用Pipeline方式，在客户端实现对ASK重定向的正确处理，既可以通过批量操作进行IO优化，又可以兼顾slot迁移场景。故障转移主观下线：与Redis Sentinel的主观下线不同的时，Redis Cluster中主观下线是直接通过节点通信来判断的，而Sentinel中是通过Sentinel监控节点通信判断的。客观下线：集群中的故障节点的下线报告通过Gossip消息在节点中传播。当半数以上持有槽的主节点都标记某个节点是主观下线时，触发客观下线流程。（必须半数以上是为了应对网络分区的原因造成的集群分割情况，被分割的小集群无法完成主观下线到客观下线这个关键过程，从而防止小集群完成故障转移继续对外提供服务。）注：如果在cluster-node-time * 2的时间内该下线报告没有得到更新则过期删除。（不建议将cluster-node-time设置得太小。部署时需要注意网络分区的情况导致分割。主从结构需要根据自身机房/机架拓扑结构，降低主从被分区的可能性。故障恢复资格检查。判断从节点是否有资格替换故障的主节点。准备选举时间。采用延迟触发。通过对多个从节点使用不同的延迟选举时间来支持不同节点的优先级。发起选举。每个主节点自身维护了一个配置纪元（clusterNode.configEpoch)标示当前主节点的版本，所有主节点的配置纪元都不相等，从节点会复制主节点的配置纪元。整个集群维护一个全局的纪元，记录集群中的纪元的最大版。更新纪元后，然后在集群中广播选举消息。纪元标示每个主节点的不同版本和当前集群最大版本集群出现新的主节点，通过纪元来记录更大配置纪元代表了更新了集群状态。如果出现slots等关键信息不一致时，以纪元最大的为准。选举投票。只有持有槽的主节点才会处理故障选举消息。当某个从节点获得N/2+1个节点的选票，则选举成功。当在cluster-node-timeout * 2内没有选举成功，则进行下一轮选举。替换主节点。附注意开发和运维中场景问题：超大规模集群带宽消耗、pub/sub广播问题、集群节点倾斜问题、手动故障转移、在线迁移数据等。缓存更新策略LRU/LFU/FIFO算法剔除：当缓存使用量超过预设的最大值，则进行剔除。一致性差，维护成本低。超时剔除：一致性较差，维护成本较低。主动更新：一致性强，维护成本高。建议在低一致性的业务配置最大内存和淘汰策略的方式使用。高一致性的业务中使用超时剔除和主动更新。穿透优化缓存空对象。优点：保护了后端数据；缺点：占Redsi内存，且更容易出现不一致情况。布隆过滤器拦截。利用位数组很简洁地表示一个集合，并判断一个元素是否属于这个集合。使用布隆过滤器，存在第一类出错（Falsepositive），但是不会存在第二类错误（Falsenegative），因此，拥有100%的召回率。无底洞优化客户端一次批量操作会涉及多次网络操作，意味着批量操作随着节点增多，耗时会不断增大。网络连接数变多，对节点的性能也有一定影响。主要对批量操作的优化方式是：并行IO，使用hash_tag。雪崩优化保证缓存层服务高可用性依赖隔离组件为后端限流并降级提前演练热点key重建优化当某个热点key，在缓存失效瞬间，有大量线程来重建缓存，会造成后端负载过大，甚至崩溃。解决办法：互斥锁。思路简单，保证一致性。代码复杂度高，存在死锁风险，存在线程池阻塞风险。永不过期。优点是基本杜绝了热点key问题。不保证一致性，逻辑过期时间增加代码维护成本和内存成本。代理TwemproxyTwemproxy是Twitter开源的代理分片机制，Twemproxy作为代理，可接受来自多个程序的访问，按照路由规则，转发给后台的各个Redis服务器，再原路返回，并且它还可以减少与后端缓存的连接数。使用Keepalived来实现高可用。Predixy相关文档codis相关文档附阿里云Redis开发规范]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为什么欧洲对现代文明影响这么深--读极简欧洲史]]></title>
    <url>%2F2019%2F04%2F24%2F%E4%B8%BA%E4%BB%80%E4%B9%88%E6%AC%A7%E6%B4%B2%E5%AF%B9%E7%8E%B0%E4%BB%A3%E6%96%87%E6%98%8E%E5%BD%B1%E5%93%8D%E8%BF%99%E4%B9%88%E6%B7%B1-%E8%AF%BB%E6%9E%81%E7%AE%80%E6%AC%A7%E6%B4%B2%E5%8F%B2%2F</url>
    <content type="text"><![CDATA[为什么欧洲发展了理论科学，而我们的先辈却只有文学和实用科学？为什么我们现在所奉行的制度基本都源于欧洲，相比较而言，优势是什么？首先，必须说，我是一个对于欧洲哲学十分喜欢的人，在欧洲所发展起来的哲学正是目前社会科学的开端。我喜欢其中对于一些幸福、人性的探讨。第一处惊讶之处在于——古典时期到中世纪的欧洲，“并非所有东西都属于国王所有”，是欧洲政府思维的基石。因此，国王、政府的权利都是有限的，国王以及政府都不能完全地为所欲为。第二处惊讶是，欧洲脱离宗教的控制是缓慢的，并且存在一段宗教控制的时候，在宗教控制时期，并没有出现对于文化、学识等的打量打压，反而古代的知识等都靠宗教留存下来。不得不承认，在欧洲在发展中，除了中间一段时间的统一，一直都存在于多元化的发展中，各个国家都在不停的竞争，文化、经济上的竞争。而在中国古时候，主要人力思维，都主要奉献在了四书五经，达到一种极高的思维认同，这种认同的遗留依然存在于现在。在我看来，正是这种原因，因此欧洲和中国的发展思路是不同的。而经过全球化后，国家之间的关系相比较原来，更加紧密，因此对于原来的对于中国的以自己为中心的发展方式现实出来了明显的缺点。并且对于欧洲所证明的那套政治、经济发展可行性。因此世界都在学习这种成功的经验。我一直在想，我们相比较来说，优势是什么？相比较西方的文化等，我们的优势是什么？我一直没想通，这个待提醒。注：本文并非妄自菲薄，只是单纯的思考。]]></content>
      <categories>
        <category>read</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[产品体验——新草]]></title>
    <url>%2F2019%2F04%2F08%2F%E4%BA%A7%E5%93%81%E4%BD%93%E9%AA%8C%E2%80%94%E2%80%94%E6%96%B0%E8%8D%89%2F</url>
    <content type="text"><![CDATA[版本：v0.9.1产品介绍新草是一个好物分享平台，分别有数码、小物、书影、家居、个护、美食、旅行等分类等。功能新草的功能很简单浏览别人的分享分享自己的好物区别谈到好物分享，当然最先想到的是小红书了。小红书（版本：v5.45.0.6ba2027）主要功能模块：首页分享商场（与其他购物app相似）个人中心功能等新草对比的是首页分享。目前主要的功能也是分享类。相对来说，小红书主要是一个购物app，而分享只是对于其功能的一个扩充，增加用户活跃、交互、留存等用户粘度，并在这个分享中有一定的转换率，来吸引用户购物。而新草，主要的是分享，提供用户浏览别人的分享，支持图片与视频的方式。使用感受优点界面设计简洁，满足我的简约偏好风格好物分享浏览容分类清晰不足内容不够丰富，或者混排不够，比如我关注的数码类，重复产品概率很高缺少一些分类，比如没有分类衣服类，会流失很多用户商业化不成熟建议每个产品很重要的有两点：用户留存活跃度与商业化。增加更多的好物分类推荐内容可以根据用户偏好进行推荐增加商业化，将更多的商品能够与用户分享能够关联起来]]></content>
      <categories>
        <category>pro-exp</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Golang下int、float和String之间的转换]]></title>
    <url>%2F2019%2F04%2F05%2FGolang%E4%B8%8Bint%E3%80%81float%E5%92%8CString%E4%B9%8B%E9%97%B4%E7%9A%84%E8%BD%AC%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[int =&gt; string1string := strconv.Itoa(int)其原理是FormatInt(int64(i), 10)。string =&gt; int1int, err := strconv.Atoi(string)int64,int32,int16,int8 =&gt; string1string := strconv.FormatInt(int64,10)string =&gt; int系列1int, err := strconv.ParseInt(string, 10, 64) // 64,32,16,8分别对应int系列然后将结果强转成对应的类型。float系列 =&gt; string1234567string := strconv.FormatFloat(float64,'E',-1,64)// 'b' (-ddddp±ddd，二进制指数)// 'e' (-d.dddde±dd，十进制指数)// 'E' (-d.ddddE±dd，十进制指数)// 'f' (-ddd.dddd，没有指数)// 'g' ('e':大指数，'f':其它情况)// 'G' ('E':大指数，'f':其它情况)string =&gt; float系列1float,err := strconv.ParseFloat(string,64)附使用fmt.Sprintf(&quot;%d&quot;, int)来转换int成string时，相对于使用strconv.FormatInt，性能差了很多。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>Golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[产品体验——今日头条]]></title>
    <url>%2F2019%2F03%2F30%2F%E4%BA%A7%E5%93%81%E4%BD%93%E9%AA%8C%E2%80%94%E2%80%94%E4%BB%8A%E6%97%A5%E5%A4%B4%E6%9D%A1%2F</url>
    <content type="text"><![CDATA[今日头条版本：7.1.9头条极速版版本：6.8.7产品介绍头条开屏的标志下有一行小字——“信息创造价值”。头条是一个信息内容创作与分享平台，其中包括文章、视频等多种内容分享方式。今日头条有两个版本——今日头条（以下称头条）、今日头条（极速版）（下称头条极速版）。功能头条的功能很丰富发布文章、视频、直播等阅读文章、观看视频等个人中心功能第三方功能接入等（包括小程序）用户头条用户群体喜欢新闻阅读的人群喜欢通过视频观看身边发生的事的人群喜欢分享身边发生的事的人群区别头条极速版和头条的区别首先，头条极速版，是对于头条的用户群体进行分流与精简提炼。截掉了发布文章、视频等功能，减少了个人设置与小程序入口。并且在极速版中，通过增加任务奖励等功能刺激用户阅读。通过对比，可以明显看出，头条的文章页广告推送数比头条极速版更多。内容上，两个平台的对比都比较相似。对比其他平台对于头条来说，有两个对比对象，一个是新闻资讯平台，另一个个人创作分享平台。类似新浪新闻、网易新闻、简书等。对于新闻类平台来说，头条的优势是资讯的及时性与创作性。还有推荐准确率，这点可以提高用户点击率，更够更加吸引用户阅读。对于创作分享平台，其中比较相似点在于创作性，都是创作类软件，能给予用户较高的创作度，但内容相关度不大。使用感受优点整体来说，头条的内容推荐丰富，内容推荐与用户喜好度相关性大。头条极速版的任务可以更好的刺激用户，能够吸引用户阅读。不足资讯同质性严重资讯数量大，质量没那么高建议对于头条来说，已经比较繁重，要求主要是功能齐全，因此目前要求的是稳定与老用户不流失，并且在这个的基础上增加商业化运转。而对于头条极速版来说，可以增加一个高质量的频道，这个频道每天推送的一定数量的高质量资讯，来增加资讯的质量。]]></content>
      <categories>
        <category>pro-exp</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[人类简史——从动物到上帝]]></title>
    <url>%2F2019%2F03%2F24%2F%E4%BA%BA%E7%B1%BB%E7%AE%80%E5%8F%B2%E2%80%94%E2%80%94%E4%BB%8E%E5%8A%A8%E7%89%A9%E5%88%B0%E4%B8%8A%E5%B8%9D%2F</url>
    <content type="text"><![CDATA[这是一本我无法用一句话来总结的书。从动物到上帝，是说明的这本书的历史部分，而涉及的科学与哲学部分都没法用这句话来概括。作者在每一处现象里，都能够深入到本质，讲究涉及物理、化学、生物，以及心理学等。这本书虽然对于每一个科学部分的涉入都特别浅，但正是因为这特别浅，因此通俗易懂，方便大众的读物；也正是因为不是纯粹的历史，因此读起来也就不无聊了。这本书不适合那些为了了解历史的人来读，同样不适合那些为了科学等知识的人读，只适合为了读书而读书的人来读，会体会到其中更多的趣味。在下文中，将摘录书中的一些观点来阐述。想象在《四月是你的谎言》中，记忆最深的一句话——“image，真正的你想要如何演奏肖邦”。虽然历史中不会要求如何去演奏肖邦，但人类的发展史中，想象确实是一个很大要素。智人从非洲大草原起的小部落，到现在的全球性国家与民族。人类将如何来构建社会与团体呢？答案就是通过想象。比如民族，并没有明显的区分，并没有基因的差异性到了可以区分的境界，只是通过一个共同的认知，来想象自己是某个民族的，并且这个认知，被大多数人所同意，因此你就是这个民族的了。比如公司、国家，这些一切不能以具象表现，却公认存在的，都是一种想象。然后让所有人都认可这个想象，并同时自己也形成这种想象。比如公司管理上，刚开始只通过人与人间的关系就能管理；随着公司的成长，越来越多的人的管理就需要制度；到最后的大公司的管理，就只能靠文化。这一系列的管理上，就是通过想象而形成了，想象形成公司、制度、文化等。在人类社会中，存在让人类统一的三个想象衍生物——金钱、帝国和宗教。为何认为这些都是想象呢？金钱，指的是我们的纸币吗？每一个东西都有两个价值——实用价值和抽象价值，而抽象价值即是想象的结果。纸币也是一样，实用价值就是纸的价值，可以用来记录，而抽象价值即每张纸币所代表的能够交换的价值的证明，而世界上所有人都认可这个价值，因此其就具有抽象价值了。宗教是一种想象，这个就更加容易理解了，其本身并不存在的东西，而通过想象上帝或者佛祖的存在，形成教义，而想象这些教义的人聚集起来共同执行教义，而形成宗教。承认无知在现在这个“后欧洲时代”里，我们所形成的很多观念，都属于欧洲在19到20世纪形成的观念。而欧洲帝国，为何在经历19到20世纪这几百年，超越了一直经济政治发展都很好的中国呢？正是因为承认自己的无知，因此在这几百年间，有了许多新的发现，形成了科学和资本主义等，这些都是欧洲帝国主义最终要的遗产。正是因为承认无知，欧洲才会去探索世界，去发现新大陆，才有了原始资本的积累。而很多地区的原住民，都因为视野的狭隘而付出沉重的代价。欧洲在殖民世纪的许多新大陆时，并没有一开始就派出大量的军队，而是只靠少数人的渗入，许多原住民国家都是通过渗入而瓦解。但是这是无法避免的。像殖民主义等，人类本身都是很恐怖的，从智人发展时也是同样，从非洲大草原迁移到许多地方的智人，都直接造成了当地人的灭亡。对于某个时代的了解越彻底，反而越难解释为什么发生了这个事件而不是那个事件。真正最知道当时情况的人，正是看不出历史走向的人。历史的铁则就是：事后看起来无可避免的事，在当时看起来总是毫不起眼。引入书中的一些句子，所表示的正是历史是无法讲究最原始的原因的，无法讲究如何避免的。承认无知，或者说不满足，这是现代科学和现代帝国背后的动力，觉得远方一定还有什么重要的事物，等着去探索，去掌握。信任现在有许多信任机制，如芝麻信用分、高铁乘坐限制等。而这些信任机制也是想象的衍生。在书中讲到了一些基于信任的经济学相关知识。真正让银行（以及整个经济）得以存活甚至大发利市的，其实是我们对未来的信任。信任就是世上绝大多数金钱的唯一后盾。像之前说的人们都承认并同时想象金钱所代表的价值，这就是信任。正是信任的概念，让我们能够预支未来，打造现在，而这背后有一项基本假设，就是未来的资源肯定远超目前的资源。只要我们实用未来的收入来投资当下，就会带来许多全新而美好的商机。正因为信任，以及对于未来资源的信任，所以现代人类的消费观都鼓励消费，鼓励活在当下。幸福我原来说过，我越来越不喜欢历史了，因为历史中，没有一个平凡人的一生被记录下来。实际上还有其他原因。历史书籍大多数对于社会结构的建立和瓦解、帝国的兴衰、科技的发明和传播，可以说是知无不尽、言无不尽。但对于这一切究竟怎么为个人带来快乐或造成痛苦，却是只字未提。这是我们对于历史理解的最大空白之处。我提过，无论历史上产生如何小的变动，对于当事大多数人来说，都是悲惨的，比如秦末人们起义，这段时间里，想要生活的人却是过着水深火热的生活，相对于之前和平的年代里，估计有过之无不及。我原来在《谈幸福》中提过，我认为“幸福或许不仅仅是现实与期望间的差值，但也是最大的相关”。在本书中讲到，对于快乐的影响，家庭和社群比金钱和健康来得重要，快乐在于客观条件和主观期望是否相符。而人类，似乎只要有了活下去的理由，几乎什么都能够忍受。“人是从众的，包括意识”。比如现代人类的消费观以及认识观等，人的认知的形成，都是基本和群体相同的。附附上一些其他认识。农业革命：从以前的采集社会开始转变，让智人稳定于某个地方发展。其真正的本质是让更多的人以更糟糕的状态活下去。工业革命：核心是能源转换的革命。虽然民族主义病毒让自己看起来对全人类有利，但其实主要还是对自身有利。博弈理论告诉我们，在有多位参与者的时候，某些概念和行为模式可能对“所有”参与者都有害，但就是有办法继续存活下去。]]></content>
      <categories>
        <category>read</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[[翻译]在Golang中使用高阶函数实现依赖注入]]></title>
    <url>%2F2019%2F03%2F18%2F%E7%BF%BB%E8%AF%91-%E5%9C%A8Golang%E4%B8%AD%E4%BD%BF%E7%94%A8%E9%AB%98%E9%98%B6%E5%87%BD%E6%95%B0%E5%AE%9E%E7%8E%B0%E4%BE%9D%E8%B5%96%E6%B3%A8%E5%85%A5%2F</url>
    <content type="text"><![CDATA[原文：Dependency injection in Golang using higher order functions你可以在github.com/steinfletcher/func-dependency-injection-go上找到完整的代码示例。该示例包含一个公开REST端口的http服务。介绍在这篇文章中，我们提出了一种在go中依赖注入的方法——使用高阶函数和闭包。先看看下列返回用户属性的方法。12345func GetUserProfile(id string) UserProfile &#123; rows, err := db.Query("SELECT ...") ... return profileText&#125;我们期望将处理用户数据的代码和访问数据库的代码分开。在这个例子中，我们希望通过提供对数据库访问的模拟，对主要业务层和其他业务逻辑进行单元测试。接下来分开这些，以至于每个方法都有一个独立的责任。123456789// 包含业务逻辑或匹配的核心业务层方法代码func GetUserProfile(id string) User &#123; ...&#125;// 数据连接层方法func SelectUserByID(id string) UserProfile &#123; ...&#125;我们也可以在其他域方法中重复使用方法SelectUserByID。我们需要一种将SelectUserByID注入到GetUserProfile的方法，以至于我们可以在测试中模拟数据访问，进行单元测试GetUserProfile方法。在Go中一种实现的方法是为函数定义一个类型别名。类型别名使GetUserProfile方法依赖一个抽象，意味着我们可以在测试中注入一个模拟的数据访问层。两种常用的方式分别是使用接口，或类型别名。类型别名很简单，不需要生成一个可以在这儿使用的新结构。接下来为这两个方法都声明别名。123456789101112131415type SelectUserByID func(id string) Usertype GetUserProfile func(id string) UserProfilefunc NewGetUserProfile(selectUser SelectUserByID) GetUserProfile &#123; return func(id string) string &#123; user := selectUser(id) return user.ProfileText &#125;&#125;func selectUser(id string) User &#123; ... return User&#123;ProfileText: userRow.ProfileText&#125;&#125;SelectUserByID是一个传入用户ID，返回一个User的方法。我们没有定义它的实现。NewGetUserProfile是一个输入方法selectUser，然后返回一个可以被调用者使用的方法，的工厂方法。这种策略使用一个闭包，来提供一个内部方法可以被外部方法依赖的入口。闭包可以获得上下文定义的变量和常量。这被称为这些变量和常量的封闭。可以像下面这样调用这些域函数。1234// 在应用中的直接依赖getUser := NewGetUserProfile(selectUser)user := getUser("1234")另一种方式如果你熟悉其他类似Java的语言，这就像创建一个类，注入这个类的依赖到构造函数中，然后通过方法访问依赖。这种访问方式没有方法上的差异——可以将函数别名当作一个只有一个简单抽象方法（SAM）的接口。在Java中，可以使用构造函数来注入依赖。1234567891011121314151617interface DB &#123; User SelectUser(String id)&#125;public class UserService &#123; private final DB db; public UserService(DB db) &#123; // 将依赖注入的构造函数 this.DB = db; &#125; public UserProfile getUserProfile(String id) &#123; // 访问方法 User user = this.DB.SelectUser(id); ... return userProfile; &#125;&#125;而在Go中使用高阶函数实现等价功能的方式如下：1234567891011type SelectUser func(id string) Usertype GetUserProfile func(id string) UserProfilefunc NewGetUserProfile(selectUser SelectUser) &#123; // 注入依赖的工厂方法 return func(id string) UserProfile &#123; // 访问方法 user := selectUser(id) ... return userProfile &#125; &#125;测试现在可以通过模拟数据访问层来单元测试业务层方法。12345678910func TestGetUserProfile(t *testing.T) &#123; selectUserMock := func(id string) User &#123; return User&#123;name: "jan"&#125; &#125; getUser := NewGetUserProfile(selectUserMock) user := getUser("12345") assert.Equal(t, UserProfile&#123;ID: "12345", Name: "jan"&#125;, user)&#125;你可以在github.com/steinfletcher/func-dependency-injection-go找到更完整的代码示例。该示例包含一个公开REST端口的http服务。译者注：本文翻译可能不够完美，如有错误请指出，我将改正。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>Golang</tag>
        <tag>DI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[翻译]When nil Isn't Equal to nil]]></title>
    <url>%2F2019%2F03%2F14%2F%E7%BF%BB%E8%AF%91-When-nil-Isn-t-Equal-to-nil%2F</url>
    <content type="text"><![CDATA[原文：https://www.calhoun.io/when-nil-isnt-equal-to-nil本文源于 a question asked on the Go Forums，是我回复的版本的略微修改。在本文中，我们将探讨一些情况，某些变量看起来相等，当使用Golang的==比较时却不等。接下来我们将探讨这种情况发生的原因，并且如何轻松的在自己的代码中避免遇到这种问题。首先让我们看一个例子。假设有两个变量，每个变量都有自己的类型，且每个变量都分配了硬编码值nil。12var a *int = nilvar b interface&#123;&#125; = nil你觉得下面代码的结果什么呢？123fmt.Println("a == nil:", a == nil)fmt.Println("b == nil:", b == nil)fmt.Println("a == b:", a == b)可以运行上面代码来验证你的结果。事实上正确结果如下：123a == nil: trueb == nil: truea == b: false我们快速的来看另一个相似而不相同的例子。接下来中会更改变量b的初始值：12345678var a *int = nil// 这是唯一的变化，我们使用a来代替硬编码的nil值赋值给avar b interface&#123;&#125; = afmt.Println("a == nil:", a == nil)fmt.Println("b == nil:", b == nil)fmt.Println("a == b:", a == b)&#125;再次，你觉得上面代码的输出是什么呢？下面给出正确答案：123a == nil：trueb == nil：falsea == b：true究竟发生了什么呢？这中情况有点难（hard/weird）解释。但是这个不是bug，也不是其他（random/magical/whatever）。这儿只是有一些被声明的明确的规则，我们需要花点时间来理解。接下来你就会明白，偶尔看到别人的代码写成如下样子：123if a == nil &#123; b = nil&#125;代替使用a来赋值给b。首先我们需要理解Go中的每个指针都有两个基本信息：类型和指针指向的值。下面将用(type, value)来表示。因为每个指针变量都需要一个类型，所以不能在不声明类型的情况下将nil值赋给变量。因此，下面代码不会编译通过：12// 因为无法确认n的类型，因此编译不通过n := nil为了编译上面的代码，我们必须使用一个有类型的指针，并赋值nil。12var a *int = nilvar b interface&#123;&#125; = nil现在，两个变量都有类型了。可以使用fmt.Printf来打印出他们的类型。12345var a *int = nilvar b interface&#123;&#125; = nilfmt.Printf("a=(%T, ...)\n", a)fmt.Printf("b=(%T, ...)\n", b)注意：%T用于打印值的类型fmt.Printf。你可以在文档中阅读有关这些特殊字符的更多信息。输出结果如下：12a=(*int, ...)b=(&lt;nil&gt;, ...)看起来，将nil硬编码给*int类型的变量a时，被设置为和变量a相同类型——*int。那就有意义了。第二个变量b有些令人困惑。它的类型是interface{}（空接口），但是打印nil值的类型，却是&lt;nil&gt;。发生了什么呢？简单的说，就是因为我们使用空接口，任何类型都可以适用。&lt;nil&gt;类型严格上也是一种类型，它可以适用于空接口，因此在编译器没有其他类型信息使用时就会生效。所以，我们知道所有的指针都有(type, value)两个属性，并且已经看过了当nil赋值给某个变量时会发生什么。那么接下来看看通过a变量而不是nil来赋值b后，它们的类型都是什么？12345var a *int = nilvar b interface&#123;&#125; = afmt.Printf("a=(%T, ...)\n", a)fmt.Printf("b=(%T, ...)\n", b)Huh…看起来b有一个新类型了。当给b硬编码nil之前，没有类型信息。使用a给b赋值时就不是这样了。通过变量a能够准确的知道应该使用什么类型。快速总结所有的指针都有值和类型；当给一个变量硬编码nil值时，编译器会决定用什么正确的类型；当用一个nil的变量赋值给当前对象时，可以通过之前的变量来决定当前的类型。当检查相等时发生来什么？我们理解类型的决定方式了，那么我们看看判等时发生了什么。首先有两个都使用nil硬编码赋值的变量a，b。接下来就是类似上面a赋值给b的桥段了。12345678910var a *int = nilvar b interface&#123;&#125; = nil// 在这儿打印两个变量的类型和值fmt.Printf("a=(%T, %v)\n", a, a)fmt.Printf("b=(%T, %v)\n", b, b)fmt.Println()fmt.Println("a == nil:", a == nil)fmt.Println("b == nil:", b == nil)fmt.Println("a == b:", a == b)接下来是输出结果如下：123456a=(*int, &lt;nil&gt;)b=(&lt;nil&gt;, &lt;nil&gt;)a == nil: trueb == nil: truea == b: false显然最奇怪的地方就是a不等于b。这看起来特别奇怪，因为乍眼一看，a == nil并且b == nil但a != b，这在逻辑上根本不可能。实际是下面这种情况——举个例子，a == nil——并不能正确代表比较的结果。真正比较的是它们两个变量的值和类型。也就是说，不仅比较存储在a和nil上的值，也比较它们的类型。确切的结果展示如下：12345a == nil: (*int, &lt;nil&gt;) == (*int*, &lt;nil&gt;)b == nil: (&lt;nil&gt;, &lt;nil&gt;) == (&lt;nil&gt;, &lt;nil&gt;)# 注意：这两个很明显不相同# 因此我们加上了类型信息a == b: (*int, &lt;nil&gt;) == (&lt;nil&gt;, &lt;nil&gt;)当通过这种方式记下这些比较后，两个变量就变得很明显不相等了——它们拥有不同的类型——但是这些信息在代码里并不是特别清晰，因此很不幸导致众多的误解。一个供选择的方法如果你真的想在你的代码里比较a和b，你可以使用下面的代码来代替你想写的：123if a == nil &amp;&amp; b == nil &#123; // both are nil!&#125;这需要更多的代码，但是能更好的表达你的意图。也就是说，这种方法可以通过将另一个nil变量（而不是硬编码nil）赋值给b，将在接下来的例子看到。现在来看看将a赋值给b并且执行相同的比较时，会发生什么。123456789var a *int = nilvar b interface&#123;&#125; = a // &lt;- the changefmt.Printf("a=(%T, %v)\n", a, a)fmt.Printf("b=(%T, %v)\n", b, b)fmt.Println()fmt.Println("a == nil:", a == nil)fmt.Println("b == nil:", b == nil)fmt.Println("a == b:", a == b)这个程序的输出是：123456a=(*int, &lt;nil&gt;)b=(*int, &lt;nil&gt;)a == nil: trueb == nil: falsea == b: true奇怪的是第二行，b == nil。这有点不明显，当将b和硬编码的nil值比较时，编译器也需要决定nil的类型。这种情况下，如果赋值nil给变量b时，编译器会做出相同的决定——也就是将等号的右边设置为(&lt;nil&gt;, &lt;nil&gt;)——如果查看b的输出时，明显有不同的类型：(*int, &lt;nil&gt;)。这点上大家比较认同的是，这儿非常令人困惑，语言本身应该为我们处理这个细节。不幸的是这个在编译时不可能，因为b的世纪类型可以随着程序运行而改变。1234567891011121314var a *int = nilvar b interface&#123;&#125; = avar c *string = nilfmt.Printf("b=(%T, %v)\n", b, b)fmt.Println("b == nil:", b == nil)b = cfmt.Printf("b=(%T, %v)\n", b, b)fmt.Println("b == nil:", b == nil)b = nilfmt.Printf("b=(%T, %v)\n", b, b)fmt.Println("b == nil:", b == nil)在这个程序中，b变量的类型改变来3次。刚开始是(*int, &lt;nil&gt;)，后来变成(*string, &lt;nil&gt;)，最后变成了(&lt;nil&gt;, &lt;nil&gt;)。这种改变三次的类型编译器编译时无法判断，因此在Go里只能处理成运行时动态处理，它有一些独特的难题，可能不值得介绍。编译时类型决定也可以用数字来演示我们看到nil如何别强制转变成正确的类型，但是这不是编译器决定正确的类型的唯一情况。例如，当将硬编码的数赋值给变量，编译器将基于程序的上下文决定使用哪种类型。显而易见的一种情况，就是当类型与变量一起声明（例如var a int = 12），但是这种情况也发生在将硬编码值传递给函数或者只是将数字赋值给变量时。这些情况都会在下面的代码中展示。12345678910111213141516171819202122232425package mainimport "fmt"func main() &#123; var a int = 12 var b float64 = 12 var c interface&#123;&#125; = a d := 12 // will be an int fmt.Printf("a=(%T,%v)\n", a, a) fmt.Printf("b=(%T,%v)\n", b, b) fmt.Printf("c=(%T,%v)\n", c, c) fmt.Printf("d=(%T,%v)\n", d, d) useInt(12) useFloat(12)&#125;func useInt(n int) &#123; fmt.Printf("useInt=(%T,%v)\n", n, n)&#125;func useFloat(n float64) &#123; fmt.Printf("useFloat=(%T,%v)\n", n, n)&#125;我们可以用一些数字来展示这些困惑。12345678910var a int = 12var b float64 = 12var c interface&#123;&#125; = afmt.Println("a==12:", a == 12) // truefmt.Println("b==12:", b == 12) // truefmt.Println("c==12:", c == 12) // truefmt.Println("a==c:", a == c) // truefmt.Println("b==c:", b == c) // false// 因为a和b的类型不匹配，我们不能比较它们现在a == 12, b == 12, c == 12， 但是当我们比较b == c是得到false。什么！！！再次去理解它们的类型：123a=(int,12)b=(float64,12)c=(int,12)a和c是int类型。b是float64类型，因此它们和硬编码值12进行比较时，在比较前，需要把比较的两边强制转化成同一类型。对于数字，另一个有趣的是，当12和一个接口进行比较时，编译器会一直将它强制转换成int类型。类似于，nil和接口类型比较时，怎么转化成(&lt;nil&gt;, &lt;nil&gt;)，修改代码演示证明：123456var b float64 = 12var c interface&#123;&#125; = bfmt.Println("c==12:", c == 12)fmt.Printf("c=(%T,%v)\n", c, c)fmt.Printf("hard-coded=(%T,%v)\n", 12, 12)输出下列结果：123c==12: falsec=(float64,12)hard-coded=(int,12)现在c == 12返回false，因为(float64, 12)和硬编码的(int, 12)是不同的，因为它们有不同的类型。总结当硬编码值与变量比较时，编译器必须假设它们有某种特定类型并遵循一些规则来实现这一点。有时这很困惑，但慢慢的你就会习惯的。如果发现自己使用的类型都可以使用nil赋值时，一种常用的避免问题方法就是明确地赋值nil。也就是，代替a = b写成下面这样：123456var a *int = nilvar b interface&#123;&#125;if a == nil &#123; b = nil&#125;接下来将b和硬编码的nil比较时，就会得到预期的结果。这需要更多的代码，但它几乎在所有情况下都会得到想要的结果。声明我没有研究任何实际编译器或Go的内部工作原理，所以如果有不准确的，请告诉我，我会解决它。这篇文章完全基于我看到过或读过的其他文章。译者注：本文是我在遇到Golang的nil问题时找到的，本文的翻译可能不够完美，有需要纠正的地方请提出，我会改正。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>Golang</tag>
        <tag>nil</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于github与hexo的博客搭建]]></title>
    <url>%2F2019%2F02%2F24%2F%E5%9F%BA%E4%BA%8Egithub%E4%B8%8Ehexo%E7%9A%84%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[安装npm进入这个网站（镜像），下载需要的最新的pkg：http://npm.taobao.org/mirrors/node/latest/。然后将这个文件解压，放到一个位置。配置export PATH=$PATH:/Users/feiyu/node-v11.7.0-darwin-x64/bin。创建github仓库仓库的名字必须是我们自己的github用户名，这样github会识别当前仓库的某个分支来创建GitHub Pages，默认选用master分支。然后我们需要在本地创建一个对应的的项目，并进入这个项目文件夹。需要注意的是，上面默认选中了master分支作为基础创建GitHub Pages，那么本地的源代码就不能再直接git push到该分支，该分支只能用来发布博客页面。安装hexo首先，需要在我们的博客项目文件夹中。输入下面命令开始安装。1npm install hexo -g安装完成后，则初始化博客项目。1hexo init输入npm install，安装所需要的组件。需要讲解几个重要的命令：hexo new &quot;&quot; 创建源md文件；hexo g 生成网页；hexo s 本地起服务，然后浏览器输入http://localhost:4000 ，就可以访问本地博客项目；hexo d 将生成的页面发送到github，github检测到master分支更新后会自动构建页面，这其中有一点延迟，需要稍微等一下。在_config.yml中配置一下Site基础信息12345678title: feiyboxsubtitle: do moredescription: 小浊微清的博客author: feiyboxlanguage: zh-Hansurl: https://feiybox.github.io/root: /...当然还有许多变量可以去配置。在hexo生成后会默认有一个页面，因此可以尝试上面hexo g等命令查看该项目构建是否成功。当hexo d发布后，就可以进入https://your_github_id.github.io/ ，就可以访问你的博客网页了，如果有构建错误或者异常等，github会通过邮件发送提醒。文章源md每个文章的源md文件都分为两个部分，文章部分就是常用的md语法，而头部分示例如下，主要有文章名、时间、标签、分类等。123456title: HashMap 源码分析date: 2017.04.03 20:08tags: - Java - mapcategories: tech这个部分许多都是直接在hexo new的时候就生成出来了，然后修改。当然也可以修改scaffolds/post.md文件就可以直接修改new生成出来的模版了。增加图片支持到目前为止，博客已经支持基础的发文操作了，接下来就是完善与优化了。1npm install hexo-asset-image --save在当前文件夹下输入上诉命令，就可以支持markdown命令![logo](logo.jpg)来支持相对路径。并且使用hexo new命令时，会创建一个对应文章的文件夹，将图片放在这个文件夹中，然后在文章中使用相对路径就可以使用了。next主题为啥使用next主题？因为够简洁呀。还有一个原因，这个博客主题中支持了许多插件，因此不需要我们去修改模版页面了，只需要修改一个配置就行了。如何安装呢，直接将next主题直接下载到themes文件夹下，然后将_config.yml中的theme修改为theme: next就可以了。使用git下载如下（前提在当前项目根目录下）1git clone https://github.com/iissnan/hexo-theme-next themes/next头像与网页缩略图这是一个代表自己网页特异性的地方。修改themes/next文件夹下的_config.yml文件中的配置如下。1234567favicon: # 缩略图 small: /images/f.png medium: /images/f.png apple_touch_icon: /images/f.png safari_pinned_tab: /images/f.png ...avatar: /images/head.png # 头像所有的图片都是next/source为根文件夹，一般放在该文件夹的images文件夹下，后续构建时，会自动生成在对应的位置。数据统计与页面阅读量展示百度统计数据统计部分，推荐使用百度统计，在百度统计上注册并新增了网站，获得一个百度统计的key，如下图位置。然后将修改themes/next/_config.yml的baidu_analytics值为我们获得的key。12# Baidu Analytics IDbaidu_analytics:然后项目构建后就可以进入百度统计查看网站的访问信息了。不蒜子统计直接修改themes/next/_config.yml的busuanzi_count的enable值为true。1234567891011busuanzi_count: enable: true site_uv: true site_uv_header: &lt;i class="fa fa-user"&gt;&lt;/i&gt; site_uv_footer: site_pv: true site_pv_header: &lt;i class="fa fa-eye"&gt;&lt;/i&gt; site_pv_footer: page_pv: true page_pv_header: &lt;i class="fa fa-file-o"&gt;&lt;/i&gt; page_pv_footer:由于不蒜子的域名已经修改，官方有说明。因此需要修改不蒜子的域名，打开themes\next\layout_third-party\analytics\busuanzi-counter.swig文件，将dn-lbstatics.qbox.me替换成busuanzi.ibruce.info即可。喜欢与评论这个主要使用的是Gitment，其中评论主要是作为某个repo的issue存在，因此可以直接绑定自己的博客项目，也可以新建一个repo来存储评论。具体怎么做呢，按照接下来的步骤。首先在项目根目录中安装Gitment。1npm i --save gitment然后新建一个OAuth application。新建完成会生成一个Client ID与Client Secret。其中需要说明一下的是Homepage URL是指你的博客根目录地址，比如我的是https://feiybox.github.io/，然后是Authorization callback URL，这个是指用户在你的页面登录github账号后的回调链接，一般也是Homepage URL。（这儿我有一个疑问，这儿可以返回用户的登录页面吗？）然后修改theme/next/_config.yml中的gitment配置。12345678910111213gitment: enable: true mint: true count: true lazy: false cleanly: true language: github_user: feiybox github_repo: client_id: client_secret: proxy_gateway: redirect_protocol:其中比较重要的有几个enable、github_user、github_repo、client_id、client_secret，这个几个都是必须填或修改的。需要注意的一点是github_repo是指评论的存储项目的项目名称，不是git仓库。需要我们上线后，自己登录并对每篇文章开通评价（都在每篇文章的最后）。然后上线并用自己账户开通评论时，可能会出现问题。Error: Validation Failed这个问题是因为issue的Label有长度限制，在中文博客中经常超过限制。因此可以将themes/next/layout/_third-party/comments/gitment.swig的window.location.pathname替换为&#39;&#39;。这样每个issue都是基于文章的date构建的，因此需要保证没有同时发布文章，一般也不会出现这种情况。注意:国内可能出现”Object ProgressEvent”的报错，可以按照下面修改方法修改themes/next/layout/_third-party/comments/gitment.swig文件。123&#123;% set CommentsClass = "Gitmint" %&#125;&lt;link rel="stylesheet" href="https://aimingoo.github.io/gitmint/style/default.css"&gt;&lt;script src="https://aimingoo.github.io/gitmint/dist/gitmint.browser.js"&gt;&lt;/script&gt;替换为123&#123;% set CommentsClass = "Gitment" %&#125;&lt;link rel="stylesheet" href="https://jjeejj.github.io/css/gitment.css"&gt;&lt;script src="https://jjeejj.github.io/js/gitment.js"&gt;&lt;/script&gt;特别需要注意需要将CommentsClass从Gitmint修改为Gitment。分享支持分享使用needmoreshare212rm -rf themes/next/source/lib/needsharebuttongit clone https://github.com/theme-next/theme-next-needmoreshare2 themes/next/source/lib/needsharebutton然后在themes/next/_config.yml中配置needmoreshare2。先将enable设置为true，然后可以配置分享按钮的样式等。12345678910111213141516needmoreshare2: enable: true postbottom: enable: false options: iconStyle: box boxForm: horizontal position: bottomCenter networks: Wechat,Douban,QQZone,Weibo,Twitter,Facebook float: enable: true options: iconStyle: default boxForm: vertical position: middleRight networks: Wechat,Douban,QQZone,Weibo,Twitter,Facebook系统优化搜索将theme/next/_config.yml中的local_search的enable设置为true，就可以提供搜索了。菜单123456789menu: home: / || home archives: /archives/ || archive categories: /categories/ || th tags: /tags/ || tags #about: /about/ || user #schedule: /schedule/ || calendar #sitemap: /sitemap.xml || sitemap #commonweal: /404/ || heartbeat加上需要的菜单，然后新增对应的页面。如下，新增categories页面。1hexo n page categories然后在source/categories/index.md中的type加上categories就好了。首页文章缩略themes/next/_config.yml文件中修改auto_excerpt。123auto_excerpt: enable: true length: 10压缩静态资源1npm install hexo-neat --save然后在_config.yml添加配置12345678910111213141516171819202122#静态资源压缩优化 hexo-neatneat_enable: true # 启用neat# html优化neat_html: enable: true exclude:# css优化neat_css: enable: true exclude: - '*.min.css'# js优化neat_js: enable: true mangle: true output: compress: exclude: - '*.min.js'参考还有许多配置点，这位博主写得很好：hexo博客优化–Next主题]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>github</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[北上征程之巧合版]]></title>
    <url>%2F2019%2F02%2F11%2F%E5%8C%97%E4%B8%8A%E5%BE%81%E7%A8%8B%E4%B9%8B%E5%B7%A7%E5%90%88%E7%89%88%2F</url>
    <content type="text"><![CDATA[北上征程有很多，对我而言，每次从家到北京都是一次征程，往往我的选择方式也有很多，比如提前一天到成都第二天坐高铁到北京，或者直接飞机到北京，或者当天动车从家里到成都再转车等。我没有试过坐上两天的绿皮车，一直不是很喜欢坐很长时间的车。时间定格在2019年2月10日，这一天，我开始了我的新一轮北上征程，也是目前唯一一次值得称得上征程的一次。早6点20，闹钟响起。起床，洗漱，洗了头发，充电器塞箱子，吃几个汤圆。Now, Go!7点，从家里出发，坐车到眉山东站。他们开车比我预计的快了挺多，8点10分，到了。时间挺早，进站慢慢等待我9点多的动车。一切都在有条不紊地进行着。上车，行李搬上行李架。我第一次心想，“我为啥不少带几个苹果或者橘子，这箱子也忒重了”，试了几次，终于搬上行李架了，真不容易。9点45分，到达成都南站。然后排队买了票，成都地铁做的比较好的一点是地铁买票可以支持微信支付宝付款，这点上比较人性化。然后再排队过安检，再排队闸机口刷票，门不开，然后我走开去刷另一个门了，失败。我当时在想，“这¥%……&amp;*什么情况？”，我知道我的票出了问题，然后需要处理。时间9点55分，我的高铁出发时间是10点42分。然后我到客服中心，然而看到非常长的队伍，我心想：“凉了，被成都地铁坑了”，我心里是很焦躁的，毕竟我的时间上不允许再有耽搁。然后我向工作人员寻求快速处理，工作人员似乎也没办法，只能把我指向另一个客服中心——“向那边走，那边客服中心人少”。我拉着行李拔腿就跑，看到了一个空空如也的歇业的客服中心，然后再询问工作人员，指向下一个客服中心，我也是一路奔拔，处理完再再再过安检，然后去等车了。为什么是“再再再”呢？因为我每次决定我可以过闸机的时候，都失败了，第一次是刷门不开，第二次是空的客服中心，我以为安检人员可以处理，第三次成功了，所以过了三次安检。上地铁了，时间10点整。到达东站，10点20分。一路跑起来，从东站地下广场到地上广场，然后进站。排队安检，向安检人员寻求快速安检方式，通过。到达B16检票口，已经没有排队了。检票上车，找了挺久行李架空位，找到一个较远的位置再次举上去。累。跑得太快，额头上都有豆大的汗珠。列车准时出发。穿越四川盆地的环山后，看到白雪装裹的平原，有雪！我有两种心情——“景色真好，但是这会不会影响高铁呢？”。一直到西安都没什么问题，问题来自那一个不经意间。雪的影响，限速允许，原来最高时速300km/h的高铁现在变成了195km/h了。从最后结果来看，延误了1个小时10分钟。当一开始延误后，就会导致更多的延误，每个站点时，这班延误的车都需要等待前面其他车通过后再运行。火车上，吃了两个面包，两盒牛奶，一个苹果，喝水若干。就这样终于到了北京西站。到达时间接近10点。花了15分钟排队过地铁安检，然后去挤地铁。一切看上去都不会有什么意外了。经历了9号线转6号线再转8号线的一系列换乘后，就要到我住的附近地铁站了。然而最意想不到事发生了。为了描述当时我的处境，有必要先描述地铁列车上的情况，列车上，人不算人多，每个人都大大小小带着行李箱，座位和中间位置都被行李箱与带行李的人占去了地方，列车门口位置都留出来了上下乘客。当我到站时，我准备下车的列车站点外门，竟然在维护，不开，“what!!!”，我只能从旁边门下车，当面临生死攸关的时刻，人的潜力总会被放大许多，我也是，我两手就抱起了箱子，从一众箱子间翻山越岭到达下一个门口出来。放下箱子，听着身后列车的关门警告声，长叹一声。“I got it!!!”，真不容易。当我叹气时，车里的人儿笑了笑，我回了一个似笑非笑，表诉我当前的心情。到达住的地方，我朋友这儿。然后他屋子的门锁密码开不了，原来的密码不对。我已经接近无语了。重新打电话给朋友，确认了一下新密码，终于休息了。码一点字，平复一下遇到这些偶然的我的心情。]]></content>
      <categories>
        <category>other</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[读《傲慢与偏见》]]></title>
    <url>%2F2019%2F01%2F31%2F%E8%AF%BB%E3%80%8A%E5%82%B2%E6%85%A2%E4%B8%8E%E5%81%8F%E8%A7%81%E3%80%8B%2F</url>
    <content type="text"><![CDATA[很喜欢《傲慢与偏见》这种故事，和《简·爱》的故事一样，都是美满的结局，全程没有一点压抑，或许有一些人物出现的不完美，但是都终归走向那个人的向往的结局。或许我本身开始对悲剧的胆怯而导致对喜剧的期待了，人终究是期待美满的。书里一直持续着两条大的线，一条是班纳特姐妹的爱情到婚姻的故事，另一条是达西的傲慢与伊丽莎白的偏见。或者说在班纳特小姐们的爱情中着重叙述了伊丽莎白的故事。书中有两点非常有趣。第一点是彬格莱与吉英的恋爱中的一段。当彬格莱刚开始在尼日斐花园时，对吉英表现了自己对于其的倾慕。但吉英虽然也喜欢彬格莱，却没有表现出喜欢，以至于后来的懊悔。对于自己的喜欢，不要刻意去压抑，喜欢的本身是很美的东西。第二点就是本书中的中心。达西的傲慢的形象，导致了伊丽莎白对于其的偏见。其中有两点很重要，一是我们也需要像达西后来一样，不能有那种十分傲慢、自以为是的态度；二是不能因为自己对于别人的偏见而否定别人。人非圣人，傲慢与偏见是或多或少都有些的。养好自己的心智才是最重要的。]]></content>
      <categories>
        <category>read</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[例行总结——2018版]]></title>
    <url>%2F2018%2F12%2F30%2F%E4%BE%8B%E8%A1%8C%E6%80%BB%E7%BB%93%E2%80%94%E2%80%942018%E7%89%88%2F</url>
    <content type="text"><![CDATA[前言：去年年终总结——《17曲终，18伊始》。18年，当然，我似乎也做了不少事。17年年末开始北漂，在北京开启新的一年；从学校毕业了，自我感觉似乎毕业很久了；现在又离职了，进入了失业状态。这一年有点不平凡。年初时，刚来北京，我去天安门上稍微挥了挥手——《【燕京景】京城第一弹——天安门、故宫》 。再后来，在北京经历了一场新雪——《下雪了》。毕业后，于高铁上写了《那些年的室友，祝安好》，从此我们毕业了。这一年里，我见证了币圈的疯狂，经历了币价的悬崖式大跌。这一年里，我稍微了解了一些区块链比特币。最终还是离开了币圈。这一年里，我明白了人所恐怖的不是不会，而是未知，因为未知所以恐惧，当迎难而上度过了那个点，便不会再害怕了。终究算来，这一年里我读了12本书，读后感写了8篇，自建了公众号“青纸”，虽然写得不怎么好，但自娱自乐是满足了。这一年里，在简书更新了46篇文章，分别为随笔类35篇，技术及工具使用类11篇。这一年里，百词斩实现第160天打卡，上班日子里每天背半个小时的单词。从上总结说，这一年里，读的书主要都在下半年，而且读的书籍还不够多，对于技术的研究学习还不够。这一年里还挺有趣，经历了跑路的理发店，因为地震延迟一个多小时的高铁，凌晨且晚点的航班，回龙观的大水，北方易上天的风。这一年里，我长到了60kg，却没有长身高。来年里，我不能再读这么少的书了，继续坚持简书的不定时更新，继续坚持读后感或者影评的写作。来年里，我需要找到一份工作，做好并做久一份工作。闲来时，继续不定时做一些leetcode题目。继续完成我后续的个人项目。2018，我将归于何处？不减丝毫心气，我仍是少年。]]></content>
      <categories>
        <category>other</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[做出改变——读《谁动了我的奶酪》]]></title>
    <url>%2F2018%2F12%2F16%2F%E5%81%9A%E5%87%BA%E6%94%B9%E5%8F%98%E2%80%94%E2%80%94%E8%AF%BB%E3%80%8A%E8%B0%81%E5%8A%A8%E4%BA%86%E6%88%91%E7%9A%84%E5%A5%B6%E9%85%AA%E3%80%8B%2F</url>
    <content type="text"><![CDATA[谁动了我的奶酪？我不知道。那么奶酪被动了，该怎么办呢？每个人都有自己面对问题的方式，那么哪种方式会是最优解呢？本书中有很重要一点，随着变化而变化，并通过衍生，每个人都可以得到自己的结论。先介绍一下故事中的出场人物。嗅嗅：能够极早地嗅出变化气息；匆匆：能够快速开始行动；哼哼：因为害怕变化而否认和拒绝变化；唧唧：当看到变化会使事情变得更好时，能够及时地调整自己去适应变化。在故事中，嗅嗅和匆匆合作，不停的寻找奶酪，每当当前找到的奶酪没有后，又重新开始寻找奶酪，也不思考规律或者奶酪变化等。虽然效率很低，但是从没有出现没有奶酪的困境。而哼哼和唧唧则使用聪明才智，找到寻找奶酪的最好方式，快速找到奶酪；但是却在找到大量奶酪后，不再寻找，也不再关心奶酪越来越少，奶酪发生变化等。等到奶酪没有后，哼哼和唧唧都开始在原地等待、迷惘。后来唧唧开始寻求改变，出去寻找奶酪，并劝说哼哼。并且在寻找过程不断反思和总结。后来唧唧找到了新的奶酪，并时刻注意奶酪的变化，并准备着面对变化，时常熟悉当前奶酪的附近环境。做出改变，似乎是只面对问题时或者安乐时，对自己做出变化。最为重要的是指，当面对变化时，可以从容对自己做出改变。书中明确提到了有几点值得我们去学习：学会观察当前安乐的环境，准备应对一些突出其来的变化；对于当前所得出的结论，应该快速将其付诸于实践；对于变化，应该学会快速适应，从心理上的适应。这点上类似与大学学习的迎难而上，学会如何去解决问题一样。面对困难时，首先应该想的是如何去解决困难，解决后去想为什么会出现这种问题，准备好下次问题发生时的解决。其实从这之中可以扩展开来，在每个环境中都有各色的人可以匹配这四种角色，每个人都有自己的“奶酪”，每个人对自己奶酪发生变化的应对方案可能解决方案也是这四种。像我之前，有时觉得不是自己的问题，就不用关心了，其实每一个特殊情况的发生，都有可能引发接下来的变化，我们需要学会对于变化的敏感性，学会去应对变化。奶酪是指什么？对于奶酪，我有两种认识。第一种，奶酪是指当前我们所经历的环境，比如工作生活等，这些中都蕴藏这一些变化，如何去应对变化，了解变化，学习变化。第二种，奶酪是指我们面对安乐时的心境。我们面对变化时，是否像哼哼面对变化时一样，因为害怕变化而否认和拒绝变化。其实在我看来，不管如何去准备面对变化，都不会是完全充分的，依然会在某些情况下，都会有一些疏漏。因此拥有一个时刻准备面对变化，迎难而上的心境非常重要了。其实总的来说，类似与中国古谚：“生于忧患，死于安乐”。准备好做出改变了吗？]]></content>
      <categories>
        <category>read</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[寻找悲惨里的崇高，做一个苦行者——读《悲惨世界》]]></title>
    <url>%2F2018%2F12%2F13%2F%E5%AF%BB%E6%89%BE%E6%82%B2%E6%83%A8%E9%87%8C%E7%9A%84%E5%B4%87%E9%AB%98%EF%BC%8C%E5%81%9A%E4%B8%80%E4%B8%AA%E8%8B%A6%E8%A1%8C%E8%80%85%E2%80%94%E2%80%94%E8%AF%BB%E3%80%8A%E6%82%B2%E6%83%A8%E4%B8%96%E7%95%8C%E3%80%8B%2F</url>
    <content type="text"><![CDATA[读《悲惨世界》以来，一直断断续续，没有一次从开始到结尾的读。终究还是读完了这书，悲惨中寻找崇高，活着悲惨里始终如一的善良，那是一种何等的崇高。当读到“我不知道把烛台送给我的那一位，在天上对我是否满意。我已经尽力而为了。”，我已经满眼含泪，一个人只是为了某一个信仰，一生行善，却从抱怨，或许抱怨过，但从没有对生活与世界失去信心，这一种坚持，这一种善心。在这本书中，我所感触最深的有两点。第一点，沙威的自杀。当一个人到头来明白，自己信任并坚持的信仰，却发现是错误的，那人会如何选择。当发现这一辈子中主要的事都是错事，那是一种何等的悲伤，沙威便是无法承受这一新的变化，这一种新的信仰，推翻了自己坚持的信仰。第二点，因为主教的感化，冉阿让从开始对社会有一定的敌意到后续的一直行善。一个人的启发，可以改变某个人或者某些人的一生。我原来多次谈到信仰，在此也是，主教的信仰，行善。“信仰，人所必需。毫无信仰的人实在不幸！”，冉阿让的信仰也是行善。他们都用尽一生去行善，对自己经历过的悲伤，却从不抱怨。“一个人有了痛处，对他最好的怜悯，不就是绝不触碰吗？”主教大人，在这方面是做到了极致，他坚持对每个人善良，对每个人都好。从不去批评和批判某个人的某一点。就是因为主教的善良，才让一颗干涸的心又有了血。书中又一段形容从牢狱里出来的冉阿让——“年复一年，这颗心逐渐干涸，缓慢地，确是不可避免地。心灵干涸，眼睛也干涸。直到出狱，十九年他没有流一滴眼泪”。而主教的善良确认这个干涸的人，心灵流了泪。冉阿让一生没有谈论过政治，没有谈论过时事，他从开始就是一个平凡的人，如果到达死去却不来回顾他的一生，从不会决定这个人的伟大。冉阿让明白自己做了小偷，这个是自己的罪过，不管是多小的罪，罪过依然是罪过，从没有为自己的罪过做过一点辩白。因为一块面包，而经历了19年的牢狱之灾，从此背负着苦刑犯的头衔。这真正说明了这个悲惨的世界。在这么一个悲惨的世界里，有很多像德纳第的人一样，为了生活不折手段一样生存下来的人，也有很多像割风一样老老实实活下来的人。在这个世界里，有很多人起来反抗，有很多人各种行恶，有很多流浪者。其实可以想象得出，这个世界的冷漠，悲伤。我从来相信，每个人都有自己独立的立场。像在街垒的战斗中，防御者和攻击者，哪一个不认为自己在为自己的信仰奋斗，或者哪一个不认为自己在行善积德呢？然而如果这其中的一种立场崩塌，人就会受不住，如同沙威一样。在我看来，沙威也是一个悲惨的人，一生之中自己尽职尽责，却追逐了一个善人的逃犯，仇恶的自己却发现自己却似乎在行恶，最终心中的矛盾无法化解。“人不只是一个中心的圆圈，而是有两个中心的椭圆形。一个中心点是事实，另一个中心点是思想。”这点上我是十分认同的，我信任存在即合理，所以虽然人的思想在某些方面里脱离了事实，但并非在行动上跃出了轨迹，如果思想和事实分离得太远，人就会分裂，我认为双重人格或许就是由此而来吧。对冉阿让而言，事实再清楚也不过了，而思想确是自己选择的，自己不断的善行，自己的信仰。有人说，《悲惨世界》在于告诉我们，再悲惨的世界里，依然会有崇高，依然会有善。在于劝谏人们去追逐那一种善。这点上我是有一些同意的。冉阿让从囚牢里出来，再到了市长。后来领养了珂赛特，并一直伴随着珂赛特的成长到最后完美婚姻的结局。《悲伤世界》是悲多还是喜多些呢？从主人公冉阿让的一生来说，终究是悲伤多了许多。对珂赛特而言，自然而言，是喜多一些，从遇到冉阿让以来，人生都是幸福的，然而我们无法想象，如果珂赛特没有遇到冉阿让，那将会是一种什么样的人生，我们无法想象，或许应该说我们不敢想象。在其中，还展示了另一中影响，爱情的影响。爱潘妮对马修斯的爱，正因为这种爱，爱潘妮选择了奋不顾身。这种爱有一定的私心，却显得十分崇高。一个伟大的苦行者形象，一个令人敬佩的苦行者。也是一个凡人，一个想拥有家庭，想拥有幸福的普通人。而这一种伟大与平凡，能够像主教大人一样，去感染世间人。我也能否，做一个苦行者，尽行善事。]]></content>
      <categories>
        <category>read</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ThreadPoolExecutor源码分析]]></title>
    <url>%2F2018%2F11%2F18%2FThreadPoolExecutor%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[首先，为什么需要读这段源码呢？其实主要就一点，“知其然，知其所以然”。当理解其中的实现方式，就更加明白该如何去使用。为什么需要使用线程池？其原因正如像众所周知的，当我们需要不断的执行各种小型的任务时，而创建与销毁线程所带来的成本将影响系统的性能，因此使用线程池来减少线程的创建、销毁。状态在此，状态是指线程池的状态。其中状态转换如下图当然，在程序中，每个状态都会有一个值来代替。RUNNING：-1；SHUTDOWN：0；STOP：1；TIDYING：2；TERMINATED：3并将所有的值左移29位。在程序中用ctl来表示当前线程池的状态。1private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));ctl是一个原子变量，后续的每一个操作都会使用CAS来进行原子操作。当然我们还需要记录当前线程池中启动的线程数，这个线程数也是通过ctl来记录的。这儿有一个巧妙的设计方式，将ctl的32位比特位分开，将其中前3位用来表示线程池的状态，而后面的29位用来记录当前线程池的线程数。其中每次获取线程数或者获取线程的状态的操作都使用位操作来获得。构造方法123456789101112131415161718192021222324public ThreadPoolExecutor(int corePoolSize,//核心线程上限数量 int maximumPoolSize,//最大线程数 long keepAliveTime,//允许线程空闲等待时间（允许setKeepAliveTime()修改） TimeUnit unit,//时间单位 BlockingQueue&lt;Runnable&gt; workQueue,//任务等待队列 ThreadFactory threadFactory,//线程构造工厂 RejectedExecutionHandler handler) &#123;//任务拒绝方案 if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0)//校验参数 throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.acc = System.getSecurityManager() == null ? null : AccessController.getContext();//初始化上下文 this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler;&#125;其中需要注意的有两点。第一点，最大线程数代表的是在线程池中执行任务所允许的最大线程数。在线程池中，分为两种线程，一种是“固定工作人员”线程，另一种是“临时工”，只是在线程池有压力的情况下才会请用“临时工”。而最大线程数代表的是所有允许工作的线程数，核心线程上限数量为最多允许的“固定工作人员”线程数。第二点，在构造方法中，有允许默认线程构造方式，以及默认拒绝方案等。默认拒绝方案是接受任务时，不做处理，直接抛出异常。拒绝方案总共：CallerRunsPolicy、AbortPolicy、DiscardPolicy、DiscardOldestPolicy。CallerRunsPolicy：默认创建线程执行任务，除非执行器关闭AbortPolicy：默认执行方案；不执行任务，直接抛出异常DiscardPolicy：什么也不做。Does nothingDiscardOldestPolicy：将任务队列的队头任务丢弃，再执行尝试加入队列。除非执行器关闭executeexecute方法为线程池接收任务的方式。12345678910111213141516171819public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); int c = ctl.get(); if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; else if (!addWorker(command, false)) reject(command);&#125;其中整体思路也是比较简单的明了的。1、首先，校验运行线程数小于核心数，尝试增加新的核心线程直接运行任务，结束；2、如果线程池在运行状态，尝试加入等待队列；加入成功后再次校验运行状态：非运行状态则移除任务并拒绝任务（拒绝任务时会执行拒绝方式）；如果线程池没有运行的线程，则加入一个新的非核心线程（运行任务将从队列中去获取）；3、对于上一点开始的判断不满足，则再次尝试加入一个非核心线程运行当前任务，失败则拒绝任务。在第2点中为什么需要再次校验线程池中没有线程，并加入线程呢？其中在于并发情况下，当我在加入任务到等待队列时，刚好前面运行的线程都执行完任务，并队列为空，如果没有等待时间或者等待时间很短，那么这些线程都会消亡，那么在加入任务到线程池等待队列后，线程池没有消费任务的线程。为什么添加“非核心”线程呢？如果添加的是核心线程会有什么不一样吗？其实换个角度想就明白了。核心线程与非核心线程在线程池中有明显的区分吗？并没有。只是有表示核心线程数上限与总线程数上限。加入线程时判断是否加入核心线程，只是判断当前线程总数是否到达核心线程数的限制。而这儿，线程总数是空的，因此加入一个新的线程，不管核心与否都行，但是必须要传这个参数。当然有一种情况，如果在此处加入非核心线程的前，其他允许核心数的线程加入线程，那么当前线程的加入没有达到最大线程数限制则不会失败，在我看来这儿传true/false本质上是相同的，ThreadPoolExecutor本身具有一定的自适应调节能力。重点是必须要传一个参数。123456...int wc = workerCountOf(c);if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false;...在第3点中，如果任务加入队列失败且创建了一个新的非核心线程。这种情况代表着当前情况下，目前的生产者的生产数量大于消费者数量，需要增加消费者的数量，等到不需要时，再释放临时工。其中addWorker函数，参数firstTask代表初始化任务，core代表创建的线程是否核心线程，而返回结果true/false分别代表新建线程加入并启动成功/失败。shutdownshutdown函数逻辑如下：1、先获得自旋锁，并加锁2、对每个worker检查是否有修改线程权限（需要加锁）3、循环尝试修改执行状态为SHUTDOWN4、尝试阻塞每个线程（修改阻塞标志）5、关闭锁后并调用tryTerminate()函数12345678910111213public void shutdown() &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; checkShutdownAccess(); advanceRunState(SHUTDOWN); interruptIdleWorkers(); onShutdown(); // hook for ScheduledThreadPoolExecutor &#125; finally &#123; mainLock.unlock(); &#125; tryTerminate();&#125;tryTerminate方法将在循环中执行下叙流程：1、判断线程池状态，运行中，TIDYING，或者SHUTDOWN同时等待队列不为空则结束；2、判断当前线程执行数不为0，阻塞一个线程，结束（只是标识为阻塞）；3、获取锁并加锁；4、尝试状态位设置为按位或上TIDYING；5、执行terminated，预留可被重载；6、状态位设置为按位或上TERMINATED；7、signalAll，唤醒此lock上等待的所有线程；8、关闭锁；shutdownNowshutdownNow()函数与shutdown()函数的主要区别是，shutdownNow会马上停止线程池，而shutdown不会马上停止线程池，会待目前线程池中的任务执行完成后再停止线程池。在代码上体现为三点区别：shutdownNow修改线程池的状态为STOP状态；shutdownNow调用阻塞线程是调用的是interruptWorkers()方法，而shutdown调用的是interruptIdleWorkers()方法。这两个线程方法具有本质的区别，interruptWorkers会直接将循环所有的线程进行阻塞线程，而interruptIdleWorkers会阻塞没有运行的任务的线程，其中在于后者会拿到Worker的的锁后再调用阻塞；shutdownNow会直接清空任务队列里没有运行的任务，并返回。Worker::run首先，Worker是对于线程的一个封装，其中有当前线程，初始化任务，完成任务数等信息。1234567891011121314151617181920212223242526272829303132333435363738final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); Runnable task = w.firstTask; w.firstTask = null; w.unlock(); // allow interrupts boolean completedAbruptly = true; try &#123; while (task != null || (task = getTask()) != null) &#123; w.lock(); if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try &#123; beforeExecute(wt, task); Throwable thrown = null; try &#123; task.run(); &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; afterExecute(task, thrown); &#125; &#125; finally &#123; task = null; w.completedTasks++; w.unlock(); &#125; &#125; completedAbruptly = false; &#125; finally &#123; processWorkerExit(w, completedAbruptly); &#125;&#125;其中逻辑如下：1、尝试从队列中拿出一个任务；（初始化时任务可能为空，后续将在此不断循环）2、加锁；3、判断线程池是否停止，如果停止则中断线程；4、执行任务；5、task置空，并将当前线程完成任务数自增，并关闭锁；6、清理。在清理中，会判断当前执行任务异常而导致线程结束，则将worker数减1，并执行一些清理性的工作。getTask在本处也是一个很有趣的方法。其实也很简单，就是循环尝试从任务队列中拿出一个新的任务，如果拿出了就返回，这是一个消费者。1、如果当前线程池的状态是STOP或者将STOP，则将worker数减1并结束；2、计算是否有存活时间，以及线程数是否大于允许核心数；3、根据2的计算结果判断线程是够需要结束，尝试将线程数减1；4、尝试从队列中拿出任务，poll方法可以超时，并返回（会阻塞等待）；5、没有拿出任务则把timeOut置为true；其实在这儿就可以明白，keepAliveTime所代表的当线程为空时，线程死亡前的等待时间，其实是设置为线程等待任务队列中拿到任务的超时时间。总结在ThreadPoolExecutor通过充分的利用锁以及CAS操作，保证了线程安全性，并且也不会有性能上的限制。并且使用一个变量来直接代表两个意义的使用方式挺惊艳。以及在核心线程与非核心线程上的区分都设计得恰到好处。整体设计方案值得学习。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ConcurrentHashMap 源码分析（Java version 1.8）]]></title>
    <url>%2F2018%2F10%2F06%2FConcurrentHashMap-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%EF%BC%88Java-version-1-8%EF%BC%89%2F</url>
    <content type="text"><![CDATA[在我之前的文章《HashMap 源码分析》中分析了HashMap的源码，众所周知，ConcurrentHashMap是线程安全的Map，在Java 1.7及以前版本使用分段加锁机制，而1.8版本开始使用CAS操作，抛弃了segment，并只对哈希桶数组的的单个元素加锁。相对于HashTable对于每个方法都使用synchronized，效率提升了非常大。本文所解读的ConcurrentHashMap是基于Java 1.8 版本。部分代码过于繁琐，因此建议对照源码。总体结构从总体上，ConcurrentHashMap与HashMap的结构是相同的，是基于哈希桶数组加链表以及红黑树构成的。红黑树，是平衡查找树的一种，使用这种结构，可以加速查找。CAS操作，是一种乐观锁技术，直接CPU支持，通过不断的尝试，获取值并进行比较操作，这种操作相比较锁来说，减少了不少的消耗以及等待等。&lt;&lt;：左移，相当于乘以2>&gt;：右移：相当于除以2>&gt;&gt;：无符号右移，空位补0节点在节点上，也是基本与HashMap相同，有Node，并通过继承等，得到TreeNode、TreeBin、ForwardingNode等类。ForwardingNode用来标示当前节点在扩容的时候已经迁移到新的哈希桶数组中了，当前的hash为-1，而TreeNode是构建红黑树的元素，而在哈希桶数组中存储的却不是TreeNode，当红黑树时，使用TreeBin封装TreeNode后放入哈希桶数组，这点与HashMap不同。1234567static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; volatile V val; volatile Node&lt;K,V&gt; next; ...&#125;而ForwardingNode相对与Node来说，多了一个nextTable属性，创建该Node时，除了将hash设置为-1外，还需要将nextTable设置成指向扩容后哈希桶数组的引用。12345678static final class ForwardingNode&lt;K,V&gt; extends Node&lt;K,V&gt; &#123; final Node&lt;K,V&gt;[] nextTable; ForwardingNode(Node&lt;K,V&gt;[] tab) &#123; super(MOVED, null, null, null); this.nextTable = tab; &#125; ...&#125;TreeNode中继承了Node的属性，也实现了指向父节点，左右节点，以及前一个节点的引用。而在TreeBin中，需要关注的是first，是指向红黑树根节点的的引用，而用lockState来对红黑树加读写锁。12345678910111213static final class TreeNode&lt;K,V&gt; extends Node&lt;K,V&gt; &#123; TreeNode&lt;K,V&gt; parent; // red-black tree links TreeNode&lt;K,V&gt; left; TreeNode&lt;K,V&gt; right; TreeNode&lt;K,V&gt; prev; // needed to unlink next upon deletion boolean red; TreeNode(int hash, K key, V val, Node&lt;K,V&gt; next, TreeNode&lt;K,V&gt; parent) &#123; super(hash, key, val, next); this.parent = parent; &#125; ...&#125;构造函数在构造函数中，与HashMap比较相似，只是初始化一些变量的值，如初始化容量、负载因子等，以及concurrencyLevel，这个在1.8版本中已经不重要了，初始化容量可能会受这个元素影响。123456789public ConcurrentHashMap(int initialCapacity, float loadFactor, int concurrencyLevel) &#123; if (!(loadFactor &gt; 0.0f) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0) throw new IllegalArgumentException(); if (initialCapacity &lt; concurrencyLevel) // Use at least as many bins initialCapacity = concurrencyLevel; // as estimated threads long size = (long)(1.0 + (long)initialCapacity / loadFactor); int cap = (size &gt;= (long)MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : tableSizeFor((int)size); this.sizeCtl = cap;&#125;当然，这个与HashMap中非常相似，在初始化哈希桶数组容量时，会使用tableSizeFor()将数组长度初始化为2的n次方的长度。而负载因子是指在符合一定条件下，当目前的元素总数达到负载因子乘上容量时，将进行扩容操作。get在说明get方法前，需要注意在ConcurrentHashMap中，所有传入的key、value等都不能为null，否则会抛出NullPointException。首先，对应HashMap中的hash()函数的speed函数，相对于来说增加了按位与上0x7fffffff，这个为2进制中从右到左31个1。保证了hash值一定大于0，这个因为在ConcurrentHashMap中，为负数的部分hash是有特殊含义的，这个在后面会有提到。123static final int spread(int h) &#123; return (h ^ (h &gt;&gt;&gt; 16)) &amp; HASH_BITS;&#125;在get中，首先根据key计算hash，然后使用哈希桶数组长度n得到的n-1值按位与上hash，得到定位到哈希桶数组中的位置；然后使用原子操作，取得这个位置的Node；如果当前的hash值相等，并且key相等，直接返回val；如果当前值的哈希小于0，则表示当前的Node要么是TreeBin，或者ForwardingNode，然后调用其find()函数查找。其他情况下，即链表情况，遍历链表返回结果。1234567891011121314151617public V get(Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek; int h = spread(key.hashCode()); if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (e = tabAt(tab, (n - 1) &amp; h)) != null) &#123; if ((eh = e.hash) == h) &#123; if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) return e.val; &#125; else if (eh &lt; 0) return (p = e.find(h, key)) != null ? p.val : null; while ((e = e.next) != null) &#123; if (e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) return e.val; &#125; &#125; return null;&#125;其中find会根据Node不同调用各自的find函数。首先是ForwardingNode的find函数，首先，在这个Node的情况下，表示当前Node的值已经迁移到了新的哈希桶数组中，因此在查找时，也需要进入新的哈希桶数组中查找。循环尝试nextTale中定位hash位置。通过Node或者TreeBin查找节点。具体代码如下，其中保证了扩容后的哈希桶数组又出现扩容等情况，通过不停对于每个数组尝试操作。1234567891011121314151617181920212223Node&lt;K,V&gt; find(int h, Object k) &#123; // loop to avoid arbitrarily deep recursion on forwarding nodes outer: for (Node&lt;K,V&gt;[] tab = nextTable;;) &#123; Node&lt;K,V&gt; e; int n; if (k == null || tab == null || (n = tab.length) == 0 || (e = tabAt(tab, (n - 1) &amp; h)) == null) return null; for (;;) &#123; int eh; K ek; if ((eh = e.hash) == h &amp;&amp; ((ek = e.key) == k || (ek != null &amp;&amp; k.equals(ek)))) return e; if (eh &lt; 0) &#123; if (e instanceof ForwardingNode) &#123; tab = ((ForwardingNode&lt;K,V&gt;)e).nextTable; continue outer; &#125; else return e.find(h, k); &#125; if ((e = e.next) == null) return null; &#125; &#125;&#125;而对于TreeBin的find，在每次循环中，先判断当前是否已经进入写锁（即存在写的线程或者等待写的线程），如果是，则判断当前节点的hash以及key相等，则直接返回当前节点，否则则进入下一个节点（在TreeNode中也又Node的元素，因此每个节点依然有指向下一个节点的引用）；当前没有写锁的情况下，使用CAS操作给TreeBin加上读锁，并查找Node，并在finally中，判断如果将读锁去掉一个读锁后，不存在正在写的线程，则唤醒正在等待写的线程。12345678910111213141516171819202122232425final Node&lt;K,V&gt; find(int h, Object k) &#123; if (k != null) &#123; for (Node&lt;K,V&gt; e = first; e != null; ) &#123; int s; K ek; if (((s = lockState) &amp; (WAITER|WRITER)) != 0) &#123; if (e.hash == h &amp;&amp; ((ek = e.key) == k || (ek != null &amp;&amp; k.equals(ek)))) return e; e = e.next; &#125; else if (U.compareAndSwapInt(this, LOCKSTATE, s, s + READER)) &#123; TreeNode&lt;K,V&gt; r, p; try &#123; p = ((r = root) == null ? null : r.findTreeNode(h, k, null)); &#125; finally &#123; Thread w; if (U.getAndAddInt(this, LOCKSTATE, -READER) ==(READER|WAITER) &amp;&amp; (w = waiter) != null)//判断如果将读锁去掉一个读锁后，不存在正在写的线程 LockSupport.unpark(w); &#125; return p; &#125; &#125; &#125; return null;&#125;putput操作中，与HashMap有所不同，此处不支持value为null。整个put操作分为几个部分，计算位置，判断哈希桶状态是否需要加入帮助扩容，放入节点，判断是否需要红黑树化。首先计算哈希值以及一些准备状态，比较简单。需要说明的是binCount在这儿代表着的是当前链表的长度，当已经是红黑树时，直接赋值2。然后进入循环尝试put操作中。1、当哈希桶数组不存在时，初始化数组当进入初始化函数后，将会去循环尝试，循环里先判断sizeCtl是否已经小于0，表示已经有其他线程进入了初始化的环节了，因此自旋等待；其他情况则尝试将sizeCtl置为-1，然后初始化一个哈希桶数组，最后将sizeCtl置为数组长度乘上负载因子。需要注意的是，Thread.yield();是将当前线程从运行态放入就绪状态的队列，一旦抢到cpu就可以继续执行。并且这里是循环里执行的，只要没有进入put完成，就会一只循环去尝试put。2、当hash值散列到数组上位置为空时，尝试cas操作去直接put，成功则退出。3、当哈希桶数组对应位置上的值已经迁移到新的哈希桶数组时，即hash为-1，则帮助扩容。扩容相关后续详解。4、其他情况，表示当前节点有值，形成链表或者红黑树。首先在该节点上加锁，并再次校验hash对应的是该数组位置。当为链表时，直接将Node放了进去，注意重复key存在的情况会根据onlyIfAbsent判断是否更新，并且循环链表时，需要给binCount自增。如果是红黑树的情况，直接将binCount设置成2，使用putTreeVal函数放入新节点或者拿到老节点，同样根据onlyIfAbsent更新新的val。在加锁结束后根据binCount是否大于等于8来判断是否需要进行红黑树化。同样的，进行红黑树化时，也需要对数组中的该节点进行加锁操作。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758final V putVal(K key, V value, boolean onlyIfAbsent) &#123; if (key == null || value == null) throw new NullPointerException(); int hash = spread(key.hashCode()); int binCount = 0; for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; if (tab == null || (n = tab.length) == 0) tab = initTable(); else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin &#125; else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else &#123; V oldVal = null; synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; if (fh &gt;= 0) &#123; binCount = 1; for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; if ((e = e.next) == null) &#123; pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; else if (f instanceof TreeBin) &#123; Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; if (binCount != 0) &#123; if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125; &#125; addCount(1L, binCount); return null;&#125;当然，在最后循环尝试结束后，将总数加1。在增加数量时，会有根据check来判断是否需要扩容，@param check if &lt;0, don&#39;t check resize, if &lt;= 1 only check if uncontended。addCount的基本逻辑如下。1、尝试使用cas修改baseCount。2、如果修改失败，则随机取CounterCell数组的一个元素更新数据。3、如果数组为空或者更新失败则调用fullAddCount函数，进行循环插入插入数据。此处包括对应CounterCell数组的一系列扩容操作。4、如果需要check，则调用sumCount函数计算总数，根据情况扩容。当然分别有扩容的初始化数组主线程以及帮助扩容的其他线程，根据sizeCtl的值进行判断。sumCount的计算，是将baseCount的值与数组中的所有值累计。扩容扩容是ConcurrentHashMap中非常重要的操作，类似在HashMap中相同，扩容的基本操作都是将哈希桶数组的长度扩展成两倍，然后将当前桶中的节点依次迁移到新的桶的。同样的，在迁移的时候，只需要将节点迁移到新的哈希桶的数组中的相对位置以及右移当前数组长度的位置。首先，在什么时候可以进入扩容操作呢？1、当在每次put的addCount时，map的节点数量达到扩容的负载的限制时，则进行扩容；2、当put时候判断已经进行扩容的时候，则进入帮助扩容；3、当进行清除的时候，正在扩容也进入帮助扩容；当在替换节点时，（删除记做替换节点为null）的情况下，如果哈希桶数组在扩容也进入帮助扩容。1、扩容开始时，首先计算每个线程需要迁移的哈希桶数组的元素，最少16，此处充分利用了cpu的并发粒度，计算同时并发时每个线程需要负责的数目。2、当扩容后的迁移哈希桶数组不存在的时候，尝试创建哈希桶数组。3、构建ForwardingNode指向新的哈希桶数组。4、循环中去申请扩容负责的部分，以及进行扩容。在这里面advance代表是否进入迁移下一个节点，而finishing代表是否以及完成了当前分配负责区域的迁移。5、循环尝试使用cas操作分配迁移的的数组的索引下标，advance设置成true，进入迁移操作。6、判断分配阈值超过范围。根据finishing判断结束，则更新一些变量（此处对于一次扩容只会执行一次）；其他情况，则将sizeCtl减1成功，表示有新的线程完成了扩容操作，然后通过(sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT筛选出最后一个线程设置finishing为true进入扩容的最后操作，即上述说的进行变量更新操作（这儿保证了只有一个线程进行该操作）。最后一个线程将循环哈希桶数组进行再次校验所有的节点已将迁移完成。7、如果当前需要迁移的数组元素为null，则直接使用cas设置为ForwardingNode，设置成功则前进。8、如果当前正在迁移，即hash为-1，则直接前进。9、当前哈希桶数组元素存储的是链表或者红黑树。对node进行加锁并再次校验。在这种情况下，当然依然需要对链表、红黑树进行分别的处理。首先是链表的情况，这种情况下，拆分成两个链表也不会出发红黑树化的操作。先得到迁移相对位置或者偏移位置的某一种情况的最后一个节点，即最后一个与前一节点迁移位置不同的节点，即在这个节点之后的节点都会迁移到相同的位置。并根据这个节点是否需要迁移，将节点赋值给ln或者hn，前者是迁移到相对位置，后者迁移到偏移位置。循环链表构建两个数组，链表只需用循环到上述所得最后一个与前一个节点迁移位置不同的节点即可。最后将两个链表写入新的链表的对应位置，然后将当前哈希桶数组的值设置成ForwardingNode，表示已经完成扩容。为什么需要先进行定位到最后不需用循环做构建新链表的，然后再循环到该节点呢构建链表呢？这点上我暂时没有明白，毕竟一个链表的最大长度也就7的长度，不管怎么做，其效率都是非常高的，而且不会出现特别慢的情况。另一种情况就是红黑树的情况。这种情况下依然需要构建两个红黑树，当然最开始构建的时候是构建两个TreeNode的链表，当然同时需要记录每个链表的节点数。最后根据计数结果判断是构建红黑树还是链表化。构建红黑树的时候是在TreeBin的构造函数。然后设置新的哈希桶数组的值，最后前进。最后循环进入下一个需要迁移的位置。在上诉说的第6点中提到了sizeCtl的值通过标记的移位等操作判断是最后一个执行的线程。相关代码如下。12345678...if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) &#123; if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) return; finishing = advance = true; i = n; // recheck before commit&#125;...这部分中容易受到sizeCtl注释中的影响，注释中如下，说明有负的（1+n）时代表有n个线程在帮助扩容，在我的理解下这儿的注释是错误的。When negative, the table is being initialized or resized: -1 for initialization, else -(1 + the number of active resizing threads).我的理解下，sizeCtl在进入的扩容的第一个线程时，声明为一个负得很大的数，比如当一个容量为64的map扩容时，这个sizeCtl在第一个线程进入扩容后的值为-2145845246。然后在每个线程进入扩容后，会将这个sizeCtl加1，然后每次线程结束扩容后将sizeCtl减1。所以当前正在扩容的线程应该是(resizeStamp(tab.length()) &lt;&lt; RESIZE_STAMP_SHIFT) + 2 - sizeCtl + 1。至于为什么要这么写来表示扩容呢？这点上我不是很清楚。在下面代码中表示了每个进入扩容的函数都会经历的部分相似逻辑。12345678910111213...while (s &gt;= (long)(sc = sizeCtl) &amp;&amp; (tab = table) != null &amp;&amp; (n = tab.length) &lt; MAXIMUM_CAPACITY) &#123; int rs = resizeStamp(n); if (sc &lt; 0) &#123; if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex &lt;= 0) break; if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) transfer(tab, nt); &#125; else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) transfer(tab, null);&#125;...其中表示了当已经进入扩容的情况下，当前线程加入后线程线程数限制resizeStamp + (1 &lt;&lt; (32 - 16)) - 1)，需要校验如果扩容分配的空间已经分配完成，如果满足这些条件下，则线程退出不进入扩容，否则将sizeCtl加1，进入扩容。如果没有线程进入扩容，则将sizeCtl初始化，然后进入扩容。replaceNode为什么要特别提及replaceNode函数呢？replaceNode函数不仅仅在replace的时候使用了，而且在remove的时候也调用了，只是传入的value为null。依旧，首先计算哈希值，然后循环尝试。1、当数组不存在或者哈希定位的值不存在时，结束。2、如果当前位置已经扩容，代表当前map进入扩容操作，则帮助进行扩容。3、其他情况，即当前位置存在链表或者红黑树等。这种情况下，会将当前节点加锁，并进行再次校验验证。当前是链表的情况，循环找到key对应的节点，如果需要更新的value是null的情况，则删除节点，否则替代节点。（首节点的情况下，需要单独处理，将首节点的Node设置到哈希桶数组中。）红黑树的情况，使用TreeNode的findTreeNode函数返回对应的节点，value不为null的情况，更新value或者使用removeTreeNode删除节点。删除情况通过removeTreeNode返回true/false结果判断是否进行红黑树化。4、在循环尝试结束后，判断是否删除以及是否成功等，将map的节点数减1。clearclear的意思是移除map中的所有的node，当然依然是循环哈希桶数组中的每个元素，做去除操作。每个循环里定位到当前节点。1、如果当前节点为空的情况，直接进入下一个节点。2、当前节点的hash为-1时，表示当前节点以及迁移到新的哈希桶数组，则进行帮助扩容操作，并将需要clear的哈希桶数组修改为扩容后的数组，并将清除索引修改为0，扩容后重新进行清除操作。3、其他情况，即当前节点存在链表或红黑树的情况。先给节点加锁，然后获取链表的开始节点，TreeNode的情况下也有指向下一个Node的引用，开始节点为TreeBin的first指向的节点。循环链表，累计Node的数目。然后将当前哈希桶数组的节点置为null。1234567891011121314151617181920212223242526272829public void clear() &#123; long delta = 0L; // negative number of deletions int i = 0; Node&lt;K,V&gt;[] tab = table; while (tab != null &amp;&amp; i &lt; tab.length) &#123; int fh; Node&lt;K,V&gt; f = tabAt(tab, i); if (f == null) ++i; else if ((fh = f.hash) == MOVED) &#123; tab = helpTransfer(tab, f); i = 0; // restart &#125; else &#123; synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; Node&lt;K,V&gt; p = (fh &gt;= 0 ? f : (f instanceof TreeBin) ? ((TreeBin&lt;K,V&gt;)f).first : null); while (p != null) &#123; --delta; p = p.next; &#125; setTabAt(tab, i++, null); &#125; &#125; &#125; &#125; if (delta != 0L) addCount(delta, -1);&#125;在循环清理完成后，调用addCount函数将map中的总数减掉清除的Node数目。附compute是传入function来计算新值，然后put（前提是符合条件，才进入计算新值）。以及merge等函数等。以及在1.8版本后推出使用mappingCount()来代替size函数。ConcurrentHashMap是支持并发的Map，并且尽量减少来加锁的操作以及减小了加锁的粒度，并使用了CAS操作，因而增大了并发度。对于其中一些设计及写法的原因，目前还很迷糊。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>map</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决SXSSF使用时“Attempting to write a row[?] in the range [0,?]that is already written to disk.”异常]]></title>
    <url>%2F2018%2F09%2F22%2F%E8%A7%A3%E5%86%B3SXSSF%E4%BD%BF%E7%94%A8%E6%97%B6%E2%80%9CAttempting-to-write-a-row-in-the-range-0-that-is-already-written-to-disk-%E2%80%9D%E5%BC%82%E5%B8%B8%2F</url>
    <content type="text"><![CDATA[在开发中，使用SXSSFWorkbook构建导出excel时，可能会遇到“Attempting to write a row[?] in the range [0,?]that is already written to disk.”的报错情况，如下图所示。对于这种情况下，需要我们详细分析，首先时这个错误时从哪儿抛出的，通过源码分析，查看到在SXSSFSheet的createRow函数中找到这样一个抛出异常的位置。1234567 ...if (rownum &lt;= this._writer.getLastFlushedRow()) &#123; throw new IllegalArgumentException("Attempting to write a row[" + rownum + "] " + "in the range [0," + this._writer.getLastFlushedRow() + "] that is already written to disk.");&#125; else if (this._sh.getPhysicalNumberOfRows() &gt; 0 &amp;&amp; rownum &lt;= this._sh.getLastRowNum()) &#123; throw new IllegalArgumentException("Attempting to write a row[" + rownum + "] " + "in the range [0," + this._sh.getLastRowNum() + "] that is already written to disk.");&#125; else &#123; ...分析这段异常的原因，当前要创建的行小于等于最近已经创建的行时，就会抛出异常。因此这个要求是，我们不能在已经创建行的位置再创建行。究其原因，是在于SXSSFWorkbook的本身实现方式，其本身实现方式在于，不断的将一定行数的表格写入临时文件，最终将所有的临时文件合并起来，这种方式中保证了内存的占用数理想，并且导出的效率也比较理想。在这种实现中，如果一个行已经写入临时文件了，就不能再修改了，因此在源代码中直接限制了重复创建并写同一栏，并在此抛出异常。解决方案1、使用HSSFWorkbook、XSSFWorkbook替代SXSSFWorkbook。这种方式中要么是在HSSFWorkbook中仅支持xls，并且导出的数量有限，并且导出文件效率也较低，内存占用较大；虽然在XSSFWorkbook中，导出效率提高了，使用了xlsx格式，导出数量限制也大大放宽，但是内存占用问题依然没有得到解决。2、避免在已经创建的行上重新创建行，使用getRow代替重复创建的情况。注：多数情况下，这种情况的出现，都是因为程序行数计数标志出现了重复、计数错误等情况导致的。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>poi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[根据前序和后序遍历构造二叉树]]></title>
    <url>%2F2018%2F08%2F19%2F%E6%A0%B9%E6%8D%AE%E5%89%8D%E5%BA%8F%E5%92%8C%E5%90%8E%E5%BA%8F%E9%81%8D%E5%8E%86%E6%9E%84%E9%80%A0%E4%BA%8C%E5%8F%89%E6%A0%91%2F</url>
    <content type="text"><![CDATA[在leetcode上做题刚好做到一题：根据前序和后序遍历构造二叉树。在我们一般构建二叉树时，一般是根据中序和前序或者后序构建二叉树。根据前序和后序构建的二叉树不一定是唯一的。889. 根据前序和后序遍历构造二叉树返回与给定的前序和后序遍历匹配的任何二叉树。pre 和 post 遍历中的值是不同的正整数。不多说，上代码：12345678910111213141516171819202122232425262728293031323334353637public TreeNode constructFromPrePost(int[] pre, int[] post) &#123; if (pre.length &lt;= 0) &#123; return null; &#125; return constructFromPrePostHelper(pre, post, 0, 0, post.length - 1);&#125;private TreeNode constructFromPrePostHelper(int[] pre, int[] post, int flag, int postStart, int postEnd) &#123; if (flag &gt;= pre.length || postStart &gt; postEnd) &#123; return null; &#125; else if (flag &lt; pre.length &amp;&amp; postStart == postEnd) &#123;//判断没有子树的节点 return new TreeNode(pre[flag]); &#125; int mid = postStart; //判断左右子树的分隔点 if (flag + 1 &lt; pre.length) &#123; for (; mid &lt; postEnd; mid++) &#123; if (post[mid] == pre[flag + 1]) &#123; break; &#125; &#125; &#125; TreeNode node = new TreeNode(pre[flag]); node.left = constructFromPrePostHelper(pre, post, flag + 1, postStart, mid); node.right = constructFromPrePostHelper(pre, post, flag + mid - postStart + 2, mid + 1, postEnd - 1); return node;&#125;public class TreeNode &#123; int val; TreeNode left; TreeNode right; TreeNode(int x) &#123; val = x; &#125;&#125;测试用例：输入：pre [1,2,4,5,3,6,7], post [4,5,2,6,7,3,1]输出：[1, 2, 3, 4, 5, 6, 7]原理：在通过递归的方式，每次找到分隔点，构建左右子树的方式，在其中主要需要判断最终一个没有子树的节点判断。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[这是一只不正经的猫：读《我是猫》]]></title>
    <url>%2F2018%2F08%2F14%2F%E8%BF%99%E6%98%AF%E4%B8%80%E5%8F%AA%E4%B8%8D%E6%AD%A3%E7%BB%8F%E7%9A%84%E7%8C%AB%EF%BC%9A%E8%AF%BB%E3%80%8A%E6%88%91%E6%98%AF%E7%8C%AB%E3%80%8B%2F</url>
    <content type="text"><![CDATA[这是一个不正经的猫，从本书中的这只猫来看，这只猫似乎有一种通晓天地，明了古今。能够不经历九年义务教育就懂得一些教育学家以及理学家的谈话。这只猫或许在老师的家里待得太久，就明了这许许多多的人事与时事，也或许通过猫界里的“人类学家”精心传授。这些都是些不正经的话语。每一本书，都有自己独到的地方，这本书当然不例外。以猫的角度写某个时期的场景，确实有一种无法比拟的悲。这种悲主要是指那些知识分子等的悲。然而这种悲伤，我无法去感同身受。人们所能感同身受的悲，莫过于自己经历过同样的悲伤。我或许还不像这书中的知识分子同样，有着面对新潮而无法接受，或者在某一种程度上却自己不被世界接受的悲伤。《我是猫》是过去作品吗？或者说写的仅仅是过去的某个时代的吗？这却得深思，在当今这个社会里，没有那些相同的吗？像苦沙弥，他正代表着自己这一类知识分子，对于实业者有着一种鄙夷，而反之金田所代表的实业家，也对那些穷苦知识分子有一种轻蔑。这是明显的两个阶层之间的矛盾。在当下，依然在有条不紊地摩擦着。这本书，我没有多少感悟，这也是一种缘。摘来部分难得的机缘，会使所有的动物敢于干出他们并非情愿的事来。临危之际，平时做不到的事这时也能做到。看起来，人哪，为了消磨时间，硬是鼓唇摇舌，笑那些并不可笑、乐那些并不可乐的事，此外便一无所长。一言以蔽之，不论是主人、寒月还是迷亭，都是些太平盛世的逸民。尽管他们像没用的丝瓜随风摇曳，却又装作超然物外的样子。其实他们既有俗念，又有贪欲。即使在日常谈笑中，也隐约可见其争胜之意、夺魁之心。进而言是一丘之貉。假如既不能零售空气，又不能割据苍天，那么，土地私有，岂不也是不合理的吗？真理在咱家手里，而权力却握在别人的手心，这时，只有两条路：或委曲求全，唯命是从；或背对权贵的耳目，我行我素。我想写美学原理的意志很坚定，可这意志对你发表后的第二天就已经忘得一干二净。因此，没能在紫薇花飘零以前完成我的著作，这时记忆力的罪孽，而不是意志的过错。既然不是意志的过错，也就没有什么理由请你吃西餐了。既然是社会动物，不管怎么自命清高，也要在某种程度上与社会协调些。那些家伙到底是“知了知了”地叫？还是“了知了知”的地鸣？冷漠乃人类本性，不加掩饰才是正直的人。]]></content>
      <categories>
        <category>read</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[时间简史：读完了多少，读懂了多少]]></title>
    <url>%2F2018%2F07%2F29%2F%E6%97%B6%E9%97%B4%E7%AE%80%E5%8F%B2%EF%BC%9A%E8%AF%BB%E5%AE%8C%E4%BA%86%E5%A4%9A%E5%B0%91%EF%BC%8C%E8%AF%BB%E6%87%82%E4%BA%86%E5%A4%9A%E5%B0%91%2F</url>
    <content type="text"><![CDATA[读完这本书，仅仅用读完来形容了。这书里面的有许多的知识都是我无法去理解的。果然发现，这是一本不符合畅销书的畅销书了。这本书里，虽然没有提到多少公式性的推到，只放了一个E=mc^2 爱因斯坦质能方程，然而就这样一本定位于科普读物的书籍，却没有多少人能够读完。为什么是畅销书呢？我们先分析人类读书的意图，除了应付考试、学以致用，剩下的一个很重要的就是“装逼”了。虽然这样谈吐起来，确实并不文雅，但现在人读书都是有着一个目标去读书的，像如何在书籍里得到职场的一些经验，如何应付当前的考试，如何在书籍里找回自己那个颗沉静的心，如何表现出高逼格等，都是现实中读书的一些需求。在现在，书籍除了用于阅读外，还有装潢的作用了。这个作用可大了，除了放在家里作实物上的修饰外，还有作为一种谈论资本上的学识上的修饰。我并不是说这个装饰不好，反而我却非常认同这种装饰，毕竟在这个装饰中，体现了一个主人的思维——读书是非常好的，知识是值得炫耀的。这点上我是非常认同的。在这本书上，除了阅读本身外，就剩下一些装饰了，而且这本书，在我看来平常的用处里，在实物上的装饰应该占比较高。有多少人读完了？又读懂了多少呢？曾有人有过这样一个观点：当哲学与科学分离后，就只剩下对于语言的理解。这点我是非常认同的。反之，科学脱离哲学后，却增加了更多的专业性以及推理性。因此在后代科学中，更加专业，并且多数基于观察现实以及对未来的预测。这本书之所以晦涩难懂，还有一个很根本的原因，因为时间简史，是基于数学运算而得出的推理，并不是基于现实的观察，这种晦涩因此十分明了了。当然，这种读完与否、读懂与否，都是一种收获。至少明白了，这世间，有许多前沿性的知识，是我当下所不能理解的。所谓不懂也是一种收获。在时间简史里，主要介绍了宇宙的本身、以及宇宙中的粒子、黑洞以及时间等许多，这些理解都是我们的基础中的认识。像这一类的科学读物，都是通过这类的读过，丰富自己的认识，或者说纠正自己的那些认识。像我平时认识中，并不明白宇宙膨胀等，也不懂一些不确定性原理等。其中我最感兴趣的就是黑洞了，黑洞并不是指洞，而是指一个密度极高的星体，将周边粒子都吸了进去，包括光粒子都逃脱不了，正式因此，所以称为黑洞了。而关于时间，我不是很明白，不懂得在数学及物理学上是怎么去量化时间的。也不明白每个人的固有时间，在物理学中是如何去推算的。但觉双生子违谬十分有趣，才明白所谓违谬，是指假的谬论，也就是这个推理是真的。其实这本书，读懂了多少？又有多少能去理解。这是一篇不像读后感的读后感，毕竟我也没读懂多少。]]></content>
      <categories>
        <category>read</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[白说：并不白说]]></title>
    <url>%2F2018%2F07%2F15%2F%E7%99%BD%E8%AF%B4%EF%BC%9A%E5%B9%B6%E4%B8%8D%E7%99%BD%E8%AF%B4%2F</url>
    <content type="text"><![CDATA[读《白说》完这本书，我是不怎么敢写读后感的。如果真的要详细写来，其中每一篇文章都可以写一个很深刻的认识，每一篇都给我一些相见恨晚的感觉。我在意的读后感，只是读后的一些感悟，形散意散，但的来源于感。我就谈谈其中一小部分的感受，这是值得再读多遍的书。《白说》，这是一本演讲集，集中了一些白岩松先生的演讲。或者也可以说成“鸡汤式”的演讲，但又不同于那些华而不实的“鸡汤”。那些鸡汤似的文大多没有多大的真实价值，唯一，也是最大的价值便是希望。也正如所有的鸡汤文一样，这本书也给希望。希望是鸡汤文里最重要的东西了，或者在很多环境都是最重要的东西。我将《白说》解释为“鸡汤”，只是代表着，它如“鸡汤文”一样，描述着正面的东西，或者正在变好，或者期望着并有实际行动变好的东西。在这点上，它们是相似的。但是在许多方面，这是一本极其厉害的书籍，包含着许多哲理性的认识，也有许多有高度的认识，用相见恨晚或者醍醐灌顶都不为过。为什么我会用相见很晚来形容呢？这本书里，涉及的东西，很多，很广。主要有幸福、成功、信仰、沟通、音乐、希望、中国梦等一系列都提到的东西。我之前的一些认识或观点，都跟这本书有一些相似，或许在印证我并不是奇怪的。我们向前走得太远了，把自己走蒙了：我到底要去哪儿啊？我确实在很多时候都很迷惘，不知道自己究竟该去哪儿？在一个物质虽然丰富的，却经济基础不能满足的环境里，我很迷惘我何去何从。或许有很多90后和我一样，被现实的房价给打击的毫无意志。“别忘了当初为什么出发”，对了，我当初为了什么出发？我出生于某个农业县的一个小村庄，为了改变自己的人生吧，就这样走着，似乎改变是已经改变了。我原来谈过幸福，我理解幸福是现实于理想的差距。但这个终究只是一种宏观意义上的理解，具体上一般理解，经济基础以及精神依靠就是幸福了。幸福需要三个层面的因素，物质、情感和精神。物质是基础，情感是依靠，精神是支柱。这些都是外在给予幸福的定义，或者应该称为条件。除了这些条件外，应该还有意识。意识或许也是在某个程度上，决定着是否幸福。幸福，不管如何，都是人的主观感受。若使你已经或者了经济、情感、以及精神，就一定幸福吗？这点就在于认识了，如果你觉得满足或者说快乐了，那就是真的幸福了。最幸福的生活状态，应该是总有一个踮起脚能够着的目标，吸引你踏踏实实始终向前。幸福的相关性太过于繁复，我理解的我们应该做好自己的这一部分。或者调整好自己的心态。人生中得意和失意都只占5%，剩下的90%是平淡。而如何将这90%过得有趣便是幸福了。正如在这些许平淡中，找到真正的乐趣，将平淡过的不平淡。生活中，没一点滴都会有有趣的东西。今天在小区里闲逛，刚好发现小区的停车位的编号的刚好都没有4结尾的，或许这是一种迷信的讲究。也或许是业主为了避免某些讲究的停车用户。在现实中，学会平淡中的心态，以及好奇的心态。正如图中，如果你处在拥挤的车流中，还能够释然吗？这便是心态，以及上述提到的没有4结尾的编号，那便是好奇了。其实，人生只要拥有很多趣味，听音乐、喝茶、美食、收藏、阅读、喝酒、有好朋友聊天……前路平淡或坎坷，就都没太大关系。我似乎谈了太多的幸福了，应该谈论些其他。信仰也是我谈过多次的东西。正如本书里涉及的一样，幸福与信仰有关，信仰也关于音乐等，一切世界里的东西都联系了起来。在本书中，还有一个非常值得去思考的是人性。如何根据人性来思考、以及决策。现在许多公司都实行了股份、期权等制度，就是将人本身的利益与公司的利益高度集中话，促进了员工的努力。这种制度，在某个程度上，就是对于人性的思考，人本身是自私的，我从来不相信什么大公无私的，那都是违背人性的，不符合科学的。正如在公益的环境下，所谓做公益就没有私心吗？这是不正确的。对于做公益而言，都是有私心的，追求内心的那一种宁静，那种帮助别人后的到喜悦或者幸福感，应该是现在公益所应该追求的。所以对于所有的东西发展等，都不应该违背人性，应该从人性的角度去思考，应该如何。比如在做产品设计一样，不应该有违背人性的操作或过程的存在。在生活中，也不应该用违背人性的规定约束人们。不经意间，我谈了许多，却完全没有完尽，这本书中有太多的东西，我拿了一些出来，提了自己的感受。当然在这本书中，通过演讲的方式，传达信息，讲一些有趣的故事，进行论述观点，或许还有一些演讲的知识等。《白说》：并不白说，十分有趣。附我谈论的一些：谈幸福信仰再论信仰探究人性]]></content>
      <categories>
        <category>read</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot解决返回体content-type非json]]></title>
    <url>%2F2018%2F07%2F07%2FSpringBoot%E8%A7%A3%E5%86%B3%E8%BF%94%E5%9B%9E%E4%BD%93content-type%E9%9D%9Ejson%2F</url>
    <content type="text"><![CDATA[最佳解决方案为自定义消息转换器。首先，为什么要自定义消息转换器？所见即所得，原本的消息转换器并不能满足我们目前的需求。在最近的项目中，使用了SpringBoot与FastJson构建项目，在我们返回时，使用 @ResponseBody的方法里，采用了fastjson里的JSON.toJSONString()方法返回我们需要的Json数据，而这种返回中，会有一个问题，在返回中@ResponseBody注解中的消息转换器会默认理解为String解析，在返回体中如下图，content-type为text/html。因此我们解决想让我们的返回体中content-type为application/json。针对于这个问题，有一种最暴力的解决方案，直接在@RequestMapping中添加produces属性，设置produces=&quot;application/json&quot;直接使得返回体设置为json格式。当然对于这种每个接口暴力解决的方案来说，对于每写一个接口都需要设置，因此增加我们写代码的重复性工作，因此需要一个一劳永逸的方式。在@ResponseBody里默认有消息转换器，一般json转换使用的是JackJson进行转换的，而我们在项目中配置使用fastjson，因此需要修改消息转化器。首先消息转化器中不只有json转换器，还有字符转换器等。在我们的项目中可以自定义一个配置类，标注有@Configuration或者在@SpringBootApplication的启动配置类中添加下面代码，就增加了fastjson的消息转换器注入。12345678910111213141516171819/** * fastjson消息转换器 * @return */@Beanpublic HttpMessageConverters httpMessageConverters() &#123; FastJsonHttpMessageConverter fastJsonHttpMessageConverter = new FastJsonHttpMessageConverter(); //添加fastJson的配置信息 FastJsonConfig fastJsonConfig = new FastJsonConfig(); fastJsonConfig.setSerializerFeatures(SerializerFeature.PrettyFormat); //处理中文乱码问题 List&lt;MediaType&gt; fastMediaTypes = new ArrayList&lt;&gt;(); fastMediaTypes.add(MediaType.APPLICATION_JSON_UTF8); //在convert中添加配置信息. fastJsonHttpMessageConverter.setSupportedMediaTypes(fastMediaTypes); fastJsonHttpMessageConverter.setFastJsonConfig(fastJsonConfig); HttpMessageConverter&lt;?&gt; converter = fastJsonHttpMessageConverter; return new HttpMessageConverters(converter);&#125;当然需要注意，这种配置的方式必须在fastjson 1.2.44版本及之后才支持。在我们使用Maven构建项目是，需要添加fastjson的依赖。12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.44&lt;/version&gt;&lt;/dependency&gt;使用这种配置后，可以在返回中去掉我们的json转化，并直接返回我们需要转化的实体，在消息转换器中会自动调用fastjson进行转json。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[那些年的室友，祝安好]]></title>
    <url>%2F2018%2F06%2F30%2F%E9%82%A3%E4%BA%9B%E5%B9%B4%E7%9A%84%E5%AE%A4%E5%8F%8B%EF%BC%8C%E7%A5%9D%E5%AE%89%E5%A5%BD%2F</url>
    <content type="text"><![CDATA[“青山不改，绿水长流，我们后会有期。”室友微微的发了句最后的告别，祝福你们前程似锦，就这样别了。一别之后，只说三四月，谁知五六年。何时相见，何时再道，你好。毕业了，每个人都诉说着那个睡上铺的兄弟姐妹，每个人都述说着那个陪自己熬夜游戏的好友，每个人都述说着那个一起泡图书馆的女友，每个人都述说着那个一个逃课的兄弟。早上起来，一句：你去吗？我不去。那我也不去了。就这样又躺下继续安详的睡着了。我记得有人问过我，对自己大学生活的评价呢？我的回答是”努力-颓废-努力“。自己记得当抛开自己大学里那些不必要的东西，剩下的是什么？是那些一起谈笑人生的室友，是那节启人思考的哲学课堂，是那些学校的点滴。从自己幼稚的进入学校，进入那个寝室时，就决定了这四年的时间里，室友陪伴的时间长于所有，长于家庭。记得我们一起用手机MC建造世界，记得我们后续再电脑上继续建造我们的MC时间，记得imba的红石电路，记得我自己的钓鱼发家致富，记得zijun的家园建造，记得zhuolin带领我们打怪升级。还记得我玩游戏的是晕3D的。还记得我们一起梦幻西游，在东方的寝室里，记得我依然喜欢玩奶妈。记得早上起来就带队日常。还记得饥荒里的纵火者与机器人，纵火者的打火机，下雨天的机器人。记得每次都打不过的boss，记得掉超强装备的触手。还记得zijun游戏激动时的那一声声惊呼，以后都没有了。还记得临近考试时的预习，大家都很努力。还记得我们寝室的无挂科记录吗？还记得一位姓曾的同学抄一位姓余的同学的吗？还记得和zijun对答案差点被老师发现的吗？还记得开卷考试我们各自写的一张纸吗，我上面至少有三种颜色的笔。我们文革画报风格的寝室，我们铺了自己的地板革，显得寝室也更加明亮了。我们有时有点乱的寝室，却依然相对于其他寝室还是最整洁的。还记得我们的寝室卫生某一学期的最低分99的记录吗？还记得我们红色主题的寝室风采建设的ppt吗？还记得那些皂片太帅无法展示的室友？还记得那张四少的假装拿错的图片吗？还记得那些每个人都选了一只狗代表的自己吗？还记得一起war3的RPG打疯狂电脑总是被虐的情况吗？还记得曾经的我还可以随便虐杀中等电脑的，可惜现在简单都打不过了。还记得NBA的那一场场总决赛，我们看了多少？才发现我的外国人脸盲都治好了。还记得我们永远都奶不死的勇士，还记得那些紧张激烈的球。还记得那些银桦餐厅的小炒，桃源餐厅的凉面，风华餐厅的冒菜……还有那些一起点过的冒菜，一起吃过的烤肉，一起去过的不在万州的万州烤鱼。沙河东门外的土豆似乎也没那么好吃，那些移动摊贩大叔阿姨买的橘子依然很不错。还记得有一次打印给我们少打印了一份ppt的东苑印务，因此再也没去光顾过了，银杏黄时，校园里的人山人海，还有那些银杏果依旧存在的恶臭。依然记得，学校的主门都是南门，学校的主楼都是朝南的。清水河的主楼依旧时沙河的放大版，品学楼依然找不到最短距离，八角书屋依然宏伟，依旧能够给人想看书的欲望，那些在校园里运营的小白依然在奔驰，立人楼依然还是那么像挖掘机。那个拥有上万粉丝的校长却没了，那个没有校长讲话的毕业典礼终究还是遗憾。还记得秋招准备得最迟却第一个拿到offer的室友，还记得晚上11点在另一个校区打车回来的我们，还记得门后的衣装镜，还记得那张“一代天骄”的海报。还记得主楼里“IMBA考试由此去”依然有趣。还记得那个不签到点名却满座的白老师的课堂；还记得那个微积分老师红阿姨至少7种不同颜色的发卡；还记得那个永远第一排的现代信息课。还记得有许多。此去或许陌路，一上海，一厦门，两北京，最后不知道还会相聚多少？祝福你们，一路皆好。]]></content>
      <categories>
        <category>other</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[边城：性格使然的悲剧]]></title>
    <url>%2F2018%2F06%2F27%2F%E8%BE%B9%E5%9F%8E%EF%BC%9A%E6%80%A7%E6%A0%BC%E4%BD%BF%E7%84%B6%E7%9A%84%E6%82%B2%E5%89%A7%2F</url>
    <content type="text"><![CDATA[再一次拿起边城，沈老先生的文笔，一直是朴素大方的，一篇中篇小说，从开始到结局，没有一点一丝的矛盾，顺其自然的发展，没有斧凿痕迹的自然。这本小说里，写的世界是美好的，每个人都有着最朴实无华的品质，没有那些勾心斗角，没有那些灯红酒绿，一切都是人最期望的平凡与宁静。而悲剧式的结尾并没有像其他悲剧一样——将美好的东西毁灭给人看，这是一种自然而然地美好式的悲剧。从开始翠翠害羞地避开问题时，就知道最终会有伤害。在文中，每个人都是有着最普通人的品质，都是抽象的人，都在不同环境下，有着人心里的一些矛盾，一些自我的思维与责任。翠翠从塑造起，就是一个最普通农家女孩，从小与爷爷相依为命，因而对爷爷依赖极深，正因为这种爱，才对于爷爷渐渐老去而感害怕，害怕自己孤单一人。在自己十五六岁时，正伴随着自己思维的成长，因而有着普通孩子的害羞，对于爷爷每次谈到恋爱婚姻等询问时，都避而不答。对于喜欢的人，因为害羞远远避开，不敢去相遇。爷爷也是极其普通老爷爷的形象，大方得总是将自己的小葫芦酒给别人喝上几口，对别人也总是嘘寒问暖。对于翠翠也是极其的爱护，希望将翠翠交给一个好人家照顾，在对于翠翠终身大事上，让翠翠自己去选择。但完全没想到，因为自己，却造成了船总大儿子天保的英年早逝，而无比地自责，也对于翠翠的未来感到无比的担忧。怀着这种愧疚，最终在大雨中去了。船总顺顺，一个朴实能干的实业家，有着幸福美满的生活。对于儿子的婚姻，也是由其发展，却也希望有一个好的未来。在小城里，是一个公正大方的人，与每个人都有着较好的关系，都受到基本人的尊重。从大儿子的死，也埋冤那老爷子，因此也不愿意再将这一个女孩迎回家门。天保，继承了父亲的老实朴素，是一个少有大为的孩子。在知道翠翠喜欢的人是瘫送时，没有选择与兄弟的反目，而是公平的竞争，以及最后的放手。一个朴实无华的老实人跃然纸上，没有对于人过多的描述，只是寥寥的点点事迹。瘫送，相比较其大哥来说，更加有聪明以及才智等。在爱恨情仇上，喜欢着翠翠，但是却又在其中得不到回复，因为失去了哥哥。却因为喜欢翠翠，始终没有怪翠翠。而却又因为自己在婚姻上的选择，与父母争吵后出去了。在沈老先生而言，文中描述一种旧时的闲适，或者一种民风，从现实中这种的消逝来说，结局正代表着这种民风的消逝，所以自然而然的悲剧的产生。我有时候怀疑，瘫送的出走，正代表着一种新青年的一种崛起，也许也代表着老先生本人。从人之间的关系，这种悲剧的产生，是性格使然的结果，如果再重复一次，依然会再一次重复这种悲剧。老爷爷因为十分爱护翠翠，每次当谈到恋爱等时，看到翠翠害羞时，都害怕继续谈下去翠翠生气，而避而不谈。却正因为没有告诉翠翠所有的事情，最终也是悲剧。这是一种因为爱护而自然而然的悲剧。而顺顺，作为父亲，因为失去的儿子而怪罪渡船老头，因为不愿意次子再娶了翠翠。这一些都是人本身性格的结果。在我认识里，虽然淳朴，但翠翠还没有真正认识到爱情，还在成长的懵懂期。正是这种害羞，不敢去面对自己喜欢的人，而没有从爷爷那里获知那一切发生的事。从每一个人的角度看来，所有人都在向着一个自己所能接受的美好的角度发展，然而从整体上而言，最终的悲剧是不可避免的。从人生角度去理解，只能感受到一种由衷的悲伤，但是这种却也是一种发展，当失去某些东西时，必定将伴随着一些的到来。像翠翠，虽然是悲剧的，但应该明白了之后的，会有长大以及思想的成熟。有时候在想，边城是代表着家乡的意思，代表着家乡的变化里，渐渐丧失了原来的一些东西，或许是自己离乡很久了，家乡就变得不像自己记忆里的那一种家乡了，最后便有了每个人心里都有一个属于自己的边城。]]></content>
      <categories>
        <category>read</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[巴霍巴利：历史是重复的]]></title>
    <url>%2F2018%2F06%2F05%2F%E5%B7%B4%E9%9C%8D%E5%B7%B4%E5%88%A9%EF%BC%9A%E5%8E%86%E5%8F%B2%E6%98%AF%E9%87%8D%E5%A4%8D%E7%9A%84%2F</url>
    <content type="text"><![CDATA[我似乎向来有着一种十分悲剧的思维，总是向着悲伤的方向进行着思考。有时候我甚至认为我变了，我没有以前那么喜欢历史了，因为历史讲述的，没有一个平凡人的一生，没有将我们所理解的生活真正多彩起来。在历史上，分久必合，合久必分，我理解里就是体现着一种历史重复的悲剧。巴霍巴利，一个英雄主义的世界，有着每个人所注意的看点。他有着一种近乎重复的剧情。讲述着一个被受爱戴的王子从角落走向王座，又被人陷害后孩子流落人间。后来孩子又重复着这种复仇的历史。一千个人有一千个哈姆雷特。有人觉得这是一个美好的结局，有人觉得太过于悲惨。虽然最终结局当然是孩子终于坐上了王座。但是难免会让我想起重复进行这种剧情，可以说剧情的前后照映，某种程度上有一种生死轮回的感觉。我是一个不敢看悲剧以及青春剧的人，悲剧太过于悲惨，青春剧或者有时没有我的生活狗血。但这种轮回的方式确实也应该是一种悲，悲剧是讲人所喜好的东西毁灭给人看。或许在这儿，我只是不愿意去承受轮回的概念，不愿意接受我或许也是在做一些重复的事，想来这些是很恐怖的。虽然我坚信，或许在当事人来说，其中有大多数的欢乐与少部分的痛苦，或许在他们主角自己的认识里，并没有觉得自己是悲惨的。我以前常说，悲剧与喜剧之间，过程是相同的，只是结局是相反的。其实也不完全对，或许正因为我过于强调了结果，而少了过程的美，少了过程的喜悦。毕竟没有一个人，能够承受住，当自己尽心竭力后，却不得不去接受那一个悲惨的结局。每个人或许都不能够承受住，当自己完全从心而行时，却完全走上了前人的路，获得了前人相同的结果，这或许不是仅仅能够用信仰能够让人坚持下去的理由。或许也应该是好奇，好奇前人在这一路上，究竟看到了哪些风景，或许好奇前人为什么后选择这一条路，正如好奇自己为什么选择着这样一样。在历史上，每个朝代的诞生都必然伴随着一个朝代的灭亡，或许在一些昏庸的末世君王下，真的有推翻后会更好。但是真的从那些安安稳稳过着小日子的人来说，战争更好吗？不管怎样，战争都无法与生活相比，哪怕是生活一次又一次的欺骗了你。在这一个过程里，又有多少的悲哀。在历史里，胜者留下宏伟，败者留下脚印，而那些想生活的人，啥都没有。然而就这样的历史，却在周而复始的向前走着，或者按照着剧本执行。或者在影片里，留下了许多动作的美好，歌曲的美好，有着象征性的美好结局。但从来不可否认的，每一个次战争就是一次重复的悲剧。只是这些重复，并没有像主角一样提上纸面，没有从主要描述上引人关注。在巴霍巴利里，国王被人从背后捅了一刀，而王子又被从背后捅一刀，让我不得不怀疑，在这个里面确实重复了许多。或许正因为相信，才会将最脆弱的地方展示给别人，或者将自己的伤展示给别人。在现实里，确实也是这样的重复，有多少人，将眼睁睁看着别人在自己恢复过的伤口上刺下一刀，却装作毫不在意的样子，笑着说没事。到后来一个人也就被刺不进了，或许这也是一种成长。在现实里，有多少人过着重复的生活，早起忙碌睡觉，但是这种生活里却又是多么有色彩，沿岸的风景只有自己才懂得，重复的日子，没有重复的心情。历史是重复的。当知道自己正在向着一个重复的结果走着，但依然踏步上前，这或许是一种勇气。知道结果的努力，是最大的悲剧，或许也是最大的喜剧。]]></content>
      <categories>
        <category>movie</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[类图中的关系]]></title>
    <url>%2F2018%2F06%2F03%2F%E7%B1%BB%E5%9B%BE%E4%B8%AD%E7%9A%84%E5%85%B3%E7%B3%BB%2F</url>
    <content type="text"><![CDATA[在我们使用UML图进行设计时，会涉及类图之间的关系，一般关系为以下的五种关系，理解其中的概要能够对于后续我们的设计有一定的帮助。1、一般化关系，或者称为继承关系2、关联关系关联关系中一个类知道另一个类的属性和方法。通常通过类里引用另一个类的实例变量实现。3、聚合关系聚合关系与下面的合成关系都是属于关联关系的一种。在聚合关系中，主要表现的是整体与个体的关系。由于本属于关联关系，因此也是通过实例变量的方式实现。聚合关系与关联关系的区别是，关联关系主要是两个类都是在同一个层次的。4、合成关系合成关系是指普通聚合关系的同时，代表整体的对象负责代表部分的对象的生命周期。合成关系是不能够共享的。代表部分的对象每个时刻只能与一个对象发生合成关系。5、依赖关系依赖关系主要指类的局部变量、方法参数以及对静态方法的调用，是另一个类的实例对象等。]]></content>
      <categories>
        <category>tech</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[读《机器崛起》]]></title>
    <url>%2F2018%2F05%2F30%2F%E8%AF%BB%E3%80%8A%E6%9C%BA%E5%99%A8%E5%B4%9B%E8%B5%B7%E3%80%8B%2F</url>
    <content type="text"><![CDATA[从开始看到这一本厚重的书，有着三百多扉页，竟然有这三十多页参考文献，让我感到有点震惊。一本本着将控制论过往的历史，引入了现代这个社会中方方面面的每一个点滴。现在我们手中的手机，包里的电脑，或者各种代步的工具，都由着这控制论的衍生。从机器里，提出控制论，或者因为控制，所以有的机器。我从书中，也得到一些有趣的论点。战争是技术最好的催化剂从人性角度，战争是残酷的；而从技术角度，战争是伟大的。每一次战争都很大促进了技术的发展。或者就在现在，军事上的技术依然超越我们目前可涉及技术一代。在第二次世界大战里，技术上提出了智能炸药以及防空系列如何预判飞行器的轨迹等武器等，都从战争中第一次的想让机器有着自动化的操作，像有着思维一般。并在后续军事技术的发展中，设计了智能头盔显示系统，以及后续的计算机网络防护。这些先进技术的发展，都是伴随着战争中的需求，或者战争后军事上的需求等，一个先进的技术上，都是从军事到民用的发展。战争在技术的发展中，明显担任了催化剂的作用。反馈从开始解除接触控制开始，就十分强调反馈的作用。在第一次接触反馈时，是在生物上的学习，有反馈调节系统，而在机器上，依然需要反馈，或者在生活的各个方面都需要反馈。在我们生活中，做每一件事，最后要能够快速给反馈。比如在针对别人的请求或者告知等事件时，需要我们首先反馈出我们的态度。或许在你每次知道事后，并没有反馈，或者对于发起人而言，告知你或许并没有那么必要，因为告知这个执行，并不知道成功与否。在机器上，同样。早期对于预算飞行器飞轨迹后，需要我们炮塔等防空无语快速作出反应。然而在炮塔的旋转后，并没有反馈是否旋转到位等，因此在后期中，引入反馈的概念。每一个系统，都是由各种反馈构成的，包括国家、机构、团队等。如果反馈机制在某一个重要的环节中断裂，就证明着现在系统是存在问题的。反馈的概念并不是仅仅针对于机器上而已，包括在生活的各个细节。在我接下来的所有行为中，我所接收到的重要消息等，我都会给予反馈，从康德的道德论来讲，我所希望的人与人之间的反馈是一种道德。信息信息即为力量。从Cybernetics所引发出赛博空间、赛博战争等。都是技术上的一种延伸。而在这些技术中，信息的重要性也尤为重要，这个在我们现在社会中也有很好的表现。信息，体现在了许多方面，比如常见的数据，也是信息的一种表现形式。因此在公司的发展中，能够保存的数据，应该存储好，后续可以做数据分析等，每一份数据都具有良好的价值。迷幻剂在计算机发展中，一直伴随着迷幻剂共同的发展，或者在某一个程度上计算机代替着迷幻剂的效果。每个人都会遇到自己的迷幻剂，但是能够说迷幻剂就是错误吗？并不能。技术在一定程度上，正是由于那些对技术如痴如醉的人，才有了技术的进一步发展。同然，在现在社会中，游戏或许在很大程度上代替着迷幻剂的作用。而对于有的经常喝醉的人而言，酒也是一种迷幻剂。而且我们无法确定自己是否已经身处迷幻剂，毕竟每个人都有所喜好的事或物。计算机是新时代的迷幻剂，下一个时代的迷幻剂会是什么？自由从赛博空间开始，都是人向往着自由，到现在的比特币技术，缘由都是想着不受控制。正因为这种对于自由的向往，才有着非对称加密技术的发展，也是第一次体现了单向函数的伟大，或者大素数的伟大作用。然而在加密技术的发展中，一直都在争议中发展。似乎体现着一种技术的成长都是带有一定的争议性，不知道目前的SDN以及区块链等是不是也是这样，最后都会发展为伟大的技术发明。附在书中还有许多有趣的故事。但是整体而言是诉说控制论以及机器的发展历程。比如在Bose提出新的播放器理论后，却没有公司接受，最终选择自己去执行，最终形成现在的Bose。都告诉我们，如果有想法，就去实现，不要犹豫。]]></content>
      <categories>
        <category>read</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[读罢此书]]></title>
    <url>%2F2018%2F03%2F19%2F%E8%AF%BB%E7%BD%A2%E6%AD%A4%E4%B9%A6%2F</url>
    <content type="text"><![CDATA[读罢此书，《自在 独行》。带着寻找心灵解药的本心，开始追寻着文学上、心理上的解脱，想要去追寻出我所期望的高度是什么，想去让自己幸福，想渡自己。读罢此书，一篇篇散文，有的朴素，有的却有深意。我明白这是一个自在的贾先生写的自在。但是我终究没有理解独行，或许是我所理解的独行不对。这书里万事万物，都以一种自由的美好角度所展示，我能看出作者所热爱的生活。当然，我明白，文字能够表现出的，是作者所想的意，或者人的细节。我明白贾先生有大男子主义，是我所不喜好的。从生活的美好里，追求生活的意义。不敢停止思考，我一直都在害怕，害怕着当有某一天，我看透了这个人生，选择离去。我害怕我会思考出自己生命的意义是没有意义。从来，对于每个人的选择都是敬畏的。当海子选择卧轨时，是抱着多大的勇气，我想，他们定是明白了这个人生了。“写给每一个孤独的行路人”，或许我明白了这书来的意义。写给孤寂的人，看到这个世间的美好，便更加有了走下去的意义。或许人生的意义，从来都是不需要去追寻的，或许它最终只是对于个人，来过这个世间的积累。看尽世间百态，或许是人生。也或许人活着，就是为了寻求人生的意义。道家里讲究死后乘鹤西去，佛家里追寻生命轮回，而唯物里，死后就什么也没有了，“化作春泥更护花”或许是唯物的追寻。我有时在想，人生的意义，是否就是追求人在死亡来临那刻的高度，精神的卓越。我始终不解，但我知道，《自在 独行》里描写的世界就是这个世界，所写出的美好，便是一个普通人理解的美好。我一直在寻找，生命的意义是什么。或许该问，寻找生命的意义的意义又是什么？有人说，生命的意义在于寻找意义的过程。或许该是如此。这书，从没有讲过生命，只是讲着这个世间的美好，而我从来喜欢“随想”，不局限思维。或许我在向一个怪人的路上渐行渐近。也是有趣。]]></content>
      <categories>
        <category>read</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[解决word章节标题段前间距不显示问题]]></title>
    <url>%2F2018%2F03%2F07%2F%E8%A7%A3%E5%86%B3word%E7%AB%A0%E8%8A%82%E6%A0%87%E9%A2%98%E6%AE%B5%E5%89%8D%E9%97%B4%E8%B7%9D%E4%B8%8D%E6%98%BE%E7%A4%BA%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[如图片所示，在word中通过样式的调整，出现这种情况，显示得不正常情况。或许你会说改段落就可以，其实非然。在目前看来，这儿有明显的段前30磅的距离，而这儿没有显示出来。首先分析，word中，所有的东西都是有格式的，只有在相同样式之间段前段后格式不会显示。而这儿是段前格式没有显示出来，那么也就是，对于这种样式，前面的也是这种样式。然而一看，前面是正文格式。或许你会发现，上一页的最后是同样的章节标题格式，但是没有表现。这点便是问题所在。因为我们使用了分节符，而由于我们可能是在写完文本后序去调整的格式，因此可能分节符的格式就是我们的章节格式。当然，解决方法就是将分节符改为与分节符前格式相同，就可解决这个问题。总结问题章节标题段前距离没有显示。解决方案将该章节标题前的分节符样式改为分节符之前的样式。]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>Word</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IDEA无限Indexing]]></title>
    <url>%2F2018%2F03%2F01%2FIDEA%E6%97%A0%E9%99%90Indexing%2F</url>
    <content type="text"><![CDATA[虽然无限Indexing并非错误，但消耗性能，并扰乱我们的开发进度。我此处遇到的异常情况是，IDEA一加载某个Js就会一直出现无限Indexing，然后关掉，或者鼠标控制其他文件就不会出现这种情况。后来发现只是我电脑会有这种情况。因此猜测是因为我IDEA主题的问题。我通过网上下载了一个名为Python的主题，并通过导入设置修改了IDEA主题。然而通过查询资料没有找到卸载主题的办法，最终选择了暴力的解决方案，卸载重装IDEA。最终解决了该问题。总结问题由于IDEA主题导致某个文件加载出现无限Indexing情况。解决方案卸载IDEA重装。附推荐如何使用IDEA开发工具中右键中的Git图形化工具。]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>Idea</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[校招一些经验]]></title>
    <url>%2F2018%2F02%2F18%2F%E6%A0%A1%E6%8B%9B%E4%B8%80%E4%BA%9B%E7%BB%8F%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[秋招对我已经过去了几个月了，现在才想起来对于我的秋招经验做一个整体的总结。秋招准备首先是怎么去准备秋招，我恰逢受学长指导，才开始于五月起准备秋招。对于秋招来说，早的公司有的会在8月的时候就开始。因此需要针对自己，做好提前准备。从五月起，我看了《算法》一书，并针对自己对于其做了自己的总结，我总结了《对于基础排序算法的简要总结》、《基础查找算法分析》以及《SCC算法初解》，后续对于SCC部分基本没有涉及。从根本来说，对于我们计算机类的学生，数据结构与算法是非常重要的，对于五个模块是需要认真学习掌握的：查找、排序、树、图、动态规划，附加数据库等一些。在我之前的学习中，完全没有涉及动态规划方向的问题，因此只能重新学习了。对于计算机网络、操作系统等，需要对于基础知识做一遍的总结归纳。然后多次记忆。避免自己忘记。通过牛客网刷题，巩固自己的记忆，以及对于一些没有复习到的知识点作完善。争取对于所有的刷题，也至少达到70%的正确率。对于算法上的复习是，最消耗时间的。我虽然之前看了算法，但又通过《剑指Offer》对于基本的题思路全部熟练。然后又通过LeetCode一些算法题目的提升，后来就基本觉得那些笔试面试的基础算法等，都没那么困难了，像曾有一个面试官，问我觉得那笔试题怎么样，我随口就回了一句挺简单的，想来是没有回答好，但这个是我的坦诚吧。LeetCode上面的题目，总体而言，难度更高一些。花费的时间也较多一些，但是想通的题目多了后，可以提高自己的思维能力，解决问题的能力。总体而言，我对于秋招的准备就是对于基础的复习，对于知识点的查缺补漏。最后需要准备的一点是，对于面试时候，面试官最后一般会问你，“还有什么问题没有”。所以需要提前准备一些问题。我一般喜欢了解一下公司，岗位职责等，培养方式等。有的经历过宣讲会，就基本没啥问题了。招聘中在校招中，会经历一段一两个月的高密度的校招，秋招时间相对于春招来说比较长一些。招聘信息的来源，有学校官网、学院官网、其他学校的官网、牛客网等众多，需要自己整理，自己分辨信息的真实性。简历，这个需要准备好。尤其对于本科生来说，没有像研究生那样有许多的项目经历等可以写，因此需要精心设计简历。本科生一般简历都是一页，因为一页能够写下。所以需要将重要的信息放在一页纸的中心位置，那个位置是视觉的聚焦点。我在简历的时候，觉得我能够拿出手的就实习与项目经历，并且我认为那部分对于公司来说应该更加看重一些。因此将这两部分放在了重心位置。秋招里。简历投递，我也基本是海投。但是本身我也是有自己的筛选，并不是所有的公司我都投递了。根据自己的兴趣爱好，以及自己对于公司的看法投简历。当然，没拿到一个offer的时候，胡乱投递也是很正常的。在笔试的时候一般会对于自己的投递有一个筛选，笔试冲突的时候，就看自己觉得是选择自己更加爱好的或者更加有把握的，按照自己的标准去放弃。在投递开始时，最好建一个表格来记录目前投递的公司，以及笔试面试的进度，或者笔试面试时间等。不要过分相信自己的记忆能力，当简历投递得过多的时候，很容易是，弄乱的。日历是一个很好的记事器。通过手机日历设置提醒每天要做那些事，完成哪些笔试，去面试哪些公司，地址在哪儿等。通过日历的提醒，可以办到自己忘记不了。面试需要带好简历、笔、成绩单、身份证、学生证等。面试中，礼貌、礼貌、礼貌很重要，重要的事说三遍。还有一点，不知道的东西，要果断，说不知道，当然可以说自己的思路，想法，展示自己的思维能力。但是千万不要遮遮掩掩。我曾旁听了一个面试，那个同学面试时，对自己不知道的东西总是遮遮掩掩。最后，他请教面试官指点一下他面试中的问题。面试官很直接就说，“我建议你以后面试中，不知道的东西，最好直接说不知道，不要遮遮掩掩，这样才能够表现出，你所表现的知道的东西更加有信服力”。关于手里的offer筛选，这个没有建议了。只是若是要拒掉一个offer最好是，客客气气的发一封邮件，礼貌有加。本人秋招的一些看法其实在秋招中，面试应该是相对的，虽然表现出来的是公司在面试你，其实你也在面试公司，通过公司招聘中的进度、效率，以及面试过程中的严谨程度等。我在面试完后，基本都把我自己认为面试过程中比较“水”的公司筛选掉了。因此这个是一个双向的筛选过程。第二点是，不要惧怕和研究生竞争，我一直想表现的就是本科生并不比研究生差。对自己要有信心。虽然他们多了三年的经历，在项目以及基础上可能要好得多，但是我们年轻，相信自己的学习能力并不比他们差。当然，找工作中，安全还是很重要的，你若没有投递过的公司发信息让你去面试等，这种都是骗局。还有注意公司信息的真实性等，对自己的未来负责。面试地址，注意偏僻地区千万别去，不要认为传销离自己很远，有可能是一里之隔。找工作当然苦了，当然有失落等。学会调节自己的心理，我想公司不会想要一个没有自控能力的人吧。当自己面试多了，自然也就习惯了。我第一次面试的时候，也是非常紧张的，而且基础知识等都没有复习完全。紧张一次后，自然后来都不紧张了。还有一点是，并不是自己面试的东西就应该是自己所擅长的。重点是表现自己的思维以及基础。我偏向于Java语言，基本没有C++项目经验，我曾去面过了一个C++的岗位，语言并不重要，当然至少得懂这门语言的核心思维。面试官一般会从你的简历上写的来了解，什么写精通等，应届生就别想通过了。笔试面试完，应该从自己的缺陷中去查缺补漏。有时候，可能关于多进程多线程等，锁等有些知识点不清楚，下来就应该快速学习或者复习。附总之，工作，说好找，也是很好找的，说难找，也难找的。只要你准备好了，就应该能够找到一份不后悔的工作。]]></content>
      <categories>
        <category>other</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Mac下Java开发环境配置]]></title>
    <url>%2F2018%2F01%2F17%2FMac%E4%B8%8BJava%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[前言作为一名程序员，每次换了电脑，都需要重新配置一次所有的环境，有时候会突然忘了一些设置以及一些软件的破解等。Java第一点是配置Java环境，下载地址http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html，目前是Jdk8，下载安装即可。同时，需要设置JAVA_HOME，可以在 ～目录下建立一个.bash_profile的文件，使用vim .bash_profile新建并打开文件，在文件中写入12export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_144.jdk/Contents/Home export PATH=$PATH:$JAVA_HOME/bin然后esc后输入:wq保存并退出，之后执行source .bash_profile即可。在命令行输入 java -version测试是否成功。IDEA第二点就是IDE了，我开始使用idea后就完全抛弃了Eclipse，当然用不起正版，这是一个不能买断的软件，当然社区版是免费的。下载地址https://www.jetbrains.com/idea/。一般下载Ultimate版本，进行破解：1、使用http://idea.iteblog.com/key.php注册，但是在最新的版本里似乎开始行不通了。2、使用该方法注册http://idea.lanyus.com/，windows与mac都可行。对于每个项目配置时，可以尝试使用lombok，使用@Slf4j使用日志，减少我们所写的重复代码。附上IDEA里面添加lombok插件,编写简略风格Java代码http://blog.csdn.net/hinstenyhisoka/article/details/50468271。12345&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.18&lt;/version&gt;&lt;/dependency&gt;每次开始项目开发时，最好将配置java导入包优化以及去掉无用包开启，可以让IDEA优化我们导入的包。gitgit很重要，能够支持多程序员合作的版本控制，以及远程办公等多功能。git教程里推荐廖雪峰的git教程。安装指南有许多种安装方法供选择。Chrome 以及postman作为一名程序员，怎么可以不用Chrome呢？下载安装都极其简单。postman用于发送各种请求测试接口。有Chrome插件版本和桌面版本。在扩展程序里可以搜索postman，当然国内在这之前需要翻墙，突破The Great Wall，下载启用就行，他会自动创建快捷的启动软件入口。推荐下载桌面版本。mysql并不一定是Mysql、还有其他数据库等，看目前的需求。在mysql下载安装后，容易出现密码忘记连接不上的情况，因此这儿需要处理。1、系统偏好设置 入口进入mysql关闭mysql2、进入终端输入：cd /usr/local/mysql/bin/登录管理员权限 sudo su输入以下命令来禁止mysql验证功能 ./mysqld_safe –skip-grant-tables &amp;运行后mysql会自动重启（偏好设置中mysql的状态会变成running）3、输入命令 ./mysql输入命令 FLUSH PRIVILEGES;输入命令 SET PASSWORD FOR ‘root‘@’localhost’ = PASSWORD(‘你的新密码’);这样后mysql会重新设置成你设置的密码。Mavenmaven并不是所有的都会用到，但是个人觉得用Maven会方便许多，但是在maven里会常常遇到包冲突问题，给人以想不到的惊喜。关于maven的基础知识，请参照《Maven基础总结》。对于Maven的安装配置参照https://www.jianshu.com/p/191685a33786对于某些公司有自己的Maven镜像库，因此会在.m2文件路径下建立一个setting.xml的文件配置自己公司的Maven镜像映射。当然有时候你需要自己手动将包加入自己的Maven仓库，使用mvn install:install-file -Dfile=../a.jar -DgroupId=a.groupId -DartifactId=a.artifactId -Dversion=a.version -Dpackaging=jar命令，其中a代表jar包名，当然groupId、artifactId和version等需要根据现场修改。tomcattomcat可以下载一个tomcat8，对于7，在某些环境情况下会出现错误、而换用8就ok。当然也可以将tomcat的命令设置成全局，我个人偏好不设置而已。附对于还有一些我个人喜欢的软件，如前端编译器Hbuilder、做手机端页面时需要的Charles等，当然对我来说，有道词典是必须的。本文仅总结一些个人Java基础开发的环境配置，带有个人偏好色彩。更新2020/3/14更新新注册码：idea系列激活2020年]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>macOS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决Java API @since 版本错误问题]]></title>
    <url>%2F2018%2F01%2F08%2F%E8%A7%A3%E5%86%B3Java-API-since-%E7%89%88%E6%9C%AC%E9%94%99%E8%AF%AF%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[在我们的项目开发过程中，常常出现Java版本过低，以导致语法中出现错误的情况，这种情况中我们通常都是比较明了的知道需要提到Java的版本。安装的Java版本过低这种情况下需要我们重新安装最新版本的Java即可。IDE中设置的Java版本过低比如在IDEA中，通过command + ; 快捷键进入项目结构中可以看到如下图项目结构中的一些信息。（注：快捷键需要是英文键）在红色框位置可以选择支持的Java版本。当然，在Modules里面也可以选择支持的Java语言版本。IDEA自动重置LanguageLevel和JavaCompiler版本如下图发生错误相同，每次都会引入项目，或者开启项目时，都会使得Java版本过低的情况。并且package后也是支持低版本的Java，会引发较大的语法问题。这个问题虽然可以每次在开发过程中手动调节版本，使得开发过程没有错误。但是不支持所有环境，即打包做出支持库等会出现语法问题，因此需要解决。解决方法是，在Maven中引入maven-compiler-plugin，并指定版本。示例如下12345678910&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.3&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt;&lt;/plugin&gt;]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[17曲终，18伊始]]></title>
    <url>%2F2017%2F12%2F30%2F17%E6%9B%B2%E7%BB%88%EF%BC%8C18%E4%BC%8A%E5%A7%8B%2F</url>
    <content type="text"><![CDATA[回顾整个17年，我个人成长了不少，我似乎开始从一个入世未深的懵懂少年成为了开始入世的大叔。我思维开始有了自己革命性的改变，我可以开始笑对我自己所面对的所有遭遇，好的，坏的，我都可笑着接受。17年，我开始表现整个自我，我开始在简书矫情，写下感动自我的文字。17年初，我正当大三下学期里的初章，我决定了我准备毕业后就工作，我去了喜马拉雅实习。那时候，我邂逅简书，我开始在简书上写下我的所遇所感，以及自我的技术总结。简书，终究还是我选择自我陶醉或者自我表达的地方。从相遇到现在，我在简书写了三万四千多文字，写了有四十篇随笔或技术。我没有那种文学上的表达能力，只是专注的写下自己的想法。没有感动别人，但终究还是感动了自我。17年里，我开始找工作，我最终找到一份比较满意的工作，选择去一个优秀的环境里变得优秀起来，最终自我选择了北漂，开启了北漂一族的生活。我未曾出过远门，而现在却独自北上，从校园到社会，对我来说，“我有什么不能够承受，或者不管什么，都得承受着。”，这是我17年后的最好的总结。我来了北京，我开始发现，是因为一个人，所以恋上一座城。而我对于每一座城都不再去追求。倘若我能够在北京好着，而没有我留恋的地方所去，则留下来。对我来说哪儿都是一座城，都是在生活里摸滚打爬。17年，也是我从16年的迷茫里里走出来的一年，这一年里，我决定了我毕业后工作的道路，我开始认真学习，我基本保持着至少一个月一本技术书籍的进度学习，认真总结学习。我开始准备构建自己的个人网站，开始学会自己安排进度。回顾这17年，我留下的一切，我开始看开感情，随风般任其跟随我心去做，“尽人事而听天命”，虽未尽人事，但也听天由命。我追求哲学里不同的认识，我开始注重经历，感受经历里的每一个风景。18年是我毕业的一年，这一年我或者是真正走上社会。这一年里，我有许多想做。每个月一本技术书籍，是我想一直坚持下去的学习。既然在技术的道路上来了，那至少让自己会些技术。17年末，我开始利用上班途中的时间学习英语。18年里，继续学习吧，方便的话也可以尝试着去考一下雅思托福。既不追求固定未来待着的地方，那么或许以后我也会选择出国深造。也相当于没有一个明确的打算，只是想看看这个世界。18年毕业之前，我会争取着让我的个人网站上线。毕业的时候，我也会穿上那个毕业的学士服，或许我也会将学士帽高高抛起。18年，我会走下一些北京有趣的地方，留下自己的足迹，带走埋藏的记忆。17年终将远去，我做过一些事。18年，我又会做哪些？]]></content>
      <categories>
        <category>other</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[关于HLS直播流HTML页面播放解决]]></title>
    <url>%2F2017%2F11%2F09%2F%E5%85%B3%E4%BA%8EHLS%E7%9B%B4%E6%92%AD%E6%B5%81HTML%E9%A1%B5%E9%9D%A2%E6%92%AD%E6%94%BE%E8%A7%A3%E5%86%B3%2F</url>
    <content type="text"><![CDATA[在最近的项目开发中，涉及了HLS直播音频流的播放，关于网上的资料较多，各种混杂，因此对此在问题解决尝试以及结果进行总结。最终解决方案使用百度播放器，通过API，自己写想要的播放器组件。什么是HLS首先，什么是HLS？HTTP Live Streaming（缩写是HLS）是一个由苹果公司提出的基于HTTP的流媒体网络传输协议。是苹果公司QuickTime X和iPhone软件系统的一部分。它的工作原理是把整个流分成一个个小的基于HTTP的文件来下载，每次只下载一些。当媒体流正在播放时，客户端可以选择从许多不同的备用源中以不同的速率下载同样的资源，允许流媒体会话适应不同的数据速率。在开始一个流媒体会话时，客户端会下载一个包含元数据的extended M3U (m3u8)playlist文件，用于寻找可用的媒体流。HLS只请求基本的HTTP报文，与实时传输协议（RTP）不同，HLS可以穿过任何允许HTTP数据通过的防火墙或者代理服务器。它也很容易使用内容分发网络来传输媒体流。—— 摘自维基百科由于是HLS技术是苹果公司提出的，虽然在该协议的推广上也是作出了许多贡献，但是也是有很多浏览器依然不支持或者不完全支持该协议。如何实现页面的直播流播放呢？对于直播流方案，我做了几种解决尝试方案一：使用video标签首先，video标签是HTML 5中的新标签，用于嵌入视频元素。而目前，video标签只支持MP4、WebM、Ogg等格式。或许，很疑惑，为什么要用视频元素标签来嵌入音频？对于我们这儿直播流的情况下，一般音频标签目前不能够解决。而使用视频元素标签来嵌入直播音频流。既然这儿video标签不支持m3u8的HLS直播流格式，那是不是我这儿说错了？肯定不是。接下来需要借助一些其他开源项目来解决。我们在这儿的解决都是基于video.js的一些衍生开源项目解决。首先是第一种直接使用video.js测试。123456789101112131415161718192021222324&lt;html&gt; &lt;head&gt; &lt;meta charset="utf-8" /&gt; &lt;title&gt;Player&lt;/title&gt; &lt;link href="https://unpkg.com/video.js/dist/video-js.css" rel="stylesheet"&gt; &lt;/head&gt; &lt;body&gt; &lt;video id="video" class="video-js vjs-default-skin" controls preload="none" data-setup='&#123;&#125;'&gt; &lt;source src="living.url" type="application/x-mpegURL"&gt; &lt;/video&gt; &lt;script src="js/video.js"&gt;&lt;/script&gt; &lt;script type="text/javascript"&gt; var player = videojs('video'); player.ready(function() &#123; var myPlayer = this; myPlayer.src(url); myPlayer.load(url); myPlayer.play(); &#125;); &lt;/script&gt; &lt;/body&gt;&lt;/html&gt;使用Safari浏览器测试如下然后，也可以使用videojs-contrib-hls项目解决，测试代码示例如下：1234567891011121314151617&lt;html&gt; &lt;head&gt; &lt;meta charset="utf-8" /&gt; &lt;title&gt;Player&lt;/title&gt; &lt;link href="https://unpkg.com/video.js/dist/video-js.css" rel="stylesheet"&gt; &lt;/head&gt; &lt;body&gt; &lt;video id="video" class="video-js vjs-default-skin" controls autoplay="autoplay" width="640" height="320" data-setup='&#123;&#125;'&gt; &lt;source src="living.url" type="application/x-mpegURL" /&gt; &lt;/video&gt; &lt;script src="https://unpkg.com/video.js/dist/video.js"&gt;&lt;/script&gt; &lt;script src="https://cdnjs.cloudflare.com/ajax/libs/videojs-contrib-hls/5.12.1/videojs-contrib-hls.min.js"&gt;&lt;/script&gt; &lt;/body&gt;&lt;/html&gt;️注意：在这儿使用的js等资源皆是在线的一些支持。若需要在项目中使用，最好下载到本地使用。这儿的测试结果，是对于mac上所有浏览器的一般m3u8视频流（即非直播）都支持，都能够播放。直播流仅持safari、edge、android，其他浏览器会出现错误。方案二：基于clappr由于第一种方案，只能够部分解决HLS流播放的问题，且未解决直播流播放的浏览器兼容问题。因此需要继续寻找新的解决方案。这个方案是基于github上clappr的开源项目解决。1234567891011121314151617181920&lt;html&gt; &lt;head&gt; &lt;title&gt;test&lt;/title&gt; &lt;script type="text/javascript" src="https://cdn.jsdelivr.net/npm/clappr@latest/dist/clappr.min.js"&gt;&lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;div id="player-wrapper"&gt;&lt;/div&gt; &lt;script&gt; var playerElement = document.getElementById("player-wrapper"); var player = new Clappr.Player(&#123; source: 'm3u8.url', mute: true, height: 360, width: 640 &#125;); player.attachTo(playerElement); &lt;/script&gt; &lt;/body&gt;&lt;/html&gt;通过测试，发现该方案对于m3u8的视频格式支持播放，但是对于直播流却不支持。方案三：基于ChPlayer在查询资料中发现，chplayer是网页视频播放器，支持mp4,flv,f4v以及m3u8格式，支持rtmp。支持点播和直播。因此决定使用这个尝试。首先将项目下载到本地，然后使用页面测试。12345678910111213141516171819&lt;html&gt; &lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;test&lt;/title&gt; &lt;script type="text/javascript" src="chplayer/chplayer.min.js"&gt;&lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;dev id='video'&gt;&lt;/dev&gt; &lt;script type="text/javascript"&gt; var videoObject = &#123; container: '#video', //“#”代表容器的ID，“.”或“”代表容器的class variable: 'player', //该属性必需设置，值等于下面的new chplayer()的对象 video: 'living.url' //视频地址 &#125;; var player = new chplayer(videoObject); &lt;/script&gt; &lt;/body&gt;&lt;/html&gt;通过这种方式测试，结果是能够解决直播流问题，并且主流浏览器都是兼容的。因此在我们的项目中决定使用这种方式解决问题。方案四：使用hls.js目前官方给出兼容情况如下：方案五：使用cyberPlayer该方式目前基本兼容常用浏览器，我测试的使用基本兼容。在该方式下，通过自己编写播放器按钮等组件可以基本解决该播放问题。但是在这个情况下，需要考虑当播放器出错时，如何屏蔽掉页面中展示的错误信息。附虽然使用chplayer已经能够解决这个问题，但是在后面的查询资料中发现FFmpeg，可以解决支持直播音频的播放以及所有解码等，虽然不仅限于该领域。后面可以借助其源码学习并解决音频领域的问题。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>HLS</tag>
        <tag>Js</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我所遇，皆为我一生]]></title>
    <url>%2F2017%2F09%2F01%2F%E6%88%91%E6%89%80%E9%81%87%EF%BC%8C%E7%9A%86%E4%B8%BA%E6%88%91%E4%B8%80%E7%94%9F%2F</url>
    <content type="text"><![CDATA[我所遇，皆为我一生。世间沉浮，人生百态，苦乐欢甜，所遇所感，所见所想，皆为我一生财富。我说过，我或许除了时间，一无所有；其实并不是，我还有我自己，我的一生。我想要一个完美的大学，想要一个完美的结束。第一次参加迎新志愿者，第一次想去看看，刚进校园的我会是什么情况。我遇到许多学弟学妹。有的健谈，说不定内心藏匿着一个内向的自己；有的沉默，说不定是一个开朗的人。有的很好相处，有的有点内向。而当初的我究竟是怎么样的呢？我看不透一生，因为我没有一生的积累。我看不透浮沉，因为我没有物质的基础。人生是怎样？未来的我是怎样？大学里，第一年里，我勤奋刻苦，我那时候十分努力，那时候，我努力是为了什么？其实我不懂。我可能只是持续着好友说的，“到一个新的环境里，我也想要名列前茅，不求第一，但求上榜”。大二里，我搬了校区，开始颓废的我开始迷惘，我究竟是要读研还是找工作呢？迷惘的我在迷惘的迷离的路灯下前行，是不是前行，我也不清楚。或许只是原地踏步吧，或许还有些后退吧，浪费了时光。大三下里，我开始实习，我也开始学习，这半年里，我知道我在努力，我知道我是幸福的，那种努力的幸福。穷尽一生，我的一生究竟有多长，我不知道，或许挺短，或许也很长。我会后悔吗？那是肯定会啊。我只想我以后不后悔曾今后悔过。当初我踏进校园，与走出高中，心情是不同的吧。这学校这么大，或许有些激动吧，也有些无赖，我最想来的并不是这儿。或许这种错过是上天给我的最好的选择，让我进入代码的世界，唱着“Hello world”，拥抱世界。也或许是上天给我的选择，是殊途同归，还是道不同。刚进校园的我，没有迷惘，没有一丝犹豫。我心中总是默默告诉自己，要好好学习。我没做到吧。大学里，我遇到不同的人，学弟学妹，学长学姐，各式各样，各有各的人生，我羡慕的是别人人生里那种自信；羡慕别人时间里可以有多一年或者两年的选择，羡慕别人比我年轻。总是叹息着，要是我现在才大三该多好啊。可惜，我大四了。大四的字眼里总是有着不同的含义一样，对于所有，大四总是特殊的。那种百感交集，会在大四的日子里一一体现出来。这三年里，我或许什么都基本经历过吧，为了考试，我可以在考前一周学完一学期的内容，而且学得更好，我可以熬夜到一点多，就为了看完复习资料，而第二天早起考试。我可以白天上班，晚上上课，直到回寝室的路上竟然叫不出同班同学的名字。我可以坐一个多小时破破烂烂的公交，为了和你相聚。我可以为了考过科三，见过凌晨三点一闪而过的流星。我可以为了看尽我的大学，在大四开始的最忙时间里参加迎新。别人总说，穷尽一生的运气遇到你。我不同意，遇到你是我一生的经历。别人总说，自己运气太差。我不同意，遇到的一切皆为我的一生。大学里，我有过拼搏，有过忙碌，有过社团，有过图书馆义工，有过迎新，有过一段伤情的恋爱，有过颓废，有过和室友一起游戏，有过逃课……大学里，我还差一场说走就走的旅行，还差一个挂科记录。世间所遇，都有不同的规律吗？缘在于上天吗？我不同意，规律是由自己决定的，缘是由自己创造的。我所遇，皆为我的选择，都是我选择的结果。每一滴泪，每一颗汗，每一次哈哈大笑，每一回沉默不语，都是我的一生。我的感情变化，我的思想变化，都是我的财富。大学里，我学会了短时间学会，我拓宽了视野，我开始为一生做安排。我开始喜欢哲学，我开始经常问自己，我想要做什么，我该做什么。我一生里后续怎样谱写？我所遇，皆为我幸，为我一生。]]></content>
      <categories>
        <category>other</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Mac上VPN 连接不上常用解决方案]]></title>
    <url>%2F2017%2F07%2F21%2FMac%E4%B8%8AVPN-%E8%BF%9E%E6%8E%A5%E4%B8%8D%E4%B8%8A%E5%B8%B8%E7%94%A8%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[在工作中常常使用VPN，但是也常常出现VPN连接不上的情况，对于这种情况我们常常是深恶痛绝，花掉半天的时间也没解决，因此在这儿给出我自己的常用解决方案，一般按照着方案1、2、3的顺序执行，通常情况下都是解决的了。方案1尝试着删除掉我们所配置的VPN，然后重新配置，尝试连接。方案2这是大家常见的方案，在 /etc/ppp下的options文件中写入以下代码12plugin L2TP.pppl2tpnoipsec然后重新连接。具体的操作步骤如下：在终端中输入 sudo vim /etc/ppp/options，可能需要密码；在文件中输入i进入insert方式，然后输入上诉代码，然后按esc，输入:wq，回车保存；尝试着重新连接或删除掉旧配置重新连接；方案3如果上述方案都不能够奏效，那么尝试第三种方案。此方案只能在方案2不奏效的情况下使用删除/etc/ppp/options文件，即在终端执行sudo rm -rf /etc/ppp/options；删除VPN的配置重新配置，连接。这儿一定要删除配置重新配置（至于为什么，我也不清楚，反正不重新配置一般是不能成功的）一般情况下，按照这三种方案的顺序执行后都是能够成功访问了。附若本文中未总结的相关解决方案，欢迎补充。]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>macOS</tag>
        <tag>VPN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MyBatis初解]]></title>
    <url>%2F2017%2F06%2F09%2FMyBatis%E5%88%9D%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[MyBatis是一种半自动映射的框架。是目前较为流行的Java ORM框架。（ORM模型是指数据库的表与Java的POJO的映射关系模型，解决之间的相互映射。）本文主要是我在学习了《深入浅出MyBatis技术原理与实战》后的自我总结。配置123456789101112131415161718192021222324252627282930&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE configuration PUBLIC "-//mybatis.org//DTD Config 3.0//EN" "http://mybatis.org/dtd/mybatis-3-config.dtd"&gt;&lt;configuration&gt; &lt;settings&gt; &lt;!-- 全局映射器启用缓存 --&gt; &lt;setting name="cacheEnabled" value="true"/&gt; &lt;!-- 全局延时加载 --&gt; &lt;setting name="lazyLoadingEnabled" value="true"/&gt; &lt;!-- 不对带有延时加载属性的对象完全加载 --&gt; &lt;setting name="aggressiveLazyLoading" value="false"/&gt; &lt;!-- 对单一SQL允许返回多结果集 --&gt; &lt;setting name="multipleResultSetsEnabled" value="true"/&gt; &lt;!-- 允许使用列标签代替列名 --&gt; &lt;setting name="useColumnLabel" value="true"/&gt; &lt;!-- 允许使用自定义的主键值(比如由程序生成的UUID 32位编码作为键值)，数据表的PK生成策略将被覆盖 --&gt; &lt;setting name="useGeneratedKeys" value="true"/&gt; &lt;!-- 自动映射任意复杂的结果集 --&gt; &lt;setting name="autoMappingBehavior" value="FULL"/&gt; &lt;!-- 简单执行器 --&gt; &lt;setting name="defaultExecutorType" value="SIMPLE"/&gt; &lt;!-- 数据库超过25000秒仍未响应则超时 --&gt; &lt;setting name="defaultStatementTimeout" value="25000"/&gt; &lt;!-- 配置使用log4j记录日志--&gt; &lt;setting name="logImpl" value="log4j"/&gt; &lt;!-- 自动转换驼峰命名 --&gt; &lt;setting name="mapUnderscoreToCamelCase" value="true"/&gt; &lt;/settings&gt;&lt;/configuration&gt;这是简单Mybatis的设置。依然还有许多属性我们没有提到。在我们的设置中，autoMappingBehavior是有三种设置：NONE（取消自动映射）、PARTIAL（只会映射没有定义嵌套结果集映射的结果集，在缺省配置的情况下默认）、FULL；而defaultExecutorType表示执行器executor类型，分为三种：SIMPLE（普通执行器，默认情况下是SIMPLE）、REUSE（执行器会重用预处理语句prepared statements）、BATCH（执行器会重用语句并执行批量更新）。在configuration中还会涉及其他属性，常用的有typeAliases（类型命名）、typeHandler（类型处理器）、plugins（插件）等。而对于typeHandler的配置里，又有javaType与jdbcType，typeHandler就是解决其转换的问题。MyBatis-Spring一般情况下，我们大多数情况下是在Spring中使用MyBatis，即需要配置MyBatis-Spring。分为五步进行配置：配置数据源配置SqlSessionFactory配置SqlSessionTemple（使用Mapper接口编程方式，这儿的配置就隐藏了）配置Mapper事务处理先配置数据源。123456789101112131415161718192021222324&lt;bean id="dataSource" class="com.alibaba.druid.pool.DruidDataSource" init-method="init" destroy-method="close"&gt; &lt;property name="url" value="#&#123;jdbc['jdbc.url']&#125;"/&gt; &lt;property name="username" value="#&#123;jdbc['jdbc.username']&#125;"/&gt; &lt;property name="password" value="#&#123;jdbc['jdbc.password']&#125;"/&gt; &lt;!-- 配置初始化大小、最小、最大 --&gt; &lt;property name="minIdle" value="#&#123;jdbc['ds.minIdle']&#125;"/&gt; &lt;property name="maxActive" value="#&#123;jdbc['ds.maxActive']&#125;"/&gt; &lt;property name="initialSize" value="#&#123;jdbc['ds.initialSize']&#125;"/&gt; &lt;!-- 配置获取连接等待超时的时间 --&gt; &lt;property name="maxWait" value="#&#123;jdbc['ds.maxWait']&#125;"/&gt; &lt;!-- 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒 --&gt; &lt;property name="timeBetweenEvictionRunsMillis" value="#&#123;jdbc['ds.timeBetweenEvictionRunsMillis']&#125;"/&gt; &lt;!-- 配置一个连接在池中最小生存的时间，单位是毫秒 --&gt; &lt;property name="minEvictableIdleTimeMillis" value="#&#123;jdbc['ds.minEvictableIdleTimeMillis']&#125;"/&gt; &lt;property name="validationQuery" value="SELECT 1"/&gt; &lt;property name="testWhileIdle" value="true"/&gt; &lt;property name="testOnBorrow" value="false"/&gt; &lt;property name="testOnReturn" value="false"/&gt; &lt;!-- 打开PSCache，并且指定每个连接上PSCache的大小 --&gt; &lt;property name="poolPreparedStatements" value="false"/&gt; &lt;property name="maxPoolPreparedStatementPerConnectionSize" value="20"/&gt; &lt;!-- 配置监控统计拦截的filters --&gt; &lt;property name="filters" value="stat"/&gt;&lt;/bean&gt;这儿我们使用的Druid数据源。接下来配置SqlSessionFactory。1234567891011121314151617&lt;bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean"&gt; &lt;property name="dataSource" ref="dataSource"/&gt; &lt;!-- 主配置文件 --&gt; &lt;property name="configLocation" value="classpath:/mybatis-config.xml"/&gt; &lt;!-- 自动扫描sqlmap目录下的所有SQL映射的xml文件 --&gt; &lt;property name="mapperLocations" value="classpath:mappers/*.xml"/&gt; &lt;!-- 自动注册javabean别名 默认会使用javabean的首字母小写的非限定类名来作为它的别名--&gt; &lt;property name="typeAliasesPackage" value="fei.self.model"/&gt; &lt;/bean&gt;&lt;!-- spring与mybatis整合配置，扫描所有dao --&gt; &lt;bean class="org.mybatis.spring.mapper.MapperScannerConfigurer"&gt; &lt;!-- 扫描基本包路径下的所有映射器接口类 采用分号或者逗号分隔 可设置多个包路径 --&gt; &lt;property name="basePackage" value="com.ximalaya.ops.fei.self.dao"/&gt; &lt;!--多个数据源 可设置具体的sqlSessionFactoryBean 单个数据源不必配置--&gt; &lt;property name="sqlSessionFactoryBeanName" value="sqlSessionFactory"/&gt; &lt;/bean&gt;这儿的mybatis-config.xml就是我们之前的configuration以及setting的那个文件。并且在这儿，我们配置了自动扫描信息，包括扫描所有的DAO以及Mapper文件。接下来只剩下事务处理的配置了。1234567891011121314151617181920212223&lt;!-- 对dataSource 数据源进行事务管理 --&gt;&lt;bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager" p:dataSource-ref="dataSource"/&gt;&lt;!-- 事务管理 通知 --&gt;&lt;tx:advice id="txAdvice" transaction-manager="transactionManager"&gt; &lt;tx:attributes&gt; &lt;!-- 对insert,update,delete 开头的方法进行事务管理,只要有异常就回滚 --&gt; &lt;tx:method name="insert*" propagation="REQUIRED" rollback-for="java.lang.Throwable"/&gt; &lt;tx:method name="update*" propagation="REQUIRED" rollback-for="java.lang.Throwable"/&gt; &lt;tx:method name="delete*" propagation="REQUIRED" rollback-for="java.lang.Throwable"/&gt; &lt;tx:method name="reset*" propagation="REQUIRED" rollback-for="java.lang.Throwable"/&gt; &lt;tx:method name="getExecution*" propagation="REQUIRED" rollback-for="java.lang.Throwable"/&gt; &lt;!-- select,count开头的方法,开启只读,提高数据库访问性能 --&gt; &lt;tx:method name="select*" read-only="true"/&gt; &lt;tx:method name="count*" read-only="true"/&gt; &lt;!-- 对其他方法 使用默认的事务管理 --&gt; &lt;tx:method name="*"/&gt; &lt;/tx:attributes&gt;&lt;/tx:advice&gt;&lt;!-- 启用对事务注解的支持 --&gt;&lt;tx:annotation-driven transaction-manager="transactionManager"/&gt;这是最基础的MyBatis-Spring的配置。这部分其实挺无趣的，个人觉得MyBatis最有趣的就是接下来的MyBatis的技术原理以及插件等。关于Mapper的一些在这儿不作罗列了。动态SQL所谓动态SQL，指的是一些特殊的MyBatis标签的使用，从而对于SQL的拼装具有动态性的效果。主要是if、choose、trim、foreach以及bind元素这些。这部分其实挺有趣的，可以增加我们对于MyBatis的掌握。这部分的知识在这儿不作罗列，看一些例子都能明白。MyBatis原理终于到了重点且有趣的地方，这部分知识可以帮助我们理解MyBatis，然后能写一些好用的插件。在学习之前需要掌握动态代理，分为JDK动态代理与CGLIB动态代理。首先，需要构建SqlSessionFactory。第一步，先通过XMLConfigBuilder解析配置文件，存入Configuration类中（这个类里基本保存了所有的配置）。第二步，使用Configuration去构建SqlSessionFactory。对于SqlSessionFactory，这是一个接口，在一般MyBatis中用DefaultSqlSessionFactory的实现类，对于接口的方法都做了实现。第二个需要掌握的是Mapper映射器。我们提到过，在Configuration中，有所有的配置，当然映射器也在里面。需要了解的是，Mapper映射是通过动态代理的方式实现的。一般映射器里面包含有三部分：MappedStatement：用户保存映射节点；SqlSource：这是MappedStatement的一个属性，一个接口，主要是根据参数和其他规则组装SQL，当然它提供BoundSql；BoundSql：建立SQL和参数的地方。我们一般修改SQL或者参数都是在BoundSql中修改的。对于BoundSql中如何实现多种参数的注入方式，我这儿就不讲解了。既然有了SqlSessionFactory，那么我们很容易就得到SqlSession了。从Mapper映射器中，我们通过代理对象会进入到MapperMethod的execute方法。然后就能进入SqlSession的方法里了。我们需要了解的是SqlSession里的增删改查方法是如何实现的。首先SqlSession下有四大对象。1、Executor执行器：用来调度StatementHandler、ParameterHandler、ResultHandler；2、StatementHandler：这个是在SqlSession里最重要的部分，它可以使数据库的Statement，即PreparedStatement执行操作（PreparedStatement接口是继承了Statement接口）；3、ParamentHandler：用于SQL的参数处理；4、ResultHandler：用于最后返回数据集的封装。我学到这儿很疑惑这个Satement究竟是什么？Statement 对象用于执行不带参数的简单 SQL 语句；PreparedStatement 对象用于执行带或不带 IN 参数的预编译 SQL 语句；CallableStatement 对象用于执行对数据库已存在的存储过程的调用。我们一般在插件中使用的是PrepareStatement，这三者对应了三种数据库会话器，SimpleStatementHandler、PrepareStatementHandler、CallableStatementHandler。对于着Executor也分为三种SIMPLE、REUSE、BATCH。关于参数处理器以及结果处理器就不提及了。插件插件部分，我无法总结清晰，所以给出我的分页插件中重点intercept函数实现的基本流程图。附本文主要是个人的一些总结，没有完全梳理MyBatis的流程等，也没有完全涉及MyBatis的所有知识。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>MyBatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SCC算法初解]]></title>
    <url>%2F2017%2F05%2F19%2FSCC%E7%AE%97%E6%B3%95%E5%88%9D%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[在算法学习之路上漂泊，遇见了图，而分无向与有向。在本文中主要讲解关于有向图中的求极大连通分量的算法，主要是Kasaraju算法、Tarjan算法以及Gabow算法。三种算法都是基于深度优先搜索算法（DFS）而实现的，实际上后两种算法是对于Kasaraju算法的改进，减少了一次深度优先搜索（DFS），因此在性能上相比较而言要好一些。初识强连通分量首先，连通分量是无向图G的一个极大连通子图称为G的一个连通分量（或连通分支）。连通图只有一个连通分量，即其自身；非连通的无向图有多个连通分量。强连通图指每一个顶点皆可以经由该图上的边抵达其他的每一个点的有向图。意即对于此图上每一个点对(Va,Vb)，皆存在路径Va→Vb以及Vb→Va。强连通分量则是指一张有向图G的极大强连通子图G’。如果将每一个强连通分量缩成一个点，则原图G将会变成一张有向无环图。一张图被称为有向无环图当且仅当此图不具有点集合数量大于一的强连通分量，因为有向环即是一个强连通分量，而且任何的强连通分量皆具有至少一个有向环。（摘自维基百科）对于无向图，求连通分量的问题就等价于求是否连通的问题，使用深度优先、广度优先搜索的算法的到的树都能求出最大连通分量。Kasaraju算法Kasaraju算法在我第一次接触时，感觉确实有点难理解，虽然现在也还是有点难理解。本文中不会去证明算法，只是讲解算法的一些实现等。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677public static class KosarajuSCC &#123; int n; List&lt;Integer&gt;[] adj; KosarajuSCC(int n) &#123; this.n = n; this.adj = new ArrayList[n]; for (int i = 0; i &lt; n; i++) &#123; this.adj[i] = new ArrayList&lt;&gt;(); &#125; &#125; public void addEdge(int v, int w) &#123; this.adj[v].add(w); &#125; //正向遍历，以后根序压栈，保证根先出栈 public void fillorder(int v, boolean[] visited, Stack&lt;Integer&gt; s) &#123; visited[v] = true; for (Integer i : this.adj[v]) &#123; if (!visited[i]) &#123; fillorder(i, visited, s); &#125; &#125; s.push(v); &#125; //reverse 得到反向图 public KosarajuSCC getTranspose() &#123; KosarajuSCC gv = new KosarajuSCC(this.n); for (int i = 0; i &lt; n; i++) &#123; for (Integer j : this.adj[i]) &#123; gv.adj[j].add(i); &#125; &#125; return gv; &#125; //DFS打印连通分支 public void DFSUtil(int v, boolean[] visited) &#123; visited[v] = true; System.out.print(v + " "); for (Integer i : adj[v]) &#123; if (!visited[i]) &#123; DFSUtil(i, visited); &#125; &#125; &#125; //按照Kosaraju算法的步骤执行 public void printSCCs() &#123; Stack&lt;Integer&gt; s = new Stack&lt;Integer&gt;(); boolean[] visited = new boolean[this.n]; for (int i = 0; i &lt; n; i++) &#123; visited[i] = false; &#125; //逆后序压栈 for (int i = 0; i &lt; n; i++) &#123; if (!visited[i]) &#123; fillorder(i, visited, s); &#125; &#125; //得到反向图 KosarajuSCC gr = this.getTranspose(); for (int i = 0; i &lt; n; i++) &#123; visited[i] = false; &#125; //依据反向图算可达性 while (!s.empty()) &#123; int v = s.pop(); if (visited[v] == false) &#123; gr.DFSUtil(v, visited); System.out.println(); &#125; &#125; &#125;&#125;先理解一下Karasaju算法的思路。对图G求其逆后序，即在深度优先遍历（DFS）中在递归调用之后压入栈中；对G进行转置，在代码中即得到反图；按照第一步中得到的栈的出栈的顶点顺序，对于GR图进行DFS可以得到若干搜索树。每棵搜索树都代表一个强连通分量。如上图示例的有向图，先求逆后序排序，得到{7, 8, 6, 9, 11, 10, 12, 0, 5, 4, 2, 3, 1}，然后按照这个图的转置图GR进行DFS，最终可以得到极大强连通分量5个：{7, 8}, {6}, {9, 11, 10, 12}, {0, 5, 4, 2, 3}, {1}。在Karasaju算法中使用了两次DFS，第一次是得到节点的逆后序排序（有的算法书将逆后序排序合并在拓扑排序里面）；第二次是对于转置图DFS得到最终的强连通分量。我们当然想要对于算法进行优化，减少DFS的次数也是一种极好的优化方式，想想如果一次DFS就可以得出强连通分量岂不是很好。Tarjan算法Tarjan算法是对于Kasaraju算法的改进。其基本代码实现思维如下：遍历一个点，指定唯一时间戳DFN[i]；指定改点向前追溯可追溯到最老时间戳LOW[i]；枚举当前点的所有边，若DFN[j]=0表明未被搜索过（这儿0、-1等都是可以的，只要是自我约定好的，正常不使用的就可以，如下面算法中使用的NO_VISIT），递归搜索；当DFN[i]不为0，则j被搜索过，这时判断是否在我们存储新建的栈中，且j的时间戳DFN[j]小于当前时间戳DFN[i]，可判定成环，将LOW[i]设定为DFN[j]；若这个点LOW[i]和DFN[i]相等，则这个点是目前强连通分量的元素中在栈中的最早的节点；出栈，将这个强连通分量全部弹出，保存。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public static class TarjanSCC &#123; private int numOfNode; private List&lt;ArrayList&lt;Integer&gt;&gt; graph;//二维数组表示图 private List&lt;ArrayList&lt;Integer&gt;&gt; result;//保存极大强连通图 private boolean[] inStack;//标记节点是否在栈内 private Stack&lt;Integer&gt; stack; private int[] dfn; private int[] low; private int time;//当前时间戳（实际是一个int的数，标记当前访问的节点） private static final int NO_VISIT = 0; public TarjanSCC(List&lt;ArrayList&lt;Integer&gt;&gt; graph, int numOfNode) &#123; this.graph = graph; this.numOfNode = numOfNode; this.inStack = new boolean[numOfNode]; this.stack = new Stack&lt;Integer&gt;(); dfn = new int[numOfNode]; low = new int[numOfNode]; Arrays.fill(dfn, NO_VISIT);//将dfn所有元素都置为0，代表i还有没被访问过。 Arrays.fill(low, NO_VISIT); result = new ArrayList&lt;ArrayList&lt;Integer&gt;&gt;(); &#125; //获取强连通分量 public List&lt;ArrayList&lt;Integer&gt;&gt; tarjanResult() &#123; for (int i = 0; i &lt; numOfNode; i++) &#123; if (dfn[i] == NO_VISIT) &#123; tarjan(i); &#125; &#125; return result; &#125; //算法核心 public void tarjan(int current) &#123; dfn[current] = low[current] = time++; inStack[current] = true; stack.push(current); for (int i = 0; i &lt; graph.get(current).size(); i++) &#123; int next = graph.get(current).get(i); if (dfn[next] == NO_VISIT) &#123; tarjan(next); low[current] = Math.min(low[current], low[next]); &#125; else if (inStack[next]) &#123; low[current] = Math.min(low[current], dfn[next]); &#125; &#125; if (low[current] == dfn[current]) &#123; ArrayList&lt;Integer&gt; temp = new ArrayList&lt;Integer&gt;(); int j = -1; while (current != j) &#123; j = stack.pop(); inStack[j] = false; temp.add(j); &#125; result.add(temp); &#125; &#125;&#125;需要注意的是在算法中的时间戳这个标记，并不是代表真正的时间戳，而是对于每个节点不同的一种标记，在本文算法中都是用一个递增数组来表示，即访问每个节点时，将该时间戳变量自增赋值给该节点的时间戳DFN[i]。Gabow算法Gabow算法在基础上与Tarjan算法相似，都是利用一次DFS算法实现。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public static class GabowSCC &#123; private int numOfNode; private List&lt;ArrayList&lt;Integer&gt;&gt; graph;//二维数组表示图 private List&lt;ArrayList&lt;Integer&gt;&gt; result;//保存极大强连通图 private Stack&lt;Integer&gt; path; private Stack&lt;Integer&gt; root; private int[] order; private int time;//当前时间戳（实际是一个int的数，标记当前访问的节点） private static final int NO_VISIT = -1; private int[] part; // 连通变量的标号； private int partNum = 0; public GabowSCC(List&lt;ArrayList&lt;Integer&gt;&gt; graph, int numOfNode) &#123; this.graph = graph; this.numOfNode = numOfNode; this.path = new Stack&lt;&gt;(); this.root = new Stack&lt;&gt;(); order = new int[numOfNode]; part = new int[numOfNode]; Arrays.fill(order, NO_VISIT); Arrays.fill(part, NO_VISIT); &#125; public int[] gabowResult() &#123; for (int i = 0; i &lt; numOfNode; i++) &#123; if (order[i] == NO_VISIT) &#123; gabow(i); &#125; &#125; return part; &#125; public void gabow(int v) &#123; order[v] = ++time; path.push(v); root.push(v); for (int i = 0; i &lt; graph.get(v).size(); i++) &#123; int next = graph.get(v).get(i); if (order[next] == NO_VISIT) &#123; gabow(next); &#125; else if (part[next] == NO_VISIT) &#123; while (order[root.peek()] &gt; order[next]) &#123; root.pop(); &#125; &#125; &#125; if (v == root.peek()) &#123; root.pop(); partNum++; int top; do &#123; top = path.peek(); part[top] = partNum; path.pop(); &#125; while (top != v); &#125; &#125;&#125;其算法基本思路是：在所有顶点中，找一个没有被访问的节点v，如果没有则完成；记录v的访问顺序；将v压入堆栈path和root；如果v指向的邻接点，对应每个邻接点next：1、如果没有访问过，则以next为参数，递归到第二步；2、如果访问过，且没有确定它属于哪个强连通分量，弹出root栈中next之后（即之上）的所有顶点；3、如果root栈中的元素等于v，那么在part中记录顶点对应的强连通分量递归返回附本文只涉及算法的实现，没有设计算法的证明等，如有想法，请分享。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基础查找算法分析]]></title>
    <url>%2F2017%2F05%2F13%2F%E5%9F%BA%E7%A1%80%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[在之前学习了一些排序算法，得出了基础排序算法的总结。之后学习了一些查找算法，今天来对于基础的一些查找算法进行总结。排序与查找是我们一般开发中最常用的算法。例如在开发中需要找出某个人的个人信息，就需要根据某个关键信息去查找。顺序查找顺序查找是按照我们思维最通俗易懂的算法，就是依次去对比，得到相等的则查找成功。当然这种算法是十分低效的，但是它对于我们需要查找的数据源，没有任何要求，就如数组中数据是可以乱序的。二分查找相似与之前排序算法的分治的思想，但是这种类似于分治的思想确实不同于分治。与分治得到有序结果相对应的是我们在查找的时候需要查找的数据源是有序的。12345678910111213141516public int halfFind(Key key) &#123; int lo = 0, hi = N - 1; while (lo &lt;= hi) &#123; int mid = (lo + hi) / 2; int cmp = key.compareTo(keys[mid]); if (cmp &lt; 0) &#123; hi = mid - 1; &#125; else if (cmp &gt; 0) &#123; lo = mid + 1; &#125; else &#123; return mid; &#125; &#125; return lo;&#125;上述代码是基于有序数组的二分查找算法简单实现，可以极大的减少比较次数，但是无法改变减少运行所需的时间，因为在查找源是无序的情况，将其排序成有序的情况也是需要一定运行时间的。二分查找的思想在很多查找算法里面都有体现，如插值查找、切波那锲查找、二叉查找数等都体现了这种思想。二叉查找树二叉查找树也是使用了二分的思想，只是在数据存储时使用二叉树的存储方式，也是链表的方式。12345678910public Value halfTreeFind(Key key) &#123; return get(root, key);&#125;private Value get(Node x, Key key) &#123; if (x == null) return null; int cmp = key.compareTo(x.key); if (cmp &lt; 0) return get(x.left, key); else if (cmp &gt; 0) return get(x.right, key); else return x.val;&#125;在二叉查找树中，插入难度和查找是差不多的，运行时间主要取决于树的形状。而删除一个结点，是将其右子树中最小的结点上浮来替代。当然从其运行时间与树的形状相关，因此我们需要想办法使得树的形状基本趋于平衡，而使得效率最高。即平衡查找树。平衡查找树由二叉查找树的缺点而推出平衡查找树，其中包括2-3查找树、红黑树等。在一棵完美的2-3查找树中、所有空链接到根结点的距离都是相同的。其有两种结点、具有1个数和2个数的结点、即有2个子分支和3个子分支。在查找与插入的时候都需要分别考虑，虽然情况是有限的几种，但是我还是觉得有点繁琐。而红黑树相比较像是对于2-3树的一种升级，用红的连接来替代3结点。但是我还是比较喜欢是结点标红的意思。对于红黑树的定义在之前的文章中体现过。红黑树在于查找、插入和删除上都是十分好的，所以在java1.8的HashMap中，满足某个特定条件时会将链表转化为红黑树。对于红黑树，所有基于红黑树的符号表实现都能保证操作的运行时间为对数级别，当然范围查找除外。散列表我第一次听说散列表的时候，对于散列的意思有点迷糊，搞不懂其与哈希表的关系。后来才明白散列表就是哈希表。哈希表中，首先需要的是一个哈希算法，最常见的就是%，除留余数法。第二点是解决冲突，一般就是拉链法与线性探测法。对于开发地址散列表中，最简单的方法就是线性探测法。至于对于散列表，我就不详解了，HashMap源码分析看完后都能基本明白。附在查找算法中，普遍都是基于二分的思想进行优化的。类似于排序算法中基于分治的思想一样。虽然本文总结不够完善，但也基本理清我的思维。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[洗牌算法]]></title>
    <url>%2F2017%2F05%2F04%2F%E6%B4%97%E7%89%8C%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[第一次接触洗牌算法是在一次面试上，面试官要求我写出一个算法将一个1～100的有序数组打乱，不考虑性能，那次我想了许久，想到一种基于二叉排序的方式实现了随机洗牌，但是那个性能呢，惨不忍睹。后来详细学习排序算法的时候，发现为了保证快速排序的性能，需要在排序之前对排序的数组进行洗牌操作。为什么不基于一般排序算法做洗牌？众所周知，一般排序算法在在性能上以快速排序最好吧，时间复杂度基本在N*logN，空间复杂度在logN，当然三切分快速排序更好一些。所有算法中空间复杂度最好时为1，这当然是最好的。详细见对于基础排序算法的简要总结。但是在排序算法中没有能够达到时间复杂度N的线性的。而在洗牌算法中，我们随便便能实现N的线性的时间复杂度，因此基于排序算法做洗牌不可取。洗牌算法第一版初次想的是一个排列好的数组，再新建一个长度相等的数组，每次通过随机数，随机一个N以内的数作为下标将其添加到新数组，并将该随机下标与N为下标的数交换，当然N需要自减。在N开始的时候为数组长度减1的值（保证下标最大而不越界）。那么最后会形成一个任意数组在数组内的某一位置的概率都是1/N的随机数组。12345678910public static Comparable[] Shuffle1(Comparable[] c) &#123; Comparable[] a = new Comparable[c.length]; int N = c.length - 1; for (int i = 0; i &lt; c.length; i++, N--) &#123; int ran = intRandom(0, N); a[i] = c[ran]; c[ran] = c[N]; &#125; return a;&#125;这种算法相比较之前打算基于一般排序算法求解的方式，在时间复杂度上有了很大的提升。在时间复杂度上，这种算法保证了N次循环（N为数组长度），N次获取随机值，N次交换（但是有2N次数组元素赋值操作）实现了分部均匀的洗牌算法。但是它的缺点是需要另建数组，使得空间复杂度增加。在算法中使用了随机数的intRandom函数如下1234567private static int intRandom(int min, int max) &#123; if (min &gt; max) throw new IllegalArgumentException("min can not bigger than max"); if (max == min) return max; return new Random().nextInt(max - min + 1) + min;&#125;洗牌算法第二版为了减少空间复杂度，使得算法在原地进行洗牌操作，尝试着将算法改进。在本算法中使用随机生成一个下标，使得对应的数与第一个i个数交换（i会从0到N-1自增）。123456789public static void Shuffle2(Comparable[] c) &#123; int N = c.length; for (int i = 0; i &lt; N; i++) &#123; Comparable mid = c[0]; int ran = intRandom(0, N-1); c[0] = c[ran]; c[ran] = mid; &#125;&#125;当然在本算法中，空间复杂度是1，达到最小。而时间复杂度也没有很大升高，依然需要N次循环，N次随机，N次交换（但是有3N次赋值操作）。因为对于数组中的每个数都会进行同样的操作，不因为数组元素顺序等变化，因此对于任意一个数分布在某个位置的概率是相同的。所有这是目前我发现的最好的洗牌算法。附本文仅讲述一些自我对于洗牌算法的一些了解以及自我的一些思考以及实现，在目前我的了解中，这两种洗牌算法是最好的了，如有更好，请指出，共同学习。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven基础总结]]></title>
    <url>%2F2017%2F05%2F03%2FMaven%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[鉴于最近基本看完《Maven实战》这本书，对于我自己的所看的结果作一下总结，理清自己的思路，并复习书中的知识。当然有时间会继续学习一下Gradle，似乎是一个更好的工具。我原来对于Maven的印象就是依赖管理的工具，但是在认真学习之后，认识到Maven可以实现挺多实用功能。自动化构建依赖管理（提供中央仓库，能够帮我们自动下载构建）项目信息管理在Maven中最重要的思维莫过于约定优于配置。虽然在Maven中没有确定的文件定义一些要求，但是大家约定的一些写法等，保证了项目的移植性，当然也可以自定义，但是不推荐（因为你写了可能就自己看得懂了，别人都看不懂）。在Maven项目中默认的主代码目录为src/test/java，默认的测试代码目录为src/test/java。Pom文件在平时开发中，感觉到pom.xml文件是Maven项目中最重要的一环，它提供了项目信息与依赖管理等。首先，pom.xml文件中，包含一般XML文件头，指定xml文件版本以及编码方式等；接下来是project元素，包含相关的命名空间以及xsd元素等。12345678910111213141516171819202122232425&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;groupId&gt;com.fei&lt;/groupId&gt; &lt;artifactId&gt;fei.empty.spring.web&lt;/artifactId&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;properties&gt; &lt;jetty.port&gt;8417&lt;/jetty.port&gt; &lt;spring.version&gt;4.2.0.RELEASE&lt;/spring.version&gt; &lt;mybatis.version&gt;3.3.1&lt;/mybatis.version&gt; &lt;slf4j.version&gt;2.6.2&lt;/slf4j.version&gt; &lt;log4j2.version&gt;2.6.2&lt;/log4j2.version&gt; &lt;/properties&gt; &lt;dependencyManagement&gt; &lt;/dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; ...元素接下来重要的是groupId、artifactId、version元素，分别表示组（当前Maven项目隶属的实际项目）、唯一ID、版本。这个是Maven的坐标元素，基本可以确定一个项目，当然这三项是必须的，不管是在项目信息还是在依赖管理中，还有packaging、classifier分别表示打包方式和帮助定义构建输出的一些附属构建（ classifier是不能直接定义的，附属构建不是项目直接默认生成的，而是由附加的插件帮助生成）。例如在本例中因为是Javaweb项目，所以使用war的打包方式，在项目中如果不做声明，默认的是jar打包方式。这5个元素可以唯一的确定项目。版本关于版本，分为发布版本和快照版本，在本例中的1.0-SNAPSHOT就是快照版本，快照版本是不稳定的。在Maven中版本号的约定是&lt;主版本&gt;.&lt;次版本&gt;.&lt;增量版本&gt;-&lt;里程碑版本&gt;。关于版本管理的一些本文不会涉及。在配置的pom文件中提供了properties标签自定义。利用这个我们将所有的版本号集中在一起，方便更新、引用，以及减少一些版本号重复性。依赖除了在项目信息中使用到了这些元素标签，还在依赖管理中使用，这是很必要的，需要用它们去确定一个Maven项目。在 dependencies里会有许多dependency来确定每个依赖。例如spring项目中一般会包含spring-core、spring-context、spring-context-support等都是Spring Framework实现依赖注入等功能必要的构建，都需要在项目中依赖。在依赖的servlet中定义了scop标签，表示定义依赖的范围，那么provided是什么意思呢？在一般情况中，我们有6种依赖范围：1、compile：编译依赖范围，一般在缺省默认情况下也使用这个默认范围；2、test：测试依赖范围；3、provided：已提供依赖范围，表示对于编译和测试classpath有效，但是在运行的时候无效；4、runtime：运行时依赖范围，即测试和运行classpath有效；5、system：系统依赖范围，该依赖范围与三种classpath的关系与provided相同，但是在使用这个依赖范围时，必须通过systemPath元素显式地指定依赖文件的路径，在使用时会造成不可移植性；6、import：导入依赖范围，其实是继承父模版的依赖配置，继承依赖范围。依赖范围（scop）对于编译classpath有效对于测试classpath有效对于运行classpath有效示例compileYYYspring-coretest-Y-JUnitprovidedYY-servlet-apiruntime-YYJDBC驱动实现systemYY-类似于java的属性继承一样，Maven也具有传递性依赖，继承依赖范围关系如下，左一列为直接依赖，横一栏为间接依赖，内容表示最终依赖范围。compiletestprovidedruntimecompilecompile--runtimetesttest--testprovidedprovided-providedprovidedruntimeruntime--runtime这儿其实有一些规律：在间接依赖为compile时其他两者一致；当间接依赖为test时，不具有传递性；当间接依赖为provided时，只有provided才能传递，且最终依赖为provided；当间接依赖为runtime时，一般情况时直接依赖与最终依赖一致，除了直接依赖为compile时最终依赖为runtime。既然有传递性依赖，以及继承等机制（这些会在后续讲到），并没有像Java一样限制只能单继承，那么必会出现像C++一样通过不同路径继承同意文件而产生冲突的情况，那么如何解决？Mave这儿需要依赖调解。第一原则是路径最近者优先；第二原则是第一声明者优先。当然在依赖的时候，提供了optional标签来表示可选。可选依赖是不会传递的。也提供exclusions标签来排除继承时的某些依赖，可以解决在继承时快照版本依赖的不稳定性问题。仓库在上文中讲到依赖，那么依赖后引入的包相对于其对应仓库中的路径应该是多少呢？在路径与坐标的大致对应关系为groupId/artifactId/version/artifactId-version.packaging。对于Maven来说，仓库只分为两种：本地仓库和远程仓库。一般情况是当我们使用依赖去引入一种构建，当Maven根据坐标寻找构建时，先会去本地查找此构建，如果本地没有这个构建，去远程仓库查找，发现则下载到本地使用（当然本地构建需要查看更新时也是需要去远程仓库查找）。本地仓库一般在用户中本机中，默认情况下都有一个.m2/repository/的仓库目录。远程仓库远程仓库分为中央仓库以及自己建立的私服等。一般情况下，基本每个公司都是有自己的Maven仓库的，在开发之前的环境配置时会加上一个自己公司的setting.xml文件的配置。生命周期Maven拥有三套独立的生命周期，分别为clean、default、site。clean生命周期目标是清理项目；default是构建项目；而site生命周期目的是建立项目站点。clean生命周期包括pre-clean、clean、post-clean。一般调用clean时会依次执行pre-clean、clean。一般命令都是执行到指定的阶段截止。default是所有生命周期中最核心的部分。包括了许多阶段：calidate、initialize、generate-sources、process-sources、generate-resources、process-resources、compile、process-classes、generate-test-sources、process-test-sources、generate-test-resources、process-test-resources、test-compile、process-test-clasess、test、prepare-package、package、pre-integration-test、integration-test、post-integration-test、verify、install、deploy。在这个生命周期中可以看到有许多编译、测试等阶段。而site生命周期有pre-site、site、post-site、site-deploy四个阶段。插件个人觉得Maven中插件是非常重要的一环，可以帮助我们完成一些任务，并且与生命周期中的某个阶段绑定。1234567891011121314151617181920212223...&lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.3&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;configuration&gt; &lt;port&gt;$&#123;web.port&#125;&lt;/port&gt; &lt;path&gt;/$&#123;project.artifactId&#125;&lt;/path&gt; &lt;uriEncoding&gt;UTF-8&lt;/uriEncoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; ...在这段代码中使用plugin标签加入了maven-compiler-plugin以及tomcat插件，可以使得项目可编译以及不用本地的tomcat服务器。compiler的插件是内置绑定的compile阶段，不用显式申明。当然也可以自定义绑定，在配置中加入executions、execution标签配置 执行一个任务，并用phase绑定生命周期。测试讲到插件，就不能跳过Maven的测试。测试也是使用插件来实现的，如maven-surefire-plugin插件。可以帮助我们单元测试、集成测试等。聚合与继承聚合特性能把项目的各个模块聚合在一起构建，而继承特性能帮助抽取各模块相同的依赖和插件等配置。所有模块组成的一个构建结构就是反应堆。单模块项目就是这个模块本身；而多模块项目则包含了各模块之间的继承和依赖关系、计算合理构建顺序。附本文中对于许多详细知识没有作总结，只是对于常用的一些部分作了浅入的涉及。如测试、聚合与继承、以及Nexus建私服、profile、站点等知识没有解释，需要学习的可以仔细看一下《Maven实战》。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对于基础排序算法的简要总结]]></title>
    <url>%2F2017%2F04%2F24%2F%E5%AF%B9%E4%BA%8E%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E7%9A%84%E7%AE%80%E8%A6%81%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[本文主要分析排序算法中的选择排序、插入排序、希尔排序、归并排序、快速排序和堆排序，以及其部分优化方式，部分代码示例。当然快速排序算法是最快的通用排序算法，这使得其在java中的地位非凡，通常的ArrayList.sort()函数就是使用的快速排序。在这之前，我们先声明两个方法：分别为比较大小与数据交换的方法。123456789final static boolean less(Comparable i, Comparable j) &#123; return i.compareTo(j) &lt; 0;&#125;final static void exch(Comparable[] a, int i, int j) &#123; Comparable t = a[i]; a[i] = a[j]; a[j] = t;&#125;在排序中我们使用Comparable[]的数组进行排序，以便兼容其他类型的数组。选择排序选择排序是的思维是依次找到最小或最大的值，将这个值与我们所比较的值中的第一个或进行交换。这种算法的特点是：1、运行时间与输入无关，就算是输入有序运行时间也是差不多的；2、数据的移动是所有算法中最少的。1234567891011public static void selectionSort(Comparable[] a) &#123; int N = a.length; for (int i = 0; i &lt; N; i++) &#123; int min = i; for (int j = i+1; j &lt; N; j++) &#123; if (less(a[j], a[min])) min = j; exch(a, i, min); &#125; &#125;&#125;插入排序插入排序的基本思路是在循环中将下标i之前的元素进行比较交换（这儿是不符合比较小或比较大的条件则交换）。这种算法对于有序或者比较有序的数组时效率较高。123456789101112131415public static void insertSort(Comparable[] a) &#123; int n = a.length; for (int i = 1; i &lt; n; i++) &#123; Comparable mi = a[i]; boolean f = false; int j = i; for (; j &gt; 0 &amp;&amp; less(mi, a[j - 1]); j--) &#123; a[j] = a[j - 1]; f = true; &#125; if (f) &#123; a[j] = mi; &#125; &#125;&#125;在上述插入排序代码示例中，并没有每次比较交换相邻的两个元素，而是将较大的元素都向右移，也是每次循环中将比循环比较的最后一个元素的值大的元素都作右移操作，从而减少访问数组的次数。对于减少访问数组的次数，这点需要详细说明一下：对于普通的插入排序，是每次获取相邻两个元素的值进行比较交换，即每次循环都会获取2*i次数据，总的访问数组（即获取数组元素）的次数就是n*(n-1)次（n为数组的长度）；而对于优化后的插入排序，每次循环访问数组i+1次，总的访问数组(n-1)*(n+2)/2次，大约减少了一半的访问数组的次数。而对于插入排序与选择排序的比较，主要是在数组有序或部分有序时，减少了交换的次数，从而对于部分有序或有序的数组较高。希尔排序希尔排序的思想是使数组中的任意间隔为h的元素都是有序的。相对于插入排序改变了原来的插入的顺序。从原来的相邻的两个元素交换改成现在相邻两个增量交换的排序（增量即间隔）。通过增量递减的方式重复排序，直到增量为1，使得原数组有序。（增量序列为一组递减的且最后一个元素为1的数组。）12345678910public static void shellSort(Comparable[] a) &#123; int N = a.length; for (int h = N / 2; h &gt;= 1; h = h / 2) &#123; for (int i = h; i &lt; N; i++) &#123; for (int j = i; j &gt;= h &amp;&amp; less(a[j], a[j - h]); j -= h) &#123; exch(a, j, j - h); &#125; &#125; &#125;&#125;在示例中我是将增量/2得到之后的增量；当然这种增量序列不是最优的。在张连堂与张博的《希尔排序最佳增量序列研究》中做了一些分析并得到一种最优的增量序列：… 2^k -1, … 15, 7, 3, 1。希尔排序对于之前的排序算法是对于平方级的突破，权衡了子数组的规模与有序性使得其更加高效。归并排序归并排序分为原地归并、自顶向下、自底向上三种归并方式。但是最主要的思维也是归并，归并是将前后两端进行比较，将小的放上去，需要注意越界。而自顶向下是采用分治的思想，使用递归的方式进行归并。自底向上是采用相邻两个归并，在到相邻两组归并，刚好与自顶向下相反。123456789101112131415161718192021222324252627282930313233343536373839404142public static class Merge &#123; private static Comparable[] aux; /*归并*/ public static void merge(Comparable[] a, int lo, int mid, int hi) &#123; int i = lo, j = mid + 1; for (int k = lo; k &lt;= hi; k++) &#123; aux[k] = a[k]; &#125; for (int k = lo; k &lt;= hi; k++) &#123; if (i &gt; mid) a[k] = aux[j++]; else if (j &gt; hi) a[k] = aux[i++]; else if (less(aux[j], aux[i])) a[k] = aux[j++]; else a[k] = aux[i++]; &#125; &#125; /*自顶向下*/ public static void mergeTopSort(Comparable[] a) &#123; aux = new Comparable[a.length]; sort(a, 0, a.length-1); &#125; private static void sort(Comparable[] a, int lo, int hi) &#123; if (hi &lt;= lo) return; int mid = lo + (hi - lo)/2; sort(a, lo, mid); sort(a, mid+1, hi); merge(a, lo, mid, hi); &#125; /*自底向上*/ public static void sort(Comparable[] a) &#123; int N = a.length; aux = new Comparable[N]; for (int sz = 1; sz &lt; N; sz = sz+sz) &#123; for (int lo = 0; lo &lt; N -sz; lo += sz+sz) &#123; merge(a, lo, lo+sz+1, Math.min(lo+sz+sz-1, N-1)); &#125; &#125; &#125;&#125;快速排序快速排序是最常用的排序算法，采用分治的思想。将一个数组分为两个数组再排序。切分（partition）是使用交换等方法将某个值放确切的位置，再将其左右排序切分。这个确切的值满足其左边都小于它，右边都大于它，使得在其确定后，在整个排序过程中都不会对其产生影响，其位置不会再作变化。12345678910111213141516final static int partition(Comparable[] a, int lo, int hi) &#123; int i = lo, j = hi + 1; Comparable v = a[lo]; while (true) &#123; while (less(a[++i], v)) &#123; if (i == hi) break; &#125; while (less(v, a[--j])) &#123; if (j == lo) break; &#125; if (i &gt;= j) break; exch(a, i, j); &#125; exch(a, lo, j); return j;&#125;而排序算法就是使用递归的方式去调用切分的方法。123456public static void quickSort(Comparable[] a, int lo, int hi) &#123; if (hi &lt;= lo) return; int j = partition(a, lo, hi); quickSort(a, lo, j - 1); quickSort(a, j + 1, hi);&#125;上述为标准快速排序，其在很多地方依然具有缺陷，如在切分不平衡时可能使得排序十分低效，如将{6, 5, 4, 3, 2, 1}转换成由小到大排序时就十分低效。当然对于快速排序，先辈们依然做了许多优化的方法：1、快速排序对于小数组的排序特别慢，因此使用在数组小时以及分治到较小是采用插入排序优化；2、使用三取样切分，来解决具有大量重复数据情况。三取样切分的快速排序算法示例如下：1234567891011121314151617public static void quick3waySort(Comparable[] a, int lo, int hi) &#123; if (hi &lt;= lo) return; int lt = lo, i = lo + 1, gt = hi; Comparable v = a[lo]; while (i &lt;= gt) &#123; int cmp = a[i].compareTo(v); if (cmp &lt; 0) &#123; exch(a, lt++, i++); &#125; else if (cmp &gt; 0) &#123; exch(a, i, gt--); &#125; else &#123; i++; &#125; &#125; quick3waySort(a, lo, lt - 1); quick3waySort(a, gt + 1, hi);&#125;优先队列以及堆排序顾名思义，是具有优先级的队列，即对于这个队列中的数据是有序的。实现方式有很多，基于数组、链表、堆都可以实现。这儿主要介绍一下基于二叉堆的优先队列的实现，下述代码中已经十分清晰。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public static class MaxPQ&lt;Key extends Comparable&lt;Key&gt;&gt; &#123; private Key[] pq; private int N = 0; public MaxPQ(int maxN) &#123; pq = (Key[]) new Comparable[maxN + 1]; &#125; public boolean isEmpty() &#123; return N == 0; &#125; public int size() &#123; return N; &#125; private boolean less(int i, int j) &#123; return pq[i].compareTo(pq[j]) &lt; 0; &#125; private void exch(int i, int j) &#123; Key t = pq[i]; pq[i] = pq[j]; pq[j] = t; &#125; private void swim(int k) &#123; while (k &gt; 1 &amp;&amp; less(k / 2, k)) &#123; exch(k / 2, k); k /= 2; &#125; &#125; private void sink(int k) &#123; while (2 * k &lt;= N) &#123; int j = 2 * k; if (j &lt; N &amp;&amp; less(j, j + 1)) &#123; j++; &#125; if (!less(k, j)) &#123; break; &#125; exch(k, j); k = j; &#125; &#125; public void insert(Key v) &#123; pq[++N] = v; swim(N); &#125; public Key delMax() &#123; Key max = pq[1]; exch(1, N--); pq[N + 1] = null; sink(1); return max; &#125;&#125;需要注意的是上浮swim()和下沉sink()函数，是分别在插入与删除的时候被调用使得二叉堆平衡。而堆排序算法如下：12345678910public static void heapSort(Comparable[] a) &#123; int n = a.length; for (int k = n/2; k &gt;= 1; k--) &#123; sink(a, k, n); &#125; while (n &gt; 1) &#123; exch(a, 1, n--); sink(a, 1, n); &#125;&#125;这儿的sink(i,j,N)也是下沉函数，是将从j为顶开始下沉操作，使得平衡，具体实现类似于之前的优先队列的sink函数。这儿的思想是得到最大数与最后一个数交换再对前面的数组进行下沉操作，以此类推。总结对于排序算法，我们需要分析其稳定性。在排序算法中保留重复元素的相对位置，则该算法是稳定的。对于目前的排序算法中，插入与归并排序是稳定的；而选择、希尔、快速、堆排序不是稳定的。算法是否稳定是否原地排序时间复杂度空间复杂度备注选择排序否是N^21插入排序是是介于N和N^2之间1取决于输入元素的排列情况希尔排序否是1快速排序否是N*logNlgN运行效率由概率提供保证三切分快速排序否是介于N和N*logN之间lgN运行效率由概率提供保证，同时取决于输入元素的分布情况归并排序是否N*logNN堆排序否是N*logN1附本文并没有涉及所有的排序算法，还有如冒泡排序、基数排序等，需要的可以找找资料学习。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap 源码分析]]></title>
    <url>%2F2017%2F04%2F03%2FHashMap-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[HashMap是非常常用的键值对类型。本文主要讲述了HashMap的思维以及其重要或者常用的put，get，remove以及resize函数。首先Java定义了java.util.Map的接口，而常用的实现类型主要有HashMap、ConcurrentHashMap、LinkedHashMap和TreeMap。对于原来常用HashTable在不强调线程安全性时可以用HashMap替代（也就是说HashMap是线程不安全的），而在线程安全的情况下用ConcurrentHashMap替代。总体结构首先HashMap在Java1.8之后修改了其部分实现方式，将原来“数组+链表”的实现方式改为现在的“数组+链表+红黑树”的实现方式，采用红黑树的实现方式，增强了对于数据查找、删除、修改等性能，对于增加来说，应该是减慢了，但是个人觉得对于增加影响非常小。红黑树，RBTree，平衡二叉查找树的一种，具有良好的查找性能。他有五点要求：1、任何一个节点都有颜色，黑色或者红色；2、根结点是黑色的；3、父子节点之间不能出现两个连续的红节点；4、任何一个节点向下遍历到其子孙的叶子节点，所经过的黑节点个数必须相等；5、空节点被认为是黑色的。其实现方式比较复杂，若有时间我看完其源码再做分析。冲突的含义：是指当两个不同的键值对（key不相同）在put的时候hash(key)所得的值是相同的，他们会放到哈希桶数组的同一下标位置，形成链表或者红黑树，这种情况就是冲突。当然，在HashMap中我们要尽量的选取比较好的哈希函数来避免冲突，但是大多数情况冲突是不能完全避免的，所以要引入链表和红黑树来解决冲突。节点首先，HashMap类中包含了多个内部类，如Node、KeySet、Values、EntrySet等，在此就不一一列举。Node是HashMap中非常重要的类型，它代表每个节点，包含（hash，key，value，next）等属性，源码如下：123456789101112131415161718192021222324252627282930313233343536373839static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + "=" + value; &#125; public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125;&#125;先来说说Node每个属性的含义，1、hash：代表存储是的哈希值，一般由hash(key)函数得出；2、key；3、value：这两个就是键和值；4、next：是指指向下一个节点的指针。HashMap重要字段1、transient Node[] table; table表示哈希桶数组，transient表示其不参与序列化，即修饰的变量不是该对象持久化的部分。这个修饰符需要注意两点：1、只能修饰变量，本地变量不能被修饰（本地变量：局部变量）；2、静态变量（static修饰）不管有没有被修饰都不能序列化。2、transient int size; size是指当前存储的键值对数目。3、int threshold; threshold表示最大容纳的键值对个数，一般为threshold=length*loadFactor；length是指哈希桶数组长度，在当前键值对数目超过这个值时，哈希桶数组会扩容。4、final float loadFactor; loadFactor，负载因子（默认或缺省为0.75）。构造函数HashMap有4个构造函数，其一示例如下：123456789101112public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal initial capacity: " + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException("Illegal load factor: " + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity);&#125;其他几个构造函数是将loadFactor缺省或者将参数全部缺省，以及其拷贝构造函数。注意的是对于上述构造函数中将参数loadFactor赋值给负载因子，并将参数initialCapacity通过tableSizeFor函数操作后传给threshold，由上面所述，threshold是最大容纳的键值对个数，而initialCapacity理论上应该是初始化容量，即哈希桶数组初始化长度，而且这儿并没有初始化哈希桶数组长度，因此这儿赋值是跟其思维上不符合的，那么我们的threshold最终究竟是多少，以及在哪儿初始化了哈希桶数组长度呢？这一点，我会在后面分析put方法时讲到。很好奇tableSizeFor函数是做了什么操作？他是在函数里面进行了一系列的移位操作，保证初始化容量为2的n次方。例如，我们new一个HashMap(11)传入的参数为11，按照之前的观点，初始化哈希桶长度应该是11，但是其进行一系列移位操作后，使得初始化容量为16。关于tableSizeFor源码如下：123456789static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125;get操作这儿的思路是非常简单的，就是通过hash(key)&amp;(table.length-1)得到对应的哈希桶数组位置，再去对应的位置查找，当然现在对应的位置可能是链表类型，也可能是RBTree类型，对于Java1.7时，是只有链表类型，因此遍历链表类型可以查找出对于的字段；而对于Java1.8添加了红黑树结构之后，就需要判断当前对应的table[j]的node是不是TreeNode，如果是则通过红黑树去查找，不是则通过链表查找。1234567891011121314151617181920212223public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125;final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125;put操作这部分相对于get操作就复杂了许多，需要注意的一点是put操作会有返回值，当该key有对应的值时，put操作会返回原来的值（至于覆盖与否，我接下来分析putVal函数参数时会讲到），当对应key不存在时则返回null。接下来，我们分为几种情况讨论put操作：1、table为空或者table.length为0的时候。这种情况会出现在两个时候，分别是刚刚new了一个HashMap和前面操作将table删掉的情况（删除操作在后面的章节会做另外的讨论）。我们前面构造函数部分提到过，在构造的时候只是初始化了负载因子loadFactor，和将初始化哈希桶长度赋值给了最大容纳的键值对个数threshold。并没有对于哈希桶数组table做初始化，因此在这儿table是空NULL，就触发了扩容，在扩容的时候就会将threshold赋值给table的长度length，而真正的threshold在这儿赋值成length*loadFactor。这里解决了我们之前对于table在哪儿赋值以及threshold最终值的疑问。2、一般情况。就是将key转换成对应的哈希值从而找到对应的数组下标位置，再判断该位置是否存储有数据，该数据的key是否就是我们需要put的数据的key，存储的是链表还是红黑树，将数据插入就好，当然这儿就有一个情况——当插入之后，该链表的长度（即节点数）刚好超过8，那么根据我们一般的猜想就是转换为红黑树RBTree，其实不然。这儿分为两种情况，第一种（也是最特殊的一种），当链表长度超过8的时候，但是总的哈希表容量size并没有达到MIN_TREEIFY_CAPACITY=64，这时候会出发扩容的情况（扩容一般上会降低同一点的冲突，具体情况我会在扩容一章resize的时候讲到；第二种情况就是size达到或超过64，大家众所周知的转为红黑树。既然有链表转化为红黑树的操作，那么想必有红黑树转化为链表的操作，这个函数就是untreeify，他会在红黑树的节点数减少到6的时候（即小于等于6）将红黑树转化为链表。123456789101112131415161718192021222324252627282930313233343536373839404142434445public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125;final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125;注意putVal函数中后面有两个参数onlyIfAbsent和evict。onlyIfAbsent为ture的时候表示仅当该key缺省（即不存在）时才将该键值对加入HashMap。evict表示是否覆盖旧值，一般情况下evict是ture，表示你在后面put一个跟原来key一样的值时会覆盖掉原来的值，而如果是false时，则保留原来的值，也就是不覆盖，相当于put相同key的值没效果吧。1234567891011121314151617181920final void treeifyBin(Node&lt;K,V&gt;[] tab, int hash) &#123; int n, index; Node&lt;K,V&gt; e; if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY) resize(); else if ((e = tab[index = (n - 1) &amp; hash]) != null) &#123; TreeNode&lt;K,V&gt; hd = null, tl = null; do &#123; TreeNode&lt;K,V&gt; p = replacementTreeNode(e, null); if (tl == null) hd = p; else &#123; p.prev = tl; tl.next = p; &#125; tl = p; &#125; while ((e = e.next) != null); if ((tab[index] = hd) != null) hd.treeify(tab); &#125;&#125;这儿有个instanceof函数表示判断前者是否是后者的一个实例。例如，Result = object instanceof class; 判断object是不是class的一个实例，如果是则返回ture。TreeNode，树节点，他是继承自Node节点的，也就是说TreeNode形成的实例既有Node的key，value等属性，重要的是他有next属性指向下一个节点，而有有TreeNode的parent，left，rigth等属性，这儿在TreeNode里面增加了pre属性来指向前一个节点，只能够在红黑树中使用。在查找HashMap中是否包含某个value的时候将所有都当作链表节点来使用，将父类与本身的属性发挥的非常不错，比如在ContainsValue函数中就没有区分是否是红黑树去查找而是直接使用其父类的next函数查找下一个依次遍历。3、putMapEntries这个函数就是将，一个Map的所有值加入当前Map，当然需要指定evict参数。12345678910111213141516171819final void putMapEntries(Map&lt;? extends K, ? extends V&gt; m, boolean evict) &#123; int s = m.size(); if (s &gt; 0) &#123; if (table == null) &#123; // pre-size float ft = ((float)s / loadFactor) + 1.0F; int t = ((ft &lt; (float)MAXIMUM_CAPACITY) ? (int)ft : MAXIMUM_CAPACITY); if (t &gt; threshold) threshold = tableSizeFor(t); &#125; else if (s &gt; threshold) resize(); for (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) &#123; K key = e.getKey(); V value = e.getValue(); putVal(hash(key), key, value, false, evict); &#125; &#125;&#125;类似的有putAll函数，他就是引用了一下putMapEntries函数，区别就是默认了evict为true而已。123public void putAll(Map&lt;? extends K, ? extends V&gt; m) &#123; putMapEntries(m, true);&#125;resize函数这部分非常重要，时HashMap重要思维的体现之处之一。首先扩容会在两种情况发生，第一种，在链表转化为红黑树的时候阐述过链表长度大于8且哈希桶数组的长度size&lt;64时会出发扩容；第二种，size&gt;threshold的时候会触发扩容（threshold=length*loadFactor）。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;"rawtypes","unchecked"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125;从代码中可以看出resize函数是返回一个新的哈希桶数组，那么为什么要返回一个新的哈希桶数组呢？这点要从数组讲起，众所周知数组的长度是固定的，不能变长，那么我们怎么在HashMap中产生一个是原来长度两倍的数组呢？这儿就只能够创建一个新的数组来代替老的数组，需要将原来数组里面的变量一一填充到新的数组里面来。在Java1.7以及之前是一次将原来HashMap中的所有节点通过hash算法依次定位到新的Map中来。在Java1.8中对于老的数组同意位置的链表或红黑树中的节点填充到新的Map中做了很大的优化，使得扩容的速度快了许多。当然虽然优化了很多，但是这也是非常消耗时间成本的，因此我们在创建HashMap的时候就需要提前估计其能达到的最大容量，尽量一次性分配足够的空间，减少扩容情况。在Java1.8中对于HashMap扩容时数据转移做了很大的优化，这儿需要讲到hash获取数组下标的方法(n-1)&amp;hash(key)。对于hash(key)方法我不做过多阐述，想要学习的看看源码再自己测试一下就明白了。而对于按位与&amp;这儿需要说明一下，比如我们的数组长度n=4，那么呢n-1就是二进制的0011，举个例子当hash(key)为2和6的二进制分别时0010和0110，（前面的一些0就不做过多书写了），他们对于n-1的&amp;后得到的0011是相同的，也就是产生冲突，就会形成链表或者红黑树。而扩容之后，n’为8，n’-1二进制为0111，hash(key)进行&amp;操作后就是0010和0110，刚好是原来下标位置和原位置下标加上原来数组长度后作为下标的位置。这儿就可以直接用原来数组长度n的二进制0100与两个hash(key)进行&amp;操作，来判断是否需要将下标位置加上n了，如果是1则加。这样就不需要对于每个节点依次去进行一次重新定位操作。remove函数当然，跟之前的分析一样，我们都需要关注返回值，这儿返回的是value或者null，那么value是哪个value呢？就是原来我们移除的那个节点的value，当无这个节点时，那么返回null。其实这儿跟put函数一样，都是对于其基础函数的封装，这里remove函数是对于removeNode函数的封装。12345678910111213141516171819202122232425262728293031323334353637383940414243444546public V remove(Object key) &#123; Node&lt;K,V&gt; e; return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value;&#125;final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) &#123; Node&lt;K,V&gt; node = null, e; K k; V v; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) node = p; else if ((e = p.next) != null) &#123; if (p instanceof TreeNode) node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); else &#123; do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; node = e; break; &#125; p = e; &#125; while ((e = e.next) != null); &#125; &#125; if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) &#123; if (node instanceof TreeNode) ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); else if (node == p) tab[index] = node.next; else p.next = node.next; ++modCount; --size; afterNodeRemoval(node); return node; &#125; &#125; return null;&#125;从上面removeNode函数可以看出其返回的是一个Node类型，即返回移除的节点，除了没有对应节点时返回null，这儿有两个比较特殊的参数matchValue和movable，matchValue表示是否匹配value的值，而moveable表示是否可以移除，对于这点我有点想不太明白。在remove函数中这部分都是和value一起以默认值传出。在removeNode函数里面又有判断当为红黑树时的removeTreeNode函数，对于这个函数我不作过多分析，需要的可以自己去看一下源码。附对于其他函数等操作等，我就不具体分析，比如contains一系列，clear函数以及一系列Set等，以及其迭代器iterator等。这些如果需要学习可以仔细看一下其源码分析。最后推荐下美团点评技术团队的《Java 8系列之重新认识HashMap》。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>map</tag>
      </tags>
  </entry>
</search>
