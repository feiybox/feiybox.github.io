<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[边城：性格使然的悲剧]]></title>
    <url>%2F2018%2F06%2F27%2F%E8%BE%B9%E5%9F%8E%EF%BC%9A%E6%80%A7%E6%A0%BC%E4%BD%BF%E7%84%B6%E7%9A%84%E6%82%B2%E5%89%A7%2F</url>
    <content type="text"><![CDATA[再一次拿起边城，沈老先生的文笔，一直是朴素大方的，一篇中篇小说，从开始到结局，没有一点一丝的矛盾，顺其自然的发展，没有斧凿痕迹的自然。 这本小说里，写的世界是美好的，每个人都有着最朴实无华的品质，没有那些勾心斗角，没有那些灯红酒绿，一切都是人最期望的平凡与宁静。而悲剧式的结尾并没有像其他悲剧一样——将美好的东西毁灭给人看，这是一种自然而然地美好式的悲剧。从开始翠翠害羞地避开问题时，就知道最终会有伤害。 在文中，每个人都是有着最普通人的品质，都是抽象的人，都在不同环境下，有着人心里的一些矛盾，一些自我的思维与责任。 翠翠从塑造起，就是一个最普通农家女孩，从小与爷爷相依为命，因而对爷爷依赖极深，正因为这种爱，才对于爷爷渐渐老去而感害怕，害怕自己孤单一人。在自己十五六岁时，正伴随着自己思维的成长，因而有着普通孩子的害羞，对于爷爷每次谈到恋爱婚姻等询问时，都避而不答。对于喜欢的人，因为害羞远远避开，不敢去相遇。 爷爷也是极其普通老爷爷的形象，大方得总是将自己的小葫芦酒给别人喝上几口，对别人也总是嘘寒问暖。对于翠翠也是极其的爱护，希望将翠翠交给一个好人家照顾，在对于翠翠终身大事上，让翠翠自己去选择。但完全没想到，因为自己，却造成了船总大儿子天保的英年早逝，而无比地自责，也对于翠翠的未来感到无比的担忧。怀着这种愧疚，最终在大雨中去了。 船总顺顺，一个朴实能干的实业家，有着幸福美满的生活。对于儿子的婚姻，也是由其发展，却也希望有一个好的未来。在小城里，是一个公正大方的人，与每个人都有着较好的关系，都受到基本人的尊重。从大儿子的死，也埋冤那老爷子，因此也不愿意再将这一个女孩迎回家门。 天保，继承了父亲的老实朴素，是一个少有大为的孩子。在知道翠翠喜欢的人是瘫送时，没有选择与兄弟的反目，而是公平的竞争，以及最后的放手。一个朴实无华的老实人跃然纸上，没有对于人过多的描述，只是寥寥的点点事迹。 瘫送，相比较其大哥来说，更加有聪明以及才智等。在爱恨情仇上，喜欢着翠翠，但是却又在其中得不到回复，因为失去了哥哥。却因为喜欢翠翠，始终没有怪翠翠。而却又因为自己在婚姻上的选择，与父母争吵后出去了。 在沈老先生而言，文中描述一种旧时的闲适，或者一种民风，从现实中这种的消逝来说，结局正代表着这种民风的消逝，所以自然而然的悲剧的产生。我有时候怀疑，瘫送的出走，正代表着一种新青年的一种崛起，也许也代表着老先生本人。 从人之间的关系，这种悲剧的产生，是性格使然的结果，如果再重复一次，依然会再一次重复这种悲剧。老爷爷因为十分爱护翠翠，每次当谈到恋爱等时，看到翠翠害羞时，都害怕继续谈下去翠翠生气，而避而不谈。却正因为没有告诉翠翠所有的事情，最终也是悲剧。这是一种因为爱护而自然而然的悲剧。而顺顺，作为父亲，因为失去的儿子而怪罪渡船老头，因为不愿意次子再娶了翠翠。 这一些都是人本身性格的结果。在我认识里，虽然淳朴，但翠翠还没有真正认识到爱情，还在成长的懵懂期。正是这种害羞，不敢去面对自己喜欢的人，而没有从爷爷那里获知那一切发生的事。 从每一个人的角度看来，所有人都在向着一个自己所能接受的美好的角度发展，然而从整体上而言，最终的悲剧是不可避免的。从人生角度去理解，只能感受到一种由衷的悲伤，但是这种却也是一种发展，当失去某些东西时，必定将伴随着一些的到来。像翠翠，虽然是悲剧的，但应该明白了之后的，会有长大以及思想的成熟。 有时候在想，边城是代表着家乡的意思，代表着家乡的变化里，渐渐丧失了原来的一些东西，或许是自己离乡很久了，家乡就变得不像自己记忆里的那一种家乡了，最后便有了每个人心里都有一个属于自己的边城。]]></content>
      <categories>
        <category>read</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[类图中的关系]]></title>
    <url>%2F2018%2F06%2F03%2F%E7%B1%BB%E5%9B%BE%E4%B8%AD%E7%9A%84%E5%85%B3%E7%B3%BB%2F</url>
    <content type="text"><![CDATA[在我们使用UML图进行设计时，会涉及类图之间的关系，一般关系为以下的五种关系，理解其中的概要能够对于后续我们的设计有一定的帮助。 1、一般化关系，或者称为继承关系 2、关联关系关联关系中一个类知道另一个类的属性和方法。通常通过类里引用另一个类的实例变量实现。 3、聚合关系聚合关系与下面的合成关系都是属于关联关系的一种。在聚合关系中，主要表现的是整体与个体的关系。由于本属于关联关系，因此也是通过实例变量的方式实现。聚合关系与关联关系的区别是，关联关系主要是两个类都是在同一个层次的。 4、合成关系合成关系是指普通聚合关系的同时，代表整体的对象负责代表部分的对象的生命周期。合成关系是不能够共享的。代表部分的对象每个时刻只能与一个对象发生合成关系。 5、依赖关系依赖关系主要指类的局部变量、方法参数以及对静态方法的调用，是另一个类的实例对象等。]]></content>
      <categories>
        <category>tech</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[读《机器崛起》]]></title>
    <url>%2F2018%2F05%2F30%2F%E8%AF%BB%E3%80%8A%E6%9C%BA%E5%99%A8%E5%B4%9B%E8%B5%B7%E3%80%8B%2F</url>
    <content type="text"><![CDATA[从开始看到这一本厚重的书，有着三百多扉页，竟然有这三十多页参考文献，让我感到有点震惊。一本本着将控制论过往的历史，引入了现代这个社会中方方面面的每一个点滴。 现在我们手中的手机，包里的电脑，或者各种代步的工具，都由着这控制论的衍生。从机器里，提出控制论，或者因为控制，所以有的机器。我从书中，也得到一些有趣的论点。 战争是技术最好的催化剂从人性角度，战争是残酷的；而从技术角度，战争是伟大的。每一次战争都很大促进了技术的发展。或者就在现在，军事上的技术依然超越我们目前可涉及技术一代。 在第二次世界大战里，技术上提出了智能炸药以及防空系列如何预判飞行器的轨迹等武器等，都从战争中第一次的想让机器有着自动化的操作，像有着思维一般。并在后续军事技术的发展中，设计了智能头盔显示系统，以及后续的计算机网络防护。 这些先进技术的发展，都是伴随着战争中的需求，或者战争后军事上的需求等，一个先进的技术上，都是从军事到民用的发展。战争在技术的发展中，明显担任了催化剂的作用。 反馈从开始解除接触控制开始，就十分强调反馈的作用。在第一次接触反馈时，是在生物上的学习，有反馈调节系统，而在机器上，依然需要反馈，或者在生活的各个方面都需要反馈。 在我们生活中，做每一件事，最后要能够快速给反馈。比如在针对别人的请求或者告知等事件时，需要我们首先反馈出我们的态度。或许在你每次知道事后，并没有反馈，或者对于发起人而言，告知你或许并没有那么必要，因为告知这个执行，并不知道成功与否。 在机器上，同样。早期对于预算飞行器飞轨迹后，需要我们炮塔等防空无语快速作出反应。然而在炮塔的旋转后，并没有反馈是否旋转到位等，因此在后期中，引入反馈的概念。 每一个系统，都是由各种反馈构成的，包括国家、机构、团队等。如果反馈机制在某一个重要的环节中断裂，就证明着现在系统是存在问题的。 反馈的概念并不是仅仅针对于机器上而已，包括在生活的各个细节。在我接下来的所有行为中，我所接收到的重要消息等，我都会给予反馈，从康德的道德论来讲，我所希望的人与人之间的反馈是一种道德。 信息信息即为力量。从Cybernetics所引发出赛博空间、赛博战争等。都是技术上的一种延伸。而在这些技术中，信息的重要性也尤为重要，这个在我们现在社会中也有很好的表现。 信息，体现在了许多方面，比如常见的数据，也是信息的一种表现形式。因此在公司的发展中，能够保存的数据，应该存储好，后续可以做数据分析等，每一份数据都具有良好的价值。 迷幻剂在计算机发展中，一直伴随着迷幻剂共同的发展，或者在某一个程度上计算机代替着迷幻剂的效果。每个人都会遇到自己的迷幻剂，但是能够说迷幻剂就是错误吗？并不能。技术在一定程度上，正是由于那些对技术如痴如醉的人，才有了技术的进一步发展。 同然，在现在社会中，游戏或许在很大程度上代替着迷幻剂的作用。而对于有的经常喝醉的人而言，酒也是一种迷幻剂。而且我们无法确定自己是否已经身处迷幻剂，毕竟每个人都有所喜好的事或物。 计算机是新时代的迷幻剂，下一个时代的迷幻剂会是什么？ 自由从赛博空间开始，都是人向往着自由，到现在的比特币技术，缘由都是想着不受控制。正因为这种对于自由的向往，才有着非对称加密技术的发展，也是第一次体现了单向函数的伟大，或者大素数的伟大作用。 然而在加密技术的发展中，一直都在争议中发展。似乎体现着一种技术的成长都是带有一定的争议性，不知道目前的SDN以及区块链等是不是也是这样，最后都会发展为伟大的技术发明。 附在书中还有许多有趣的故事。但是整体而言是诉说控制论以及机器的发展历程。 比如在Bose提出新的播放器理论后，却没有公司接受，最终选择自己去执行，最终形成现在的Bose。都告诉我们，如果有想法，就去实现，不要犹豫。]]></content>
      <categories>
        <category>read</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[读罢此书]]></title>
    <url>%2F2018%2F03%2F19%2F%E8%AF%BB%E7%BD%A2%E6%AD%A4%E4%B9%A6%2F</url>
    <content type="text"><![CDATA[读罢此书，《自在 独行》。 带着寻找心灵解药的本心，开始追寻着文学上、心理上的解脱，想要去追寻出我所期望的高度是什么，想去让自己幸福，想渡自己。 读罢此书，一篇篇散文，有的朴素，有的却有深意。我明白这是一个自在的贾先生写的自在。但是我终究没有理解独行，或许是我所理解的独行不对。 这书里万事万物，都以一种自由的美好角度所展示，我能看出作者所热爱的生活。当然，我明白，文字能够表现出的，是作者所想的意，或者人的细节。我明白贾先生有大男子主义，是我所不喜好的。 从生活的美好里，追求生活的意义。不敢停止思考，我一直都在害怕，害怕着当有某一天，我看透了这个人生，选择离去。我害怕我会思考出自己生命的意义是没有意义。从来，对于每个人的选择都是敬畏的。当海子选择卧轨时，是抱着多大的勇气，我想，他们定是明白了这个人生了。 “写给每一个孤独的行路人”，或许我明白了这书来的意义。写给孤寂的人，看到这个世间的美好，便更加有了走下去的意义。 或许人生的意义，从来都是不需要去追寻的，或许它最终只是对于个人，来过这个世间的积累。看尽世间百态，或许是人生。也或许人活着，就是为了寻求人生的意义。道家里讲究死后乘鹤西去，佛家里追寻生命轮回，而唯物里，死后就什么也没有了，“化作春泥更护花”或许是唯物的追寻。 我有时在想，人生的意义，是否就是追求人在死亡来临那刻的高度，精神的卓越。我始终不解，但我知道，《自在 独行》里描写的世界就是这个世界，所写出的美好，便是一个普通人理解的美好。 我一直在寻找，生命的意义是什么。或许该问，寻找生命的意义的意义又是什么？有人说，生命的意义在于寻找意义的过程。或许该是如此。 这书，从没有讲过生命，只是讲着这个世间的美好，而我从来喜欢“随想”，不局限思维。或许我在向一个怪人的路上渐行渐近。也是有趣。]]></content>
      <categories>
        <category>read</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[解决word章节标题段前间距不显示问题]]></title>
    <url>%2F2018%2F03%2F07%2F%E8%A7%A3%E5%86%B3word%E7%AB%A0%E8%8A%82%E6%A0%87%E9%A2%98%E6%AE%B5%E5%89%8D%E9%97%B4%E8%B7%9D%E4%B8%8D%E6%98%BE%E7%A4%BA%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[如图片所示，在word中通过样式的调整，出现这种情况，显示得不正常情况。或许你会说改段落就可以，其实非然。 在目前看来，这儿有明显的段前30磅的距离，而这儿没有显示出来。 首先分析，word中，所有的东西都是有格式的，只有在相同样式之间段前段后格式不会显示。而这儿是段前格式没有显示出来，那么也就是，对于这种样式，前面的也是这种样式。然而一看，前面是正文格式。 或许你会发现，上一页的最后是同样的章节标题格式，但是没有表现。这点便是问题所在。因为我们使用了分节符，而由于我们可能是在写完文本后序去调整的格式，因此可能分节符的格式就是我们的章节格式。 当然，解决方法就是将分节符改为与分节符前格式相同，就可解决这个问题。 总结 问题章节标题段前距离没有显示。 解决方案将该章节标题前的分节符样式改为分节符之前的样式。]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>Word</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IDEA无限Indexing]]></title>
    <url>%2F2018%2F03%2F01%2FIDEA%E6%97%A0%E9%99%90Indexing%2F</url>
    <content type="text"><![CDATA[虽然无限Indexing并非错误，但消耗性能，并扰乱我们的开发进度。 我此处遇到的异常情况是，IDEA一加载某个Js就会一直出现无限Indexing，然后关掉，或者鼠标控制其他文件就不会出现这种情况。后来发现只是我电脑会有这种情况。因此猜测是因为我IDEA主题的问题。 我通过网上下载了一个名为Python的主题，并通过导入设置修改了IDEA主题。 然而通过查询资料没有找到卸载主题的办法，最终选择了暴力的解决方案，卸载重装IDEA。最终解决了该问题。 总结 问题由于IDEA主题导致某个文件加载出现无限Indexing情况。 解决方案卸载IDEA重装。 附推荐如何使用IDEA开发工具中右键中的Git图形化工具。]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>Idea</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[校招一些经验]]></title>
    <url>%2F2018%2F02%2F18%2F%E6%A0%A1%E6%8B%9B%E4%B8%80%E4%BA%9B%E7%BB%8F%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[秋招对我已经过去了几个月了，现在才想起来对于我的秋招经验做一个整体的总结。 秋招准备首先是怎么去准备秋招，我恰逢受学长指导，才开始于五月起准备秋招。对于秋招来说，早的公司有的会在8月的时候就开始。因此需要针对自己，做好提前准备。 从五月起，我看了《算法》一书，并针对自己对于其做了自己的总结，我总结了《对于基础排序算法的简要总结》、《基础查找算法分析》以及《SCC算法初解》，后续对于SCC部分基本没有涉及。 从根本来说，对于我们计算机类的学生，数据结构与算法是非常重要的，对于五个模块是需要认真学习掌握的：查找、排序、树、图、动态规划，附加数据库等一些。在我之前的学习中，完全没有涉及动态规划方向的问题，因此只能重新学习了。 对于计算机网络、操作系统等，需要对于基础知识做一遍的总结归纳。然后多次记忆。避免自己忘记。通过牛客网刷题，巩固自己的记忆，以及对于一些没有复习到的知识点作完善。争取对于所有的刷题，也至少达到70%的正确率。 对于算法上的复习是，最消耗时间的。我虽然之前看了算法，但又通过《剑指Offer》对于基本的题思路全部熟练。然后又通过LeetCode一些算法题目的提升，后来就基本觉得那些笔试面试的基础算法等，都没那么困难了，像曾有一个面试官，问我觉得那笔试题怎么样，我随口就回了一句挺简单的，想来是没有回答好，但这个是我的坦诚吧。LeetCode上面的题目，总体而言，难度更高一些。花费的时间也较多一些，但是想通的题目多了后，可以提高自己的思维能力，解决问题的能力。 总体而言，我对于秋招的准备就是对于基础的复习，对于知识点的查缺补漏。 最后需要准备的一点是，对于面试时候，面试官最后一般会问你，“还有什么问题没有”。所以需要提前准备一些问题。我一般喜欢了解一下公司，岗位职责等，培养方式等。有的经历过宣讲会，就基本没啥问题了。 招聘中在校招中，会经历一段一两个月的高密度的校招，秋招时间相对于春招来说比较长一些。 招聘信息的来源，有学校官网、学院官网、其他学校的官网、牛客网等众多，需要自己整理，自己分辨信息的真实性。 简历，这个需要准备好。尤其对于本科生来说，没有像研究生那样有许多的项目经历等可以写，因此需要精心设计简历。本科生一般简历都是一页，因为一页能够写下。所以需要将重要的信息放在一页纸的中心位置，那个位置是视觉的聚焦点。我在简历的时候，觉得我能够拿出手的就实习与项目经历，并且我认为那部分对于公司来说应该更加看重一些。因此将这两部分放在了重心位置。 秋招里。简历投递，我也基本是海投。但是本身我也是有自己的筛选，并不是所有的公司我都投递了。根据自己的兴趣爱好，以及自己对于公司的看法投简历。当然，没拿到一个offer的时候，胡乱投递也是很正常的。 在笔试的时候一般会对于自己的投递有一个筛选，笔试冲突的时候，就看自己觉得是选择自己更加爱好的或者更加有把握的，按照自己的标准去放弃。 在投递开始时，最好建一个表格来记录目前投递的公司，以及笔试面试的进度，或者笔试面试时间等。不要过分相信自己的记忆能力，当简历投递得过多的时候，很容易是，弄乱的。 日历是一个很好的记事器。通过手机日历设置提醒每天要做那些事，完成哪些笔试，去面试哪些公司，地址在哪儿等。通过日历的提醒，可以办到自己忘记不了。 面试需要带好简历、笔、成绩单、身份证、学生证等。 面试中，礼貌、礼貌、礼貌很重要，重要的事说三遍。 还有一点，不知道的东西，要果断，说不知道，当然可以说自己的思路，想法，展示自己的思维能力。但是千万不要遮遮掩掩。我曾旁听了一个面试，那个同学面试时，对自己不知道的东西总是遮遮掩掩。最后，他请教面试官指点一下他面试中的问题。面试官很直接就说，“我建议你以后面试中，不知道的东西，最好直接说不知道，不要遮遮掩掩，这样才能够表现出，你所表现的知道的东西更加有信服力”。 关于手里的offer筛选，这个没有建议了。只是若是要拒掉一个offer最好是，客客气气的发一封邮件，礼貌有加。 本人秋招的一些看法其实在秋招中，面试应该是相对的，虽然表现出来的是公司在面试你，其实你也在面试公司，通过公司招聘中的进度、效率，以及面试过程中的严谨程度等。我在面试完后，基本都把我自己认为面试过程中比较“水”的公司筛选掉了。因此这个是一个双向的筛选过程。 第二点是，不要惧怕和研究生竞争，我一直想表现的就是本科生并不比研究生差。对自己要有信心。虽然他们多了三年的经历，在项目以及基础上可能要好得多，但是我们年轻，相信自己的学习能力并不比他们差。 当然，找工作中，安全还是很重要的，你若没有投递过的公司发信息让你去面试等，这种都是骗局。还有注意公司信息的真实性等，对自己的未来负责。面试地址，注意偏僻地区千万别去，不要认为传销离自己很远，有可能是一里之隔。 找工作当然苦了，当然有失落等。学会调节自己的心理，我想公司不会想要一个没有自控能力的人吧。 当自己面试多了，自然也就习惯了。我第一次面试的时候，也是非常紧张的，而且基础知识等都没有复习完全。紧张一次后，自然后来都不紧张了。 还有一点是，并不是自己面试的东西就应该是自己所擅长的。重点是表现自己的思维以及基础。我偏向于Java语言，基本没有C++项目经验，我曾去面过了一个C++的岗位，语言并不重要，当然至少得懂这门语言的核心思维。面试官一般会从你的简历上写的来了解，什么写精通等，应届生就别想通过了。 笔试面试完，应该从自己的缺陷中去查缺补漏。有时候，可能关于多进程多线程等，锁等有些知识点不清楚，下来就应该快速学习或者复习。 附总之，工作，说好找，也是很好找的，说难找，也难找的。只要你准备好了，就应该能够找到一份不后悔的工作。]]></content>
      <categories>
        <category>Other</category>
      </categories>
      <tags>
        <tag>Other</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决Java API @since 版本错误问题]]></title>
    <url>%2F2018%2F01%2F08%2F%E8%A7%A3%E5%86%B3Java-API-since-%E7%89%88%E6%9C%AC%E9%94%99%E8%AF%AF%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[在我们的项目开发过程中，常常出现Java版本过低，以导致语法中出现错误的情况，这种情况中我们通常都是比较明了的知道需要提到Java的版本。 安装的Java版本过低这种情况下需要我们重新安装最新版本的Java即可。 IDE中设置的Java版本过低比如在IDEA中，通过command + ; 快捷键进入项目结构中可以看到如下图项目结构中的一些信息。（注：快捷键需要是英文键） 在红色框位置可以选择支持的Java版本。 当然，在Modules里面也可以选择支持的Java语言版本。 IDEA自动重置LanguageLevel和JavaCompiler版本如下图发生错误相同，每次都会引入项目，或者开启项目时，都会使得Java版本过低的情况。并且package后也是支持低版本的Java，会引发较大的语法问题。 这个问题虽然可以每次在开发过程中手动调节版本，使得开发过程没有错误。但是不支持所有环境，即打包做出支持库等会出现语法问题，因此需要解决。 解决方法是，在Maven中引入maven-compiler-plugin，并指定版本。示例如下 12345678910&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.3&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt;&lt;/plugin&gt;]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于HLS直播流HTML页面播放解决]]></title>
    <url>%2F2017%2F11%2F09%2F%E5%85%B3%E4%BA%8EHLS%E7%9B%B4%E6%92%AD%E6%B5%81HTML%E9%A1%B5%E9%9D%A2%E6%92%AD%E6%94%BE%E8%A7%A3%E5%86%B3%2F</url>
    <content type="text"><![CDATA[在最近的项目开发中，涉及了HLS直播音频流的播放，关于网上的资料较多，各种混杂，因此对此在问题解决尝试以及结果进行总结。 最终解决方案使用百度播放器，通过API，自己写想要的播放器组件。 什么是HLS首先，什么是HLS？ HTTP Live Streaming（缩写是HLS）是一个由苹果公司提出的基于HTTP的流媒体网络传输协议。是苹果公司QuickTime X和iPhone软件系统的一部分。它的工作原理是把整个流分成一个个小的基于HTTP的文件来下载，每次只下载一些。当媒体流正在播放时，客户端可以选择从许多不同的备用源中以不同的速率下载同样的资源，允许流媒体会话适应不同的数据速率。在开始一个流媒体会话时，客户端会下载一个包含元数据的extended M3U (m3u8)playlist文件，用于寻找可用的媒体流。 HLS只请求基本的HTTP报文，与实时传输协议（RTP）不同，HLS可以穿过任何允许HTTP数据通过的防火墙或者代理服务器。它也很容易使用内容分发网络来传输媒体流。 —— 摘自维基百科 由于是HLS技术是苹果公司提出的，虽然在该协议的推广上也是作出了许多贡献，但是也是有很多浏览器依然不支持或者不完全支持该协议。 如何实现页面的直播流播放呢？对于直播流方案，我做了几种解决尝试 方案一：使用video标签首先，video标签是HTML 5中的新标签，用于嵌入视频元素。而目前，video标签只支持MP4、WebM、Ogg等格式。 或许，很疑惑，为什么要用视频元素标签来嵌入音频？对于我们这儿直播流的情况下，一般音频标签目前不能够解决。而使用视频元素标签来嵌入直播音频流。 既然这儿video标签不支持m3u8的HLS直播流格式，那是不是我这儿说错了？肯定不是。接下来需要借助一些其他开源项目来解决。 我们在这儿的解决都是基于video.js的一些衍生开源项目解决。 首先是第一种直接使用video.js测试。 123456789101112131415161718192021222324&lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;utf-8&quot; /&gt; &lt;title&gt;Player&lt;/title&gt; &lt;link href=&quot;https://unpkg.com/video.js/dist/video-js.css&quot; rel=&quot;stylesheet&quot;&gt; &lt;/head&gt; &lt;body&gt; &lt;video id=&quot;video&quot; class=&quot;video-js vjs-default-skin&quot; controls preload=&quot;none&quot; data-setup=&apos;&#123;&#125;&apos;&gt; &lt;source src=&quot;living.url&quot; type=&quot;application/x-mpegURL&quot;&gt; &lt;/video&gt; &lt;script src=&quot;js/video.js&quot;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot;&gt; var player = videojs(&apos;video&apos;); player.ready(function() &#123; var myPlayer = this; myPlayer.src(url); myPlayer.load(url); myPlayer.play(); &#125;); &lt;/script&gt; &lt;/body&gt;&lt;/html&gt; 使用Safari浏览器测试如下 然后，也可以使用videojs-contrib-hls项目解决，测试代码示例如下： 1234567891011121314151617&lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;utf-8&quot; /&gt; &lt;title&gt;Player&lt;/title&gt; &lt;link href=&quot;https://unpkg.com/video.js/dist/video-js.css&quot; rel=&quot;stylesheet&quot;&gt; &lt;/head&gt; &lt;body&gt; &lt;video id=&quot;video&quot; class=&quot;video-js vjs-default-skin&quot; controls autoplay=&quot;autoplay&quot; width=&quot;640&quot; height=&quot;320&quot; data-setup=&apos;&#123;&#125;&apos;&gt; &lt;source src=&quot;living.url&quot; type=&quot;application/x-mpegURL&quot; /&gt; &lt;/video&gt; &lt;script src=&quot;https://unpkg.com/video.js/dist/video.js&quot;&gt;&lt;/script&gt; &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/videojs-contrib-hls/5.12.1/videojs-contrib-hls.min.js&quot;&gt;&lt;/script&gt; &lt;/body&gt;&lt;/html&gt; ️注意：在这儿使用的js等资源皆是在线的一些支持。若需要在项目中使用，最好下载到本地使用。 这儿的测试结果，是对于mac上所有浏览器的一般m3u8视频流（即非直播）都支持，都能够播放。直播流仅持safari、edge、android，其他浏览器会出现错误。 方案二：基于clappr由于第一种方案，只能够部分解决HLS流播放的问题，且未解决直播流播放的浏览器兼容问题。因此需要继续寻找新的解决方案。 这个方案是基于github上clappr的开源项目解决。 1234567891011121314151617181920&lt;html&gt; &lt;head&gt; &lt;title&gt;test&lt;/title&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;https://cdn.jsdelivr.net/npm/clappr@latest/dist/clappr.min.js&quot;&gt;&lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;div id=&quot;player-wrapper&quot;&gt;&lt;/div&gt; &lt;script&gt; var playerElement = document.getElementById(&quot;player-wrapper&quot;); var player = new Clappr.Player(&#123; source: &apos;m3u8.url&apos;, mute: true, height: 360, width: 640 &#125;); player.attachTo(playerElement); &lt;/script&gt; &lt;/body&gt;&lt;/html&gt; 通过测试，发现该方案对于m3u8的视频格式支持播放，但是对于直播流却不支持。 方案三：基于ChPlayer在查询资料中发现，chplayer是网页视频播放器，支持mp4,flv,f4v以及m3u8格式，支持rtmp。支持点播和直播。因此决定使用这个尝试。 首先将项目下载到本地，然后使用页面测试。 12345678910111213141516171819&lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;test&lt;/title&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;chplayer/chplayer.min.js&quot;&gt;&lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;dev id=&apos;video&apos;&gt;&lt;/dev&gt; &lt;script type=&quot;text/javascript&quot;&gt; var videoObject = &#123; container: &apos;#video&apos;, //“#”代表容器的ID，“.”或“”代表容器的class variable: &apos;player&apos;, //该属性必需设置，值等于下面的new chplayer()的对象 video: &apos;living.url&apos; //视频地址 &#125;; var player = new chplayer(videoObject); &lt;/script&gt; &lt;/body&gt;&lt;/html&gt; 通过这种方式测试，结果是能够解决直播流问题，并且主流浏览器都是兼容的。因此在我们的项目中决定使用这种方式解决问题。 方案四：使用hls.js目前官方给出兼容情况如下： 方案五：使用cyberPlayer该方式目前基本兼容常用浏览器，我测试的使用基本兼容。在该方式下，通过自己编写播放器按钮等组件可以基本解决该播放问题。但是在这个情况下，需要考虑当播放器出错时，如何屏蔽掉页面中展示的错误信息。 附虽然使用chplayer已经能够解决这个问题，但是在后面的查询资料中发现FFmpeg，可以解决支持直播音频的播放以及所有解码等，虽然不仅限于该领域。后面可以借助其源码学习并解决音频领域的问题。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>HLS</tag>
        <tag>Js</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac上VPN 连接不上常用解决方案]]></title>
    <url>%2F2017%2F07%2F21%2FMac%E4%B8%8AVPN-%E8%BF%9E%E6%8E%A5%E4%B8%8D%E4%B8%8A%E5%B8%B8%E7%94%A8%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[在工作中常常使用VPN，但是也常常出现VPN连接不上的情况，对于这种情况我们常常是深恶痛绝，花掉半天的时间也没解决，因此在这儿给出我自己的常用解决方案，一般按照着方案1、2、3的顺序执行，通常情况下都是解决的了。 方案1尝试着删除掉我们所配置的VPN，然后重新配置，尝试连接。 方案2这是大家常见的方案，在 /etc/ppp下的options文件中写入以下代码 12plugin L2TP.pppl2tpnoipsec 然后重新连接。 具体的操作步骤如下： 在终端中输入 sudo vim /etc/ppp/options，可能需要密码； 在文件中输入i进入insert方式，然后输入上诉代码，然后按esc，输入:wq，回车保存； 尝试着重新连接或删除掉旧配置重新连接； 方案3如果上述方案都不能够奏效，那么尝试第三种方案。此方案只能在方案2不奏效的情况下使用 删除/etc/ppp/options文件，即在终端执行sudo rm -rf /etc/ppp/options； 删除VPN的配置重新配置，连接。这儿一定要删除配置重新配置（至于为什么，我也不清楚，反正不重新配置一般是不能成功的） 一般情况下，按照这三种方案的顺序执行后都是能够成功访问了。 附若本文中未总结的相关解决方案，欢迎补充。]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>VPN</tag>
        <tag>Mac OX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MyBatis初解]]></title>
    <url>%2F2017%2F06%2F09%2FMyBatis%E5%88%9D%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[MyBatis是一种半自动映射的框架。是目前较为流行的Java ORM框架。（ORM模型是指数据库的表与Java的POJO的映射关系模型，解决之间的相互映射。）本文主要是我在学习了《深入浅出MyBatis技术原理与实战》后的自我总结。 配置123456789101112131415161718192021222324252627282930&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE configuration PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;&lt;configuration&gt; &lt;settings&gt; &lt;!-- 全局映射器启用缓存 --&gt; &lt;setting name=&quot;cacheEnabled&quot; value=&quot;true&quot;/&gt; &lt;!-- 全局延时加载 --&gt; &lt;setting name=&quot;lazyLoadingEnabled&quot; value=&quot;true&quot;/&gt; &lt;!-- 不对带有延时加载属性的对象完全加载 --&gt; &lt;setting name=&quot;aggressiveLazyLoading&quot; value=&quot;false&quot;/&gt; &lt;!-- 对单一SQL允许返回多结果集 --&gt; &lt;setting name=&quot;multipleResultSetsEnabled&quot; value=&quot;true&quot;/&gt; &lt;!-- 允许使用列标签代替列名 --&gt; &lt;setting name=&quot;useColumnLabel&quot; value=&quot;true&quot;/&gt; &lt;!-- 允许使用自定义的主键值(比如由程序生成的UUID 32位编码作为键值)，数据表的PK生成策略将被覆盖 --&gt; &lt;setting name=&quot;useGeneratedKeys&quot; value=&quot;true&quot;/&gt; &lt;!-- 自动映射任意复杂的结果集 --&gt; &lt;setting name=&quot;autoMappingBehavior&quot; value=&quot;FULL&quot;/&gt; &lt;!-- 简单执行器 --&gt; &lt;setting name=&quot;defaultExecutorType&quot; value=&quot;SIMPLE&quot;/&gt; &lt;!-- 数据库超过25000秒仍未响应则超时 --&gt; &lt;setting name=&quot;defaultStatementTimeout&quot; value=&quot;25000&quot;/&gt; &lt;!-- 配置使用log4j记录日志--&gt; &lt;setting name=&quot;logImpl&quot; value=&quot;log4j&quot;/&gt; &lt;!-- 自动转换驼峰命名 --&gt; &lt;setting name=&quot;mapUnderscoreToCamelCase&quot; value=&quot;true&quot;/&gt; &lt;/settings&gt;&lt;/configuration&gt; 这是简单Mybatis的设置。依然还有许多属性我们没有提到。在我们的设置中，autoMappingBehavior是有三种设置：NONE（取消自动映射）、PARTIAL（只会映射没有定义嵌套结果集映射的结果集，在缺省配置的情况下默认）、FULL；而defaultExecutorType表示执行器executor类型，分为三种：SIMPLE（普通执行器，默认情况下是SIMPLE）、REUSE（执行器会重用预处理语句prepared statements）、BATCH（执行器会重用语句并执行批量更新）。 在configuration中还会涉及其他属性，常用的有typeAliases（类型命名）、typeHandler（类型处理器）、plugins（插件）等。而对于typeHandler的配置里，又有javaType与jdbcType，typeHandler就是解决其转换的问题。 MyBatis-Spring一般情况下，我们大多数情况下是在Spring中使用MyBatis，即需要配置MyBatis-Spring。分为五步进行配置： 配置数据源 配置SqlSessionFactory 配置SqlSessionTemple（使用Mapper接口编程方式，这儿的配置就隐藏了） 配置Mapper 事务处理 先配置数据源。 123456789101112131415161718192021222324&lt;bean id=&quot;dataSource&quot; class=&quot;com.alibaba.druid.pool.DruidDataSource&quot; init-method=&quot;init&quot; destroy-method=&quot;close&quot;&gt; &lt;property name=&quot;url&quot; value=&quot;#&#123;jdbc[&apos;jdbc.url&apos;]&#125;&quot;/&gt; &lt;property name=&quot;username&quot; value=&quot;#&#123;jdbc[&apos;jdbc.username&apos;]&#125;&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;#&#123;jdbc[&apos;jdbc.password&apos;]&#125;&quot;/&gt; &lt;!-- 配置初始化大小、最小、最大 --&gt; &lt;property name=&quot;minIdle&quot; value=&quot;#&#123;jdbc[&apos;ds.minIdle&apos;]&#125;&quot;/&gt; &lt;property name=&quot;maxActive&quot; value=&quot;#&#123;jdbc[&apos;ds.maxActive&apos;]&#125;&quot;/&gt; &lt;property name=&quot;initialSize&quot; value=&quot;#&#123;jdbc[&apos;ds.initialSize&apos;]&#125;&quot;/&gt; &lt;!-- 配置获取连接等待超时的时间 --&gt; &lt;property name=&quot;maxWait&quot; value=&quot;#&#123;jdbc[&apos;ds.maxWait&apos;]&#125;&quot;/&gt; &lt;!-- 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒 --&gt; &lt;property name=&quot;timeBetweenEvictionRunsMillis&quot; value=&quot;#&#123;jdbc[&apos;ds.timeBetweenEvictionRunsMillis&apos;]&#125;&quot;/&gt; &lt;!-- 配置一个连接在池中最小生存的时间，单位是毫秒 --&gt; &lt;property name=&quot;minEvictableIdleTimeMillis&quot; value=&quot;#&#123;jdbc[&apos;ds.minEvictableIdleTimeMillis&apos;]&#125;&quot;/&gt; &lt;property name=&quot;validationQuery&quot; value=&quot;SELECT 1&quot;/&gt; &lt;property name=&quot;testWhileIdle&quot; value=&quot;true&quot;/&gt; &lt;property name=&quot;testOnBorrow&quot; value=&quot;false&quot;/&gt; &lt;property name=&quot;testOnReturn&quot; value=&quot;false&quot;/&gt; &lt;!-- 打开PSCache，并且指定每个连接上PSCache的大小 --&gt; &lt;property name=&quot;poolPreparedStatements&quot; value=&quot;false&quot;/&gt; &lt;property name=&quot;maxPoolPreparedStatementPerConnectionSize&quot; value=&quot;20&quot;/&gt; &lt;!-- 配置监控统计拦截的filters --&gt; &lt;property name=&quot;filters&quot; value=&quot;stat&quot;/&gt;&lt;/bean&gt; 这儿我们使用的Druid数据源。接下来配置SqlSessionFactory。 1234567891011121314151617&lt;bean id=&quot;sqlSessionFactory&quot; class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt; &lt;!-- 主配置文件 --&gt; &lt;property name=&quot;configLocation&quot; value=&quot;classpath:/mybatis-config.xml&quot;/&gt; &lt;!-- 自动扫描sqlmap目录下的所有SQL映射的xml文件 --&gt; &lt;property name=&quot;mapperLocations&quot; value=&quot;classpath:mappers/*.xml&quot;/&gt; &lt;!-- 自动注册javabean别名 默认会使用javabean的首字母小写的非限定类名来作为它的别名--&gt; &lt;property name=&quot;typeAliasesPackage&quot; value=&quot;fei.self.model&quot;/&gt; &lt;/bean&gt;&lt;!-- spring与mybatis整合配置，扫描所有dao --&gt; &lt;bean class=&quot;org.mybatis.spring.mapper.MapperScannerConfigurer&quot;&gt; &lt;!-- 扫描基本包路径下的所有映射器接口类 采用分号或者逗号分隔 可设置多个包路径 --&gt; &lt;property name=&quot;basePackage&quot; value=&quot;com.ximalaya.ops.fei.self.dao&quot;/&gt; &lt;!--多个数据源 可设置具体的sqlSessionFactoryBean 单个数据源不必配置--&gt; &lt;property name=&quot;sqlSessionFactoryBeanName&quot; value=&quot;sqlSessionFactory&quot;/&gt; &lt;/bean&gt; 这儿的mybatis-config.xml就是我们之前的configuration以及setting的那个文件。并且在这儿，我们配置了自动扫描信息，包括扫描所有的DAO以及Mapper文件。接下来只剩下事务处理的配置了。 1234567891011121314151617181920212223&lt;!-- 对dataSource 数据源进行事务管理 --&gt;&lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot; p:dataSource-ref=&quot;dataSource&quot;/&gt;&lt;!-- 事务管理 通知 --&gt;&lt;tx:advice id=&quot;txAdvice&quot; transaction-manager=&quot;transactionManager&quot;&gt; &lt;tx:attributes&gt; &lt;!-- 对insert,update,delete 开头的方法进行事务管理,只要有异常就回滚 --&gt; &lt;tx:method name=&quot;insert*&quot; propagation=&quot;REQUIRED&quot; rollback-for=&quot;java.lang.Throwable&quot;/&gt; &lt;tx:method name=&quot;update*&quot; propagation=&quot;REQUIRED&quot; rollback-for=&quot;java.lang.Throwable&quot;/&gt; &lt;tx:method name=&quot;delete*&quot; propagation=&quot;REQUIRED&quot; rollback-for=&quot;java.lang.Throwable&quot;/&gt; &lt;tx:method name=&quot;reset*&quot; propagation=&quot;REQUIRED&quot; rollback-for=&quot;java.lang.Throwable&quot;/&gt; &lt;tx:method name=&quot;getExecution*&quot; propagation=&quot;REQUIRED&quot; rollback-for=&quot;java.lang.Throwable&quot;/&gt; &lt;!-- select,count开头的方法,开启只读,提高数据库访问性能 --&gt; &lt;tx:method name=&quot;select*&quot; read-only=&quot;true&quot;/&gt; &lt;tx:method name=&quot;count*&quot; read-only=&quot;true&quot;/&gt; &lt;!-- 对其他方法 使用默认的事务管理 --&gt; &lt;tx:method name=&quot;*&quot;/&gt; &lt;/tx:attributes&gt;&lt;/tx:advice&gt;&lt;!-- 启用对事务注解的支持 --&gt;&lt;tx:annotation-driven transaction-manager=&quot;transactionManager&quot;/&gt; 这是最基础的MyBatis-Spring的配置。这部分其实挺无趣的，个人觉得MyBatis最有趣的就是接下来的MyBatis的技术原理以及插件等。关于Mapper的一些在这儿不作罗列了。 动态SQL所谓动态SQL，指的是一些特殊的MyBatis标签的使用，从而对于SQL的拼装具有动态性的效果。主要是if、choose、trim、foreach以及bind元素这些。这部分其实挺有趣的，可以增加我们对于MyBatis的掌握。这部分的知识在这儿不作罗列，看一些例子都能明白。 MyBatis原理终于到了重点且有趣的地方，这部分知识可以帮助我们理解MyBatis，然后能写一些好用的插件。 在学习之前需要掌握动态代理，分为JDK动态代理与CGLIB动态代理。 首先，需要构建SqlSessionFactory。第一步，先通过XMLConfigBuilder解析配置文件，存入Configuration类中（这个类里基本保存了所有的配置）。第二步，使用Configuration去构建SqlSessionFactory。对于SqlSessionFactory，这是一个接口，在一般MyBatis中用DefaultSqlSessionFactory的实现类，对于接口的方法都做了实现。 第二个需要掌握的是Mapper映射器。我们提到过，在Configuration中，有所有的配置，当然映射器也在里面。需要了解的是，Mapper映射是通过动态代理的方式实现的。一般映射器里面包含有三部分：MappedStatement：用户保存映射节点；SqlSource：这是MappedStatement的一个属性，一个接口，主要是根据参数和其他规则组装SQL，当然它提供BoundSql；BoundSql：建立SQL和参数的地方。我们一般修改SQL或者参数都是在BoundSql中修改的。对于BoundSql中如何实现多种参数的注入方式，我这儿就不讲解了。 既然有了SqlSessionFactory，那么我们很容易就得到SqlSession了。从Mapper映射器中，我们通过代理对象会进入到MapperMethod的execute方法。然后就能进入SqlSession的方法里了。我们需要了解的是SqlSession里的增删改查方法是如何实现的。 首先SqlSession下有四大对象。1、Executor执行器：用来调度StatementHandler、ParameterHandler、ResultHandler；2、StatementHandler：这个是在SqlSession里最重要的部分，它可以使数据库的Statement，即PreparedStatement执行操作（PreparedStatement接口是继承了Statement接口）；3、ParamentHandler：用于SQL的参数处理；4、ResultHandler：用于最后返回数据集的封装。我学到这儿很疑惑这个Satement究竟是什么？Statement 对象用于执行不带参数的简单 SQL 语句；PreparedStatement 对象用于执行带或不带 IN 参数的预编译 SQL 语句；CallableStatement 对象用于执行对数据库已存在的存储过程的调用。我们一般在插件中使用的是PrepareStatement，这三者对应了三种数据库会话器，SimpleStatementHandler、PrepareStatementHandler、CallableStatementHandler。对于着Executor也分为三种SIMPLE、REUSE、BATCH。关于参数处理器以及结果处理器就不提及了。 插件插件部分，我无法总结清晰，所以给出我的分页插件中重点intercept函数实现的基本流程图。 附本文主要是个人的一些总结，没有完全梳理MyBatis的流程等，也没有完全涉及MyBatis的所有知识。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>MyBatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SCC算法初解]]></title>
    <url>%2F2017%2F05%2F19%2FSCC%E7%AE%97%E6%B3%95%E5%88%9D%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[在算法学习之路上漂泊，遇见了图，而分无向与有向。在本文中主要讲解关于有向图中的求极大连通分量的算法，主要是Kasaraju算法、Tarjan算法以及Gabow算法。 三种算法都是基于深度优先搜索算法（DFS）而实现的，实际上后两种算法是对于Kasaraju算法的改进，减少了一次深度优先搜索（DFS），因此在性能上相比较而言要好一些。 初识强连通分量首先，连通分量是无向图G的一个极大连通子图称为G的一个连通分量（或连通分支）。连通图只有一个连通分量，即其自身；非连通的无向图有多个连通分量。 强连通图指每一个顶点皆可以经由该图上的边抵达其他的每一个点的有向图。意即对于此图上每一个点对(Va,Vb)，皆存在路径Va→Vb以及Vb→Va。强连通分量则是指一张有向图G的极大强连通子图G’。如果将每一个强连通分量缩成一个点，则原图G将会变成一张有向无环图。一张图被称为有向无环图当且仅当此图不具有点集合数量大于一的强连通分量，因为有向环即是一个强连通分量，而且任何的强连通分量皆具有至少一个有向环。（摘自维基百科） 对于无向图，求连通分量的问题就等价于求是否连通的问题，使用深度优先、广度优先搜索的算法的到的树都能求出最大连通分量。 Kasaraju算法Kasaraju算法在我第一次接触时，感觉确实有点难理解，虽然现在也还是有点难理解。本文中不会去证明算法，只是讲解算法的一些实现等。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677public static class KosarajuSCC &#123; int n; List&lt;Integer&gt;[] adj; KosarajuSCC(int n) &#123; this.n = n; this.adj = new ArrayList[n]; for (int i = 0; i &lt; n; i++) &#123; this.adj[i] = new ArrayList&lt;&gt;(); &#125; &#125; public void addEdge(int v, int w) &#123; this.adj[v].add(w); &#125; //正向遍历，以后根序压栈，保证根先出栈 public void fillorder(int v, boolean[] visited, Stack&lt;Integer&gt; s) &#123; visited[v] = true; for (Integer i : this.adj[v]) &#123; if (!visited[i]) &#123; fillorder(i, visited, s); &#125; &#125; s.push(v); &#125; //reverse 得到反向图 public KosarajuSCC getTranspose() &#123; KosarajuSCC gv = new KosarajuSCC(this.n); for (int i = 0; i &lt; n; i++) &#123; for (Integer j : this.adj[i]) &#123; gv.adj[j].add(i); &#125; &#125; return gv; &#125; //DFS打印连通分支 public void DFSUtil(int v, boolean[] visited) &#123; visited[v] = true; System.out.print(v + &quot; &quot;); for (Integer i : adj[v]) &#123; if (!visited[i]) &#123; DFSUtil(i, visited); &#125; &#125; &#125; //按照Kosaraju算法的步骤执行 public void printSCCs() &#123; Stack&lt;Integer&gt; s = new Stack&lt;Integer&gt;(); boolean[] visited = new boolean[this.n]; for (int i = 0; i &lt; n; i++) &#123; visited[i] = false; &#125; //逆后序压栈 for (int i = 0; i &lt; n; i++) &#123; if (!visited[i]) &#123; fillorder(i, visited, s); &#125; &#125; //得到反向图 KosarajuSCC gr = this.getTranspose(); for (int i = 0; i &lt; n; i++) &#123; visited[i] = false; &#125; //依据反向图算可达性 while (!s.empty()) &#123; int v = s.pop(); if (visited[v] == false) &#123; gr.DFSUtil(v, visited); System.out.println(); &#125; &#125; &#125;&#125; 先理解一下Karasaju算法的思路。 对图G求其逆后序，即在深度优先遍历（DFS）中在递归调用之后压入栈中； 对G进行转置，在代码中即得到反图； 按照第一步中得到的栈的出栈的顶点顺序，对于GR图进行DFS可以得到若干搜索树。每棵搜索树都代表一个强连通分量。 如上图示例的有向图，先求逆后序排序，得到{7, 8, 6, 9, 11, 10, 12, 0, 5, 4, 2, 3, 1}，然后按照这个图的转置图GR进行DFS，最终可以得到极大强连通分量5个：{7, 8}, {6}, {9, 11, 10, 12}, {0, 5, 4, 2, 3}, {1}。 在Karasaju算法中使用了两次DFS，第一次是得到节点的逆后序排序（有的算法书将逆后序排序合并在拓扑排序里面）；第二次是对于转置图DFS得到最终的强连通分量。我们当然想要对于算法进行优化，减少DFS的次数也是一种极好的优化方式，想想如果一次DFS就可以得出强连通分量岂不是很好。 Tarjan算法Tarjan算法是对于Kasaraju算法的改进。其基本代码实现思维如下： 遍历一个点，指定唯一时间戳DFN[i]；指定改点向前追溯可追溯到最老时间戳LOW[i]； 枚举当前点的所有边，若DFN[j]=0表明未被搜索过（这儿0、-1等都是可以的，只要是自我约定好的，正常不使用的就可以，如下面算法中使用的NO_VISIT），递归搜索； 当DFN[i]不为0，则j被搜索过，这时判断是否在我们存储新建的栈中，且j的时间戳DFN[j]小于当前时间戳DFN[i]，可判定成环，将LOW[i]设定为DFN[j]； 若这个点LOW[i]和DFN[i]相等，则这个点是目前强连通分量的元素中在栈中的最早的节点； 出栈，将这个强连通分量全部弹出，保存。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public static class TarjanSCC &#123; private int numOfNode; private List&lt;ArrayList&lt;Integer&gt;&gt; graph;//二维数组表示图 private List&lt;ArrayList&lt;Integer&gt;&gt; result;//保存极大强连通图 private boolean[] inStack;//标记节点是否在栈内 private Stack&lt;Integer&gt; stack; private int[] dfn; private int[] low; private int time;//当前时间戳（实际是一个int的数，标记当前访问的节点） private static final int NO_VISIT = 0; public TarjanSCC(List&lt;ArrayList&lt;Integer&gt;&gt; graph, int numOfNode) &#123; this.graph = graph; this.numOfNode = numOfNode; this.inStack = new boolean[numOfNode]; this.stack = new Stack&lt;Integer&gt;(); dfn = new int[numOfNode]; low = new int[numOfNode]; Arrays.fill(dfn, NO_VISIT);//将dfn所有元素都置为0，代表i还有没被访问过。 Arrays.fill(low, NO_VISIT); result = new ArrayList&lt;ArrayList&lt;Integer&gt;&gt;(); &#125; //获取强连通分量 public List&lt;ArrayList&lt;Integer&gt;&gt; tarjanResult() &#123; for (int i = 0; i &lt; numOfNode; i++) &#123; if (dfn[i] == NO_VISIT) &#123; tarjan(i); &#125; &#125; return result; &#125; //算法核心 public void tarjan(int current) &#123; dfn[current] = low[current] = time++; inStack[current] = true; stack.push(current); for (int i = 0; i &lt; graph.get(current).size(); i++) &#123; int next = graph.get(current).get(i); if (dfn[next] == NO_VISIT) &#123; tarjan(next); low[current] = Math.min(low[current], low[next]); &#125; else if (inStack[next]) &#123; low[current] = Math.min(low[current], dfn[next]); &#125; &#125; if (low[current] == dfn[current]) &#123; ArrayList&lt;Integer&gt; temp = new ArrayList&lt;Integer&gt;(); int j = -1; while (current != j) &#123; j = stack.pop(); inStack[j] = false; temp.add(j); &#125; result.add(temp); &#125; &#125;&#125; 需要注意的是在算法中的时间戳这个标记，并不是代表真正的时间戳，而是对于每个节点不同的一种标记，在本文算法中都是用一个递增数组来表示，即访问每个节点时，将该时间戳变量自增赋值给该节点的时间戳DFN[i]。 Gabow算法Gabow算法在基础上与Tarjan算法相似，都是利用一次DFS算法实现。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public static class GabowSCC &#123; private int numOfNode; private List&lt;ArrayList&lt;Integer&gt;&gt; graph;//二维数组表示图 private List&lt;ArrayList&lt;Integer&gt;&gt; result;//保存极大强连通图 private Stack&lt;Integer&gt; path; private Stack&lt;Integer&gt; root; private int[] order; private int time;//当前时间戳（实际是一个int的数，标记当前访问的节点） private static final int NO_VISIT = -1; private int[] part; // 连通变量的标号； private int partNum = 0; public GabowSCC(List&lt;ArrayList&lt;Integer&gt;&gt; graph, int numOfNode) &#123; this.graph = graph; this.numOfNode = numOfNode; this.path = new Stack&lt;&gt;(); this.root = new Stack&lt;&gt;(); order = new int[numOfNode]; part = new int[numOfNode]; Arrays.fill(order, NO_VISIT); Arrays.fill(part, NO_VISIT); &#125; public int[] gabowResult() &#123; for (int i = 0; i &lt; numOfNode; i++) &#123; if (order[i] == NO_VISIT) &#123; gabow(i); &#125; &#125; return part; &#125; public void gabow(int v) &#123; order[v] = ++time; path.push(v); root.push(v); for (int i = 0; i &lt; graph.get(v).size(); i++) &#123; int next = graph.get(v).get(i); if (order[next] == NO_VISIT) &#123; gabow(next); &#125; else if (part[next] == NO_VISIT) &#123; while (order[root.peek()] &gt; order[next]) &#123; root.pop(); &#125; &#125; &#125; if (v == root.peek()) &#123; root.pop(); partNum++; int top; do &#123; top = path.peek(); part[top] = partNum; path.pop(); &#125; while (top != v); &#125; &#125;&#125; 其算法基本思路是： 在所有顶点中，找一个没有被访问的节点v，如果没有则完成； 记录v的访问顺序；将v压入堆栈path和root；如果v指向的邻接点，对应每个邻接点next：1、如果没有访问过，则以next为参数，递归到第二步；2、如果访问过，且没有确定它属于哪个强连通分量，弹出root栈中next之后（即之上）的所有顶点；3、如果root栈中的元素等于v，那么在part中记录顶点对应的强连通分量 递归返回 附本文只涉及算法的实现，没有设计算法的证明等，如有想法，请分享。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>Algo</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基础查找算法分析]]></title>
    <url>%2F2017%2F05%2F13%2F%E5%9F%BA%E7%A1%80%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[在之前学习了一些排序算法，得出了基础排序算法的总结。之后学习了一些查找算法，今天来对于基础的一些查找算法进行总结。 排序与查找是我们一般开发中最常用的算法。例如在开发中需要找出某个人的个人信息，就需要根据某个关键信息去查找。 顺序查找顺序查找是按照我们思维最通俗易懂的算法，就是依次去对比，得到相等的则查找成功。当然这种算法是十分低效的，但是它对于我们需要查找的数据源，没有任何要求，就如数组中数据是可以乱序的。 二分查找相似与之前排序算法的分治的思想，但是这种类似于分治的思想确实不同于分治。与分治得到有序结果相对应的是我们在查找的时候需要查找的数据源是有序的。 12345678910111213141516public int halfFind(Key key) &#123; int lo = 0, hi = N - 1; while (lo &lt;= hi) &#123; int mid = (lo + hi) / 2; int cmp = key.compareTo(keys[mid]); if (cmp &lt; 0) &#123; hi = mid - 1; &#125; else if (cmp &gt; 0) &#123; lo = mid + 1; &#125; else &#123; return mid; &#125; &#125; return lo;&#125; 上述代码是基于有序数组的二分查找算法简单实现，可以极大的减少比较次数，但是无法改变减少运行所需的时间，因为在查找源是无序的情况，将其排序成有序的情况也是需要一定运行时间的。二分查找的思想在很多查找算法里面都有体现，如插值查找、切波那锲查找、二叉查找数等都体现了这种思想。 二叉查找树二叉查找树也是使用了二分的思想，只是在数据存储时使用二叉树的存储方式，也是链表的方式。 12345678910public Value halfTreeFind(Key key) &#123; return get(root, key);&#125;private Value get(Node x, Key key) &#123; if (x == null) return null; int cmp = key.compareTo(x.key); if (cmp &lt; 0) return get(x.left, key); else if (cmp &gt; 0) return get(x.right, key); else return x.val;&#125; 在二叉查找树中，插入难度和查找是差不多的，运行时间主要取决于树的形状。而删除一个结点，是将其右子树中最小的结点上浮来替代。当然从其运行时间与树的形状相关，因此我们需要想办法使得树的形状基本趋于平衡，而使得效率最高。即平衡查找树。 平衡查找树由二叉查找树的缺点而推出平衡查找树，其中包括2-3查找树、红黑树等。 在一棵完美的2-3查找树中、所有空链接到根结点的距离都是相同的。其有两种结点、具有1个数和2个数的结点、即有2个子分支和3个子分支。在查找与插入的时候都需要分别考虑，虽然情况是有限的几种，但是我还是觉得有点繁琐。 而红黑树相比较像是对于2-3树的一种升级，用红的连接来替代3结点。但是我还是比较喜欢是结点标红的意思。对于红黑树的定义在之前的文章中体现过。红黑树在于查找、插入和删除上都是十分好的，所以在java1.8的HashMap中，满足某个特定条件时会将链表转化为红黑树。 对于红黑树，所有基于红黑树的符号表实现都能保证操作的运行时间为对数级别，当然范围查找除外。 散列表我第一次听说散列表的时候，对于散列的意思有点迷糊，搞不懂其与哈希表的关系。后来才明白散列表就是哈希表。 哈希表中，首先需要的是一个哈希算法，最常见的就是%，除留余数法。第二点是解决冲突，一般就是拉链法与线性探测法。对于开发地址散列表中，最简单的方法就是线性探测法。 至于对于散列表，我就不详解了，HashMap源码分析看完后都能基本明白。 附在查找算法中，普遍都是基于二分的思想进行优化的。类似于排序算法中基于分治的思想一样。虽然本文总结不够完善，但也基本理清我的思维。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>Algo</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[洗牌算法]]></title>
    <url>%2F2017%2F05%2F04%2F%E6%B4%97%E7%89%8C%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[第一次接触洗牌算法是在一次面试上，面试官要求我写出一个算法将一个1～100的有序数组打乱，不考虑性能，那次我想了许久，想到一种基于二叉排序的方式实现了随机洗牌，但是那个性能呢，惨不忍睹。后来详细学习排序算法的时候，发现为了保证快速排序的性能，需要在排序之前对排序的数组进行洗牌操作。 为什么不基于一般排序算法做洗牌？众所周知，一般排序算法在在性能上以快速排序最好吧，时间复杂度基本在N*logN，空间复杂度在logN，当然三切分快速排序更好一些。所有算法中空间复杂度最好时为1，这当然是最好的。详细见对于基础排序算法的简要总结。但是在排序算法中没有能够达到时间复杂度N的线性的。而在洗牌算法中，我们随便便能实现N的线性的时间复杂度，因此基于排序算法做洗牌不可取。 洗牌算法第一版初次想的是一个排列好的数组，再新建一个长度相等的数组，每次通过随机数，随机一个N以内的数作为下标将其添加到新数组，并将该随机下标与N为下标的数交换，当然N需要自减。在N开始的时候为数组长度减1的值（保证下标最大而不越界）。那么最后会形成一个任意数组在数组内的某一位置的概率都是1/N的随机数组。 12345678910public static Comparable[] Shuffle1(Comparable[] c) &#123; Comparable[] a = new Comparable[c.length]; int N = c.length - 1; for (int i = 0; i &lt; c.length; i++, N--) &#123; int ran = intRandom(0, N); a[i] = c[ran]; c[ran] = c[N]; &#125; return a; &#125; 这种算法相比较之前打算基于一般排序算法求解的方式，在时间复杂度上有了很大的提升。在时间复杂度上，这种算法保证了N次循环（N为数组长度），N次获取随机值，N次交换（但是有2N次数组元素赋值操作）实现了分部均匀的洗牌算法。但是它的缺点是需要另建数组，使得空间复杂度增加。 在算法中使用了随机数的intRandom函数如下 1234567private static int intRandom(int min, int max) &#123; if (min &gt; max) throw new IllegalArgumentException(&quot;min can not bigger than max&quot;); if (max == min) return max; return new Random().nextInt(max - min + 1) + min; &#125; 洗牌算法第二版为了减少空间复杂度，使得算法在原地进行洗牌操作，尝试着将算法改进。在本算法中使用随机生成一个下标，使得对应的数与第一个i个数交换（i会从0到N-1自增）。 123456789public static void Shuffle2(Comparable[] c) &#123; int N = c.length; for (int i = 0; i &lt; N; i++) &#123; Comparable mid = c[0]; int ran = intRandom(0, N-1); c[0] = c[ran]; c[ran] = mid; &#125; &#125; 当然在本算法中，空间复杂度是1，达到最小。而时间复杂度也没有很大升高，依然需要N次循环，N次随机，N次交换（但是有3N次赋值操作）。因为对于数组中的每个数都会进行同样的操作，不因为数组元素顺序等变化，因此对于任意一个数分布在某个位置的概率是相同的。所有这是目前我发现的最好的洗牌算法。 附本文仅讲述一些自我对于洗牌算法的一些了解以及自我的一些思考以及实现，在目前我的了解中，这两种洗牌算法是最好的了，如有更好，请指出，共同学习。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>Algo</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven基础总结]]></title>
    <url>%2F2017%2F05%2F03%2FMaven%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[鉴于最近基本看完《Maven实战》这本书，对于我自己的所看的结果作一下总结，理清自己的思路，并复习书中的知识。当然有时间会继续学习一下Gradle，似乎是一个更好的工具。 我原来对于Maven的印象就是依赖管理的工具，但是在认真学习之后，认识到Maven可以实现挺多实用功能。 自动化构建 依赖管理（提供中央仓库，能够帮我们自动下载构建） 项目信息管理 在Maven中最重要的思维莫过于约定优于配置。虽然在Maven中没有确定的文件定义一些要求，但是大家约定的一些写法等，保证了项目的移植性，当然也可以自定义，但是不推荐（因为你写了可能就自己看得懂了，别人都看不懂）。在Maven项目中默认的主代码目录为src/test/java，默认的测试代码目录为src/test/java。 Pom文件在平时开发中，感觉到pom.xml文件是Maven项目中最重要的一环，它提供了项目信息与依赖管理等。 首先，pom.xml文件中，包含一般XML文件头，指定xml文件版本以及编码方式等；接下来是project元素，包含相关的命名空间以及xsd元素等。 12345678910111213141516171819202122232425&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;groupId&gt;com.fei&lt;/groupId&gt; &lt;artifactId&gt;fei.empty.spring.web&lt;/artifactId&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;properties&gt; &lt;jetty.port&gt;8417&lt;/jetty.port&gt; &lt;spring.version&gt;4.2.0.RELEASE&lt;/spring.version&gt; &lt;mybatis.version&gt;3.3.1&lt;/mybatis.version&gt; &lt;slf4j.version&gt;2.6.2&lt;/slf4j.version&gt; &lt;log4j2.version&gt;2.6.2&lt;/log4j2.version&gt; &lt;/properties&gt; &lt;dependencyManagement&gt; &lt;/dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; ... 元素接下来重要的是groupId、artifactId、version元素，分别表示组（当前Maven项目隶属的实际项目）、唯一ID、版本。这个是Maven的坐标元素，基本可以确定一个项目，当然这三项是必须的，不管是在项目信息还是在依赖管理中，还有packaging、classifier分别表示打包方式和帮助定义构建输出的一些附属构建（ classifier是不能直接定义的，附属构建不是项目直接默认生成的，而是由附加的插件帮助生成）。例如在本例中因为是Javaweb项目，所以使用war的打包方式，在项目中如果不做声明，默认的是jar打包方式。这5个元素可以唯一的确定项目。 版本关于版本，分为发布版本和快照版本，在本例中的1.0-SNAPSHOT就是快照版本，快照版本是不稳定的。在Maven中版本号的约定是&lt;主版本&gt;.&lt;次版本&gt;.&lt;增量版本&gt;-&lt;里程碑版本&gt;。关于版本管理的一些本文不会涉及。 在配置的pom文件中提供了properties标签自定义。利用这个我们将所有的版本号集中在一起，方便更新、引用，以及减少一些版本号重复性。 依赖除了在项目信息中使用到了这些元素标签，还在依赖管理中使用，这是很必要的，需要用它们去确定一个Maven项目。在 dependencies里会有许多dependency来确定每个依赖。例如spring项目中一般会包含spring-core、spring-context、spring-context-support等都是Spring Framework实现依赖注入等功能必要的构建，都需要在项目中依赖。 在依赖的servlet中定义了scop标签，表示定义依赖的范围，那么provided是什么意思呢？在一般情况中，我们有6种依赖范围：1、compile：编译依赖范围，一般在缺省默认情况下也使用这个默认范围；2、test：测试依赖范围；3、provided：已提供依赖范围，表示对于编译和测试classpath有效，但是在运行的时候无效；4、runtime：运行时依赖范围，即测试和运行classpath有效；5、system：系统依赖范围，该依赖范围与三种classpath的关系与provided相同，但是在使用这个依赖范围时，必须通过systemPath元素显式地指定依赖文件的路径，在使用时会造成不可移植性；6、import：导入依赖范围，其实是继承父模版的依赖配置，继承依赖范围。 依赖范围（scop） 对于编译classpath有效 对于测试classpath有效 对于运行classpath有效 示例 compile Y Y Y spring-core test - Y - JUnit provided Y Y - servlet-api runtime - Y Y JDBC驱动实现 system Y Y - 类似于java的属性继承一样，Maven也具有传递性依赖，继承依赖范围关系如下，左一列为直接依赖，横一栏为间接依赖，内容表示最终依赖范围。 compile test provided runtime compile compile - - runtime test test - - test provided provided - provided provided runtime runtime - - runtime 这儿其实有一些规律：在间接依赖为compile时其他两者一致；当间接依赖为test时，不具有传递性；当间接依赖为provided时，只有provided才能传递，且最终依赖为provided；当间接依赖为runtime时，一般情况时直接依赖与最终依赖一致，除了直接依赖为compile时最终依赖为runtime。 既然有传递性依赖，以及继承等机制（这些会在后续讲到），并没有像Java一样限制只能单继承，那么必会出现像C++一样通过不同路径继承同意文件而产生冲突的情况，那么如何解决？Mave这儿需要依赖调解。第一原则是路径最近者优先；第二原则是第一声明者优先。 当然在依赖的时候，提供了optional标签来表示可选。可选依赖是不会传递的。也提供exclusions标签来排除继承时的某些依赖，可以解决在继承时快照版本依赖的不稳定性问题。 仓库在上文中讲到依赖，那么依赖后引入的包相对于其对应仓库中的路径应该是多少呢？在路径与坐标的大致对应关系为groupId/artifactId/version/artifactId-version.packaging。 对于Maven来说，仓库只分为两种：本地仓库和远程仓库。 一般情况是当我们使用依赖去引入一种构建，当Maven根据坐标寻找构建时，先会去本地查找此构建，如果本地没有这个构建，去远程仓库查找，发现则下载到本地使用（当然本地构建需要查看更新时也是需要去远程仓库查找）。 本地仓库一般在用户中本机中，默认情况下都有一个.m2/repository/的仓库目录。 远程仓库远程仓库分为中央仓库以及自己建立的私服等。一般情况下，基本每个公司都是有自己的Maven仓库的，在开发之前的环境配置时会加上一个自己公司的setting.xml文件的配置。 生命周期Maven拥有三套独立的生命周期，分别为clean、default、site。clean生命周期目标是清理项目；default是构建项目；而site生命周期目的是建立项目站点。 clean生命周期包括pre-clean、clean、post-clean。一般调用clean时会依次执行pre-clean、clean。一般命令都是执行到指定的阶段截止。 default是所有生命周期中最核心的部分。包括了许多阶段：calidate、initialize、generate-sources、process-sources、generate-resources、process-resources、compile、process-classes、generate-test-sources、process-test-sources、generate-test-resources、process-test-resources、test-compile、process-test-clasess、test、prepare-package、package、pre-integration-test、integration-test、post-integration-test、verify、install、deploy。在这个生命周期中可以看到有许多编译、测试等阶段。 而site生命周期有pre-site、site、post-site、site-deploy四个阶段。 插件个人觉得Maven中插件是非常重要的一环，可以帮助我们完成一些任务，并且与生命周期中的某个阶段绑定。 1234567891011121314151617181920212223...&lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.3&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;configuration&gt; &lt;port&gt;$&#123;web.port&#125;&lt;/port&gt; &lt;path&gt;/$&#123;project.artifactId&#125;&lt;/path&gt; &lt;uriEncoding&gt;UTF-8&lt;/uriEncoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; ... 在这段代码中使用plugin标签加入了maven-compiler-plugin以及tomcat插件，可以使得项目可编译以及不用本地的tomcat服务器。compiler的插件是内置绑定的compile阶段，不用显式申明。当然也可以自定义绑定，在配置中加入executions、execution标签配置 执行一个任务，并用phase绑定生命周期。 测试讲到插件，就不能跳过Maven的测试。测试也是使用插件来实现的，如maven-surefire-plugin插件。可以帮助我们单元测试、集成测试等。 聚合与继承聚合特性能把项目的各个模块聚合在一起构建，而继承特性能帮助抽取各模块相同的依赖和插件等配置。 所有模块组成的一个构建结构就是反应堆。单模块项目就是这个模块本身；而多模块项目则包含了各模块之间的继承和依赖关系、计算合理构建顺序。 附本文中对于许多详细知识没有作总结，只是对于常用的一些部分作了浅入的涉及。如测试、聚合与继承、以及Nexus建私服、profile、站点等知识没有解释，需要学习的可以仔细看一下《Maven实战》。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对于基础排序算法的简要总结]]></title>
    <url>%2F2017%2F04%2F24%2F%E5%AF%B9%E4%BA%8E%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E7%9A%84%E7%AE%80%E8%A6%81%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[本文主要分析排序算法中的选择排序、插入排序、希尔排序、归并排序、快速排序和堆排序，以及其部分优化方式，部分代码示例。当然快速排序算法是最快的通用排序算法，这使得其在java中的地位非凡，通常的ArrayList.sort()函数就是使用的快速排序。 在这之前，我们先声明两个方法：分别为比较大小与数据交换的方法。 123456789final static boolean less(Comparable i, Comparable j) &#123; return i.compareTo(j) &lt; 0;&#125;final static void exch(Comparable[] a, int i, int j) &#123; Comparable t = a[i]; a[i] = a[j]; a[j] = t;&#125; 在排序中我们使用Comparable[]的数组进行排序，以便兼容其他类型的数组。 选择排序快速排序是的思维是依次找到最小或最大的值，将这个值与我们所比较的值中的第一个或进行交换。这种算法的特点是：1、运行时间与输入无关，就算是输入有序运行时间也是差不多的；2、数据的移动是所有算法中最少的。 1234567891011public static void selectionSort(Comparable[] a) &#123; int N = a.length; for (int i = 0; i &lt; N; i++) &#123; int min = i; for (int j = i+1; j &lt; N; j++) &#123; if (less(a[j], a[min])) min = j; exch(a, i, min); &#125; &#125; &#125; 插入排序插入排序的基本思路是在循环中将下标i之前的元素进行比较交换（这儿是不符合比较小或比较大的条件则交换）。这种算法对于有序或者比较有序的数组时效率较高。 123456789101112131415public static void insertSort(Comparable[] a) &#123; int n = a.length; for (int i = 1; i &lt; n; i++) &#123; Comparable mi = a[i]; boolean f = false; int j = i; for (; j &gt; 0 &amp;&amp; less(mi, a[j - 1]); j--) &#123; a[j] = a[j - 1]; f = true; &#125; if (f) &#123; a[j] = mi; &#125; &#125; &#125; 在上述插入排序代码示例中，并没有每次比较交换相邻的两个元素，而是将较大的元素都向右移，也是每次循环中将比循环比较的最后一个元素的值大的元素都作右移操作，从而减少访问数组的次数。对于减少访问数组的次数，这点需要详细说明一下：对于普通的插入排序，是每次获取相邻两个元素的值进行比较交换，即每次循环都会获取2*i次数据，总的访问数组（即获取数组元素）的次数就是n*(n-1)次（n为数组的长度）；而对于优化后的插入排序，每次循环访问数组i+1次，总的访问数组(n-1)*(n+2)/2次，大约减少了一半的访问数组的次数。 而对于插入排序与选择排序的比较，主要是在数组有序或部分有序时，减少了交换的次数，从而对于部分有序或有序的数组较高。 希尔排序希尔排序的思想是使数组中的任意间隔为h的元素都是有序的。相对于插入排序改变了原来的插入的顺序。从原来的相邻的两个元素交换改成现在相邻两个增量交换的排序（增量即间隔）。通过增量递减的方式重复排序，直到增量为1，使得原数组有序。（增量序列为一组递减的且最后一个元素为1的数组。） 12345678910public static void shellSort(Comparable[] a) &#123; int N = a.length; for (int h = N / 2; h &gt;= 1; h = h / 2) &#123; for (int i = h; i &lt; N; i++) &#123; for (int j = i; j &gt;= h &amp;&amp; less(a[j], a[j - h]); j -= h) &#123; exch(a, j, j - h); &#125; &#125; &#125; &#125; 在示例中我是将增量/2得到之后的增量；当然这种增量序列不是最优的。在张连堂与张博的《希尔排序最佳增量序列研究》中做了一些分析并得到一种最优的增量序列：… 2^k -1, … 15, 7, 3, 1。 希尔排序对于之前的排序算法是对于平方级的突破，权衡了子数组的规模与有序性使得其更加高效。 归并排序归并排序分为原地归并、自顶向下、自底向上三种归并方式。但是最主要的思维也是归并，归并是将前后两端进行比较，将小的放上去，需要注意越界。而自顶向下是采用分治的思想，使用递归的方式进行归并。自底向上是采用相邻两个归并，在到相邻两组归并，刚好与自顶向下相反。 123456789101112131415161718192021222324252627282930313233343536373839404142public static class Merge &#123; private static Comparable[] aux; /*归并*/ public static void merge(Comparable[] a, int lo, int mid, int hi) &#123; int i = lo, j = mid + 1; for (int k = lo; k &lt;= hi; k++) &#123; aux[k] = a[k]; &#125; for (int k = lo; k &lt;= hi; k++) &#123; if (i &gt; mid) a[k] = aux[j++]; else if (j &gt; hi) a[k] = aux[i++]; else if (less(aux[j], aux[i])) a[k] = aux[j++]; else a[k] = aux[i++]; &#125; &#125; /*自顶向下*/ public static void mergeTopSort(Comparable[] a) &#123; aux = new Comparable[a.length]; sort(a, 0, a.length-1); &#125; private static void sort(Comparable[] a, int lo, int hi) &#123; if (hi &lt;= lo) return; int mid = lo + (hi - lo)/2; sort(a, lo, mid); sort(a, mid+1, hi); merge(a, lo, mid, hi); &#125; /*自底向上*/ public static void sort(Comparable[] a) &#123; int N = a.length; aux = new Comparable[N]; for (int sz = 1; sz &lt; N; sz = sz+sz) &#123; for (int lo = 0; lo &lt; N -sz; lo += sz+sz) &#123; merge(a, lo, lo+sz+1, Math.min(lo+sz+sz-1, N-1)); &#125; &#125; &#125; &#125; 快速排序快速排序是最常用的排序算法，采用分治的思想。将一个数组分为两个数组再排序。 切分（partition）是使用交换等方法将某个值放确切的位置，再将其左右排序切分。这个确切的值满足其左边都小于它，右边都大于它，使得在其确定后，在整个排序过程中都不会对其产生影响，其位置不会再作变化。 12345678910111213141516final static int partition(Comparable[] a, int lo, int hi) &#123; int i = lo, j = hi + 1; Comparable v = a[lo]; while (true) &#123; while (less(a[++i], v)) &#123; if (i == hi) break; &#125; while (less(v, a[--j])) &#123; if (j == lo) break; &#125; if (i &gt;= j) break; exch(a, i, j); &#125; exch(a, lo, j); return j; &#125; 而排序算法就是使用递归的方式去调用切分的方法。 123456public static void quickSort(Comparable[] a, int lo, int hi) &#123; if (hi &lt;= lo) return; int j = partition(a, lo, hi); quickSort(a, lo, j - 1); quickSort(a, j + 1, hi); &#125; 上述为标准快速排序，其在很多地方依然具有缺陷，如在切分不平衡时可能使得排序十分低效，如将{6, 5, 4, 3, 2, 1}转换成由小到大排序时就十分低效。 当然对于快速排序，先辈们依然做了许多优化的方法：1、快速排序对于小数组的排序特别慢，因此使用在数组小时以及分治到较小是采用插入排序优化；2、使用三取样切分，来解决具有大量重复数据情况。三取样切分的快速排序算法示例如下： 1234567891011121314151617public static void quick3waySort(Comparable[] a, int lo, int hi) &#123; if (hi &lt;= lo) return; int lt = lo, i = lo + 1, gt = hi; Comparable v = a[lo]; while (i &lt;= gt) &#123; int cmp = a[i].compareTo(v); if (cmp &lt; 0) &#123; exch(a, lt++, i++); &#125; else if (cmp &gt; 0) &#123; exch(a, i, gt--); &#125; else &#123; i++; &#125; &#125; quick3waySort(a, lo, lt - 1); quick3waySort(a, gt + 1, hi); &#125; 优先队列以及堆排序顾名思义，是具有优先级的队列，即对于这个队列中的数据是有序的。实现方式有很多，基于数组、链表、堆都可以实现。这儿主要介绍一下基于二叉堆的优先队列的实现，下述代码中已经十分清晰。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public static class MaxPQ&lt;Key extends Comparable&lt;Key&gt;&gt; &#123; private Key[] pq; private int N = 0; public MaxPQ(int maxN) &#123; pq = (Key[]) new Comparable[maxN + 1]; &#125; public boolean isEmpty() &#123; return N == 0; &#125; public int size() &#123; return N; &#125; private boolean less(int i, int j) &#123; return pq[i].compareTo(pq[j]) &lt; 0; &#125; private void exch(int i, int j) &#123; Key t = pq[i]; pq[i] = pq[j]; pq[j] = t; &#125; private void swim(int k) &#123; while (k &gt; 1 &amp;&amp; less(k / 2, k)) &#123; exch(k / 2, k); k /= 2; &#125; &#125; private void sink(int k) &#123; while (2 * k &lt;= N) &#123; int j = 2 * k; if (j &lt; N &amp;&amp; less(j, j + 1)) &#123; j++; &#125; if (!less(k, j)) &#123; break; &#125; exch(k, j); k = j; &#125; &#125; public void insert(Key v) &#123; pq[++N] = v; swim(N); &#125; public Key delMax() &#123; Key max = pq[1]; exch(1, N--); pq[N + 1] = null; sink(1); return max; &#125; &#125; 需要注意的是上浮swim()和下沉sink()函数，是分别在插入与删除的时候被调用使得二叉堆平衡。 而堆排序算法如下： 12345678910public static void heapSort(Comparable[] a) &#123; int n = a.length; for (int k = n/2; k &gt;= 1; k--) &#123; sink(a, k, n); &#125; while (n &gt; 1) &#123; exch(a, 1, n--); sink(a, 1, n); &#125; &#125; 这儿的sink(i,j,N)也是下沉函数，是将从j为顶开始下沉操作，使得平衡，具体实现类似于之前的优先队列的sink函数。这儿的思想是得到最大数与最后一个数交换再对前面的数组进行下沉操作，以此类推。 总结对于排序算法，我们需要分析其稳定性。在排序算法中保留重复元素的相对位置，则该算法是稳定的。对于目前的排序算法中，插入与归并排序是稳定的；而选择、希尔、快速、堆排序不是稳定的。 算法 是否稳定 是否原地排序 时间复杂度 空间复杂度 备注 选择排序 否 是 N^2 1 插入排序 是 是 介于N和N^2之间 1 取决于输入元素的排列情况 希尔排序 否 是 1 快速排序 否 是 N*logN lgN 运行效率由概率提供保证 三切分快速排序 否 是 介于N和N*logN之间 lgN 运行效率由概率提供保证，同时取决于输入元素的分布情况 归并排序 是 否 N*logN N 堆排序 否 是 N*logN 1 附本文并没有涉及所有的排序算法，还有如冒泡排序、基数排序等，需要的可以找找资料学习。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>Algo</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap 源码分析]]></title>
    <url>%2F2017%2F04%2F03%2FHashMap-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[HashMap是非常常用的键值对类型。本文主要讲述了HashMap的思维以及其重要或者常用的put，get，remove以及resize函数。 首先Java定义了java.util.Map的接口，而常用的实现类型主要有HashMap、ConcurrentHashMap、LinkedHashMap和TreeMap。对于原来常用HashTable在不强调线程安全性时可以用HashMap替代（也就是说HashMap是线程不安全的），而在线程安全的情况下用ConcurrentHashMap替代。 总体结构首先HashMap在Java1.8之后修改了其部分实现方式，将原来“数组+链表”的实现方式改为现在的“数组+链表+红黑树”的实现方式，采用红黑树的实现方式，增强了对于数据查找、删除、修改等性能，对于增加来说，应该是减慢了，但是个人觉得对于增加影响非常小。 红黑树，RBTree，平衡二叉查找树的一种，具有良好的查找性能。他有五点要求：1、任何一个节点都有颜色，黑色或者红色；2、根结点是黑色的；3、父子节点之间不能出现两个连续的红节点；4、任何一个节点向下遍历到其子孙的叶子节点，所经过的黑节点个数必须相等；5、空节点被认为是黑色的。其实现方式比较复杂，若有时间我看完其源码再做分析。 冲突的含义：是指当两个不同的键值对（key不相同）在put的时候hash(key)所得的值是相同的，他们会放到哈希桶数组的同一下标位置，形成链表或者红黑树，这种情况就是冲突。当然，在HashMap中我们要尽量的选取比较好的哈希函数来避免冲突，但是大多数情况冲突是不能完全避免的，所以要引入链表和红黑树来解决冲突。 节点首先，HashMap类中包含了多个内部类，如Node、KeySet、Values、EntrySet等，在此就不一一列举。Node是HashMap中非常重要的类型，它代表每个节点，包含（hash，key，value，next）等属性，源码如下： 123456789101112131415161718192021222324252627282930313233343536373839static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + &quot;=&quot; + value; &#125; public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125;&#125; 先来说说Node每个属性的含义，1、hash：代表存储是的哈希值，一般由hash(key)函数得出；2、key；3、value：这两个就是键和值；4、next：是指指向下一个节点的指针。 HashMap重要字段1、transient Node[] table; table表示哈希桶数组，transient表示其不参与序列化，即修饰的变量不是该对象持久化的部分。这个修饰符需要注意两点：1、只能修饰变量，本地变量不能被修饰（本地变量：局部变量）；2、静态变量（static修饰）不管有没有被修饰都不能序列化。 2、transient int size; size是指当前存储的键值对数目。 3、int threshold; threshold表示最大容纳的键值对个数，一般为threshold=length*loadFactor；length是指哈希桶数组长度，在当前键值对数目超过这个值时，哈希桶数组会扩容。 4、final float loadFactor; loadFactor，负载因子（默认或缺省为0.75）。 构造函数HashMap有4个构造函数，其一示例如下：123456789101112public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(&quot;Illegal initial capacity: &quot; + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(&quot;Illegal load factor: &quot; + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity);&#125; 其他几个构造函数是将loadFactor缺省或者将参数全部缺省，以及其拷贝构造函数。注意的是对于上述构造函数中将参数loadFactor赋值给负载因子，并将参数initialCapacity通过tableSizeFor函数操作后传给threshold，由上面所述，threshold是最大容纳的键值对个数，而initialCapacity理论上应该是初始化容量，即哈希桶数组初始化长度，而且这儿并没有初始化哈希桶数组长度，因此这儿赋值是跟其思维上不符合的，那么我们的threshold最终究竟是多少，以及在哪儿初始化了哈希桶数组长度呢？这一点，我会在后面分析put方法时讲到。 很好奇tableSizeFor函数是做了什么操作？他是在函数里面进行了一系列的移位操作，保证初始化容量为2的n次方。例如，我们new一个HashMap(11)传入的参数为11，按照之前的观点，初始化哈希桶长度应该是11，但是其进行一系列移位操作后，使得初始化容量为16。关于tableSizeFor源码如下： 123456789static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; get操作这儿的思路是非常简单的，就是通过hash(key)&amp;(table.length-1)得到对应的哈希桶数组位置，再去对应的位置查找，当然现在对应的位置可能是链表类型，也可能是RBTree类型，对于Java1.7时，是只有链表类型，因此遍历链表类型可以查找出对于的字段；而对于Java1.8添加了红黑树结构之后，就需要判断当前对应的table[j]的node是不是TreeNode，如果是则通过红黑树去查找，不是则通过链表查找。 1234567891011121314151617181920212223public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125;final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; put操作这部分相对于get操作就复杂了许多，需要注意的一点是put操作会有返回值，当该key有对应的值时，put操作会返回原来的值（至于覆盖与否，我接下来分析putVal函数参数时会讲到），当对应key不存在时则返回null。接下来，我们分为几种情况讨论put操作： 1、table为空或者table.length为0的时候。这种情况会出现在两个时候，分别是刚刚new了一个HashMap和前面操作将table删掉的情况（删除操作在后面的章节会做另外的讨论）。我们前面构造函数部分提到过，在构造的时候只是初始化了负载因子loadFactor，和将初始化哈希桶长度赋值给了最大容纳的键值对个数threshold。并没有对于哈希桶数组table做初始化，因此在这儿table是空NULL，就触发了扩容，在扩容的时候就会将threshold赋值给table的长度length，而真正的threshold在这儿赋值成length*loadFactor。这里解决了我们之前对于table在哪儿赋值以及threshold最终值的疑问。 2、一般情况。就是将key转换成对应的哈希值从而找到对应的数组下标位置，再判断该位置是否存储有数据，该数据的key是否就是我们需要put的数据的key，存储的是链表还是红黑树，将数据插入就好，当然这儿就有一个情况——当插入之后，该链表的长度（即节点数）刚好超过8，那么根据我们一般的猜想就是转换为红黑树RBTree，其实不然。这儿分为两种情况，第一种（也是最特殊的一种），当链表长度超过8的时候，但是总的哈希表容量size并没有达到MIN_TREEIFY_CAPACITY=64，这时候会出发扩容的情况（扩容一般上会降低同一点的冲突，具体情况我会在扩容一章resize的时候讲到；第二种情况就是size达到或超过64，大家众所周知的转为红黑树。 既然有链表转化为红黑树的操作，那么想必有红黑树转化为链表的操作，这个函数就是untreeify，他会在红黑树的节点数减少到6的时候（即小于等于6）将红黑树转化为链表。 123456789101112131415161718192021222324252627282930313233343536373839404142434445public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125;final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125; 注意putVal函数中后面有两个参数onlyIfAbsent和evict。onlyIfAbsent为ture的时候表示仅当该key缺省（即不存在）时才将该键值对加入HashMap。evict表示是否覆盖旧值，一般情况下evict是ture，表示你在后面put一个跟原来key一样的值时会覆盖掉原来的值，而如果是false时，则保留原来的值，也就是不覆盖，相当于put相同key的值没效果吧。 1234567891011121314151617181920final void treeifyBin(Node&lt;K,V&gt;[] tab, int hash) &#123; int n, index; Node&lt;K,V&gt; e; if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY) resize(); else if ((e = tab[index = (n - 1) &amp; hash]) != null) &#123; TreeNode&lt;K,V&gt; hd = null, tl = null; do &#123; TreeNode&lt;K,V&gt; p = replacementTreeNode(e, null); if (tl == null) hd = p; else &#123; p.prev = tl; tl.next = p; &#125; tl = p; &#125; while ((e = e.next) != null); if ((tab[index] = hd) != null) hd.treeify(tab); &#125;&#125; 这儿有个instanceof函数表示判断前者是否是后者的一个实例。例如，Result = object instanceof class; 判断object是不是class的一个实例，如果是则返回ture。 TreeNode，树节点，他是继承自Node节点的，也就是说TreeNode形成的实例既有Node的key，value等属性，重要的是他有next属性指向下一个节点，而有有TreeNode的parent，left，rigth等属性，这儿在TreeNode里面增加了pre属性来指向前一个节点，只能够在红黑树中使用。在查找HashMap中是否包含某个value的时候将所有都当作链表节点来使用，将父类与本身的属性发挥的非常不错，比如在ContainsValue函数中就没有区分是否是红黑树去查找而是直接使用其父类的next函数查找下一个依次遍历。 3、putMapEntries这个函数就是将，一个Map的所有值加入当前Map，当然需要指定evict参数。 12345678910111213141516171819final void putMapEntries(Map&lt;? extends K, ? extends V&gt; m, boolean evict) &#123; int s = m.size(); if (s &gt; 0) &#123; if (table == null) &#123; // pre-size float ft = ((float)s / loadFactor) + 1.0F; int t = ((ft &lt; (float)MAXIMUM_CAPACITY) ? (int)ft : MAXIMUM_CAPACITY); if (t &gt; threshold) threshold = tableSizeFor(t); &#125; else if (s &gt; threshold) resize(); for (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) &#123; K key = e.getKey(); V value = e.getValue(); putVal(hash(key), key, value, false, evict); &#125; &#125;&#125; 类似的有putAll函数，他就是引用了一下putMapEntries函数，区别就是默认了evict为true而已。 123public void putAll(Map&lt;? extends K, ? extends V&gt; m) &#123; putMapEntries(m, true);&#125; resize函数这部分非常重要，时HashMap重要思维的体现之处之一。首先扩容会在两种情况发生，第一种，在链表转化为红黑树的时候阐述过链表长度大于8且哈希桶数组的长度size&lt;64时会出发扩容；第二种，size&gt;threshold的时候会触发扩容（threshold=length*loadFactor）。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;&quot;rawtypes&quot;,&quot;unchecked&quot;&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; 从代码中可以看出resize函数是返回一个新的哈希桶数组，那么为什么要返回一个新的哈希桶数组呢？这点要从数组讲起，众所周知数组的长度是固定的，不能变长，那么我们怎么在HashMap中产生一个是原来长度两倍的数组呢？这儿就只能够创建一个新的数组来代替老的数组，需要将原来数组里面的变量一一填充到新的数组里面来。在Java1.7以及之前是一次将原来HashMap中的所有节点通过hash算法依次定位到新的Map中来。在Java1.8中对于老的数组同意位置的链表或红黑树中的节点填充到新的Map中做了很大的优化，使得扩容的速度快了许多。当然虽然优化了很多，但是这也是非常消耗时间成本的，因此我们在创建HashMap的时候就需要提前估计其能达到的最大容量，尽量一次性分配足够的空间，减少扩容情况。 在Java1.8中对于HashMap扩容时数据转移做了很大的优化，这儿需要讲到hash获取数组下标的方法(n-1)&amp;hash(key)。对于hash(key)方法我不做过多阐述，想要学习的看看源码再自己测试一下就明白了。而对于按位与&amp;这儿需要说明一下，比如我们的数组长度n=4，那么呢n-1就是二进制的0011，举个例子当hash(key)为2和6的二进制分别时0010和0110，（前面的一些0就不做过多书写了），他们对于n-1的&amp;后得到的0011是相同的，也就是产生冲突，就会形成链表或者红黑树。而扩容之后，n’为8，n’-1二进制为0111，hash(key)进行&amp;操作后就是0010和0110，刚好是原来下标位置和原位置下标加上原来数组长度后作为下标的位置。这儿就可以直接用原来数组长度n的二进制0100与两个hash(key)进行&amp;操作，来判断是否需要将下标位置加上n了，如果是1则加。这样就不需要对于每个节点依次去进行一次重新定位操作。 remove函数当然，跟之前的分析一样，我们都需要关注返回值，这儿返回的是value或者null，那么value是哪个value呢？就是原来我们移除的那个节点的value，当无这个节点时，那么返回null。其实这儿跟put函数一样，都是对于其基础函数的封装，这里remove函数是对于removeNode函数的封装。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public V remove(Object key) &#123; Node&lt;K,V&gt; e; return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value;&#125;final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) &#123; Node&lt;K,V&gt; node = null, e; K k; V v; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) node = p; else if ((e = p.next) != null) &#123; if (p instanceof TreeNode) node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); else &#123; do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; node = e; break; &#125; p = e; &#125; while ((e = e.next) != null); &#125; &#125; if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) &#123; if (node instanceof TreeNode) ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); else if (node == p) tab[index] = node.next; else p.next = node.next; ++modCount; --size; afterNodeRemoval(node); return node; &#125; &#125; return null;&#125; 从上面removeNode函数可以看出其返回的是一个Node类型，即返回移除的节点，除了没有对应节点时返回null，这儿有两个比较特殊的参数matchValue和movable，matchValue表示是否匹配value的值，而moveable表示是否可以移除，对于这点我有点想不太明白。在remove函数中这部分都是和value一起以默认值传出。在removeNode函数里面又有判断当为红黑树时的removeTreeNode函数，对于这个函数我不作过多分析，需要的可以自己去看一下源码。 附对于其他函数等操作等，我就不具体分析，比如contains一系列，clear函数以及一系列Set等，以及其迭代器iterator等。这些如果需要学习可以仔细看一下其源码分析。最后推荐下美团点评技术团队的《Java 8系列之重新认识HashMap》。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>map</tag>
      </tags>
  </entry>
</search>
