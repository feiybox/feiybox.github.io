<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[洗牌算法]]></title>
    <url>%2F2017%2F05%2F04%2F%E6%B4%97%E7%89%8C%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[第一次接触洗牌算法是在一次面试上，面试官要求我写出一个算法将一个1～100的有序数组打乱，不考虑性能，那次我想了许久，想到一种基于二叉排序的方式实现了随机洗牌，但是那个性能呢，惨不忍睹。后来详细学习排序算法的时候，发现为了保证快速排序的性能，需要在排序之前对排序的数组进行洗牌操作。 为什么不基于一般排序算法做洗牌？众所周知，一般排序算法在在性能上以快速排序最好吧，时间复杂度基本在N*logN，空间复杂度在logN，当然三切分快速排序更好一些。所有算法中空间复杂度最好时为1，这当然是最好的。详细见对于基础排序算法的简要总结。但是在排序算法中没有能够达到时间复杂度N的线性的。而在洗牌算法中，我们随便便能实现N的线性的时间复杂度，因此基于排序算法做洗牌不可取。 洗牌算法第一版初次想的是一个排列好的数组，再新建一个长度相等的数组，每次通过随机数，随机一个N以内的数作为下标将其添加到新数组，并将该随机下标与N为下标的数交换，当然N需要自减。在N开始的时候为数组长度减1的值（保证下标最大而不越界）。那么最后会形成一个任意数组在数组内的某一位置的概率都是1/N的随机数组。 12345678910public static Comparable[] Shuffle1(Comparable[] c) &#123; Comparable[] a = new Comparable[c.length]; int N = c.length - 1; for (int i = 0; i &lt; c.length; i++, N--) &#123; int ran = intRandom(0, N); a[i] = c[ran]; c[ran] = c[N]; &#125; return a; &#125; 这种算法相比较之前打算基于一般排序算法求解的方式，在时间复杂度上有了很大的提升。在时间复杂度上，这种算法保证了N次循环（N为数组长度），N次获取随机值，N次交换（但是有2N次数组元素赋值操作）实现了分部均匀的洗牌算法。但是它的缺点是需要另建数组，使得空间复杂度增加。 在算法中使用了随机数的intRandom函数如下 1234567private static int intRandom(int min, int max) &#123; if (min &gt; max) throw new IllegalArgumentException(&quot;min can not bigger than max&quot;); if (max == min) return max; return new Random().nextInt(max - min + 1) + min; &#125; 洗牌算法第二版为了减少空间复杂度，使得算法在原地进行洗牌操作，尝试着将算法改进。在本算法中使用随机生成一个下标，使得对应的数与第一个i个数交换（i会从0到N-1自增）。 123456789public static void Shuffle2(Comparable[] c) &#123; int N = c.length; for (int i = 0; i &lt; N; i++) &#123; Comparable mid = c[0]; int ran = intRandom(0, N-1); c[0] = c[ran]; c[ran] = mid; &#125; &#125; 当然在本算法中，空间复杂度是1，达到最小。而时间复杂度也没有很大升高，依然需要N次循环，N次随机，N次交换（但是有3N次赋值操作）。因为对于数组中的每个数都会进行同样的操作，不因为数组元素顺序等变化，因此对于任意一个数分布在某个位置的概率是相同的。所有这是目前我发现的最好的洗牌算法。 附本文仅讲述一些自我对于洗牌算法的一些了解以及自我的一些思考以及实现，在目前我的了解中，这两种洗牌算法是最好的了，如有更好，请指出，共同学习。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>Algo</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven基础总结]]></title>
    <url>%2F2017%2F05%2F03%2FMaven%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[鉴于最近基本看完《Maven实战》这本书，对于我自己的所看的结果作一下总结，理清自己的思路，并复习书中的知识。当然有时间会继续学习一下Gradle，似乎是一个更好的工具。 我原来对于Maven的印象就是依赖管理的工具，但是在认真学习之后，认识到Maven可以实现挺多实用功能。 自动化构建 依赖管理（提供中央仓库，能够帮我们自动下载构建） 项目信息管理 在Maven中最重要的思维莫过于约定优于配置。虽然在Maven中没有确定的文件定义一些要求，但是大家约定的一些写法等，保证了项目的移植性，当然也可以自定义，但是不推荐（因为你写了可能就自己看得懂了，别人都看不懂）。在Maven项目中默认的主代码目录为src/test/java，默认的测试代码目录为src/test/java。 Pom文件在平时开发中，感觉到pom.xml文件是Maven项目中最重要的一环，它提供了项目信息与依赖管理等。 首先，pom.xml文件中，包含一般XML文件头，指定xml文件版本以及编码方式等；接下来是project元素，包含相关的命名空间以及xsd元素等。 12345678910111213141516171819202122232425&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;groupId&gt;com.fei&lt;/groupId&gt; &lt;artifactId&gt;fei.empty.spring.web&lt;/artifactId&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;properties&gt; &lt;jetty.port&gt;8417&lt;/jetty.port&gt; &lt;spring.version&gt;4.2.0.RELEASE&lt;/spring.version&gt; &lt;mybatis.version&gt;3.3.1&lt;/mybatis.version&gt; &lt;slf4j.version&gt;2.6.2&lt;/slf4j.version&gt; &lt;log4j2.version&gt;2.6.2&lt;/log4j2.version&gt; &lt;/properties&gt; &lt;dependencyManagement&gt; &lt;/dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; ... 元素接下来重要的是groupId、artifactId、version元素，分别表示组（当前Maven项目隶属的实际项目）、唯一ID、版本。这个是Maven的坐标元素，基本可以确定一个项目，当然这三项是必须的，不管是在项目信息还是在依赖管理中，还有packaging、classifier分别表示打包方式和帮助定义构建输出的一些附属构建（ classifier是不能直接定义的，附属构建不是项目直接默认生成的，而是由附加的插件帮助生成）。例如在本例中因为是Javaweb项目，所以使用war的打包方式，在项目中如果不做声明，默认的是jar打包方式。这5个元素可以唯一的确定项目。 版本关于版本，分为发布版本和快照版本，在本例中的1.0-SNAPSHOT就是快照版本，快照版本是不稳定的。在Maven中版本号的约定是&lt;主版本&gt;.&lt;次版本&gt;.&lt;增量版本&gt;-&lt;里程碑版本&gt;。关于版本管理的一些本文不会涉及。 在配置的pom文件中提供了properties标签自定义。利用这个我们将所有的版本号集中在一起，方便更新、引用，以及减少一些版本号重复性。 依赖除了在项目信息中使用到了这些元素标签，还在依赖管理中使用，这是很必要的，需要用它们去确定一个Maven项目。在 dependencies里会有许多dependency来确定每个依赖。例如spring项目中一般会包含spring-core、spring-context、spring-context-support等都是Spring Framework实现依赖注入等功能必要的构建，都需要在项目中依赖。 在依赖的servlet中定义了scop标签，表示定义依赖的范围，那么provided是什么意思呢？在一般情况中，我们有6种依赖范围：1、compile：编译依赖范围，一般在缺省默认情况下也使用这个默认范围；2、test：测试依赖范围；3、provided：已提供依赖范围，表示对于编译和测试classpath有效，但是在运行的时候无效；4、runtime：运行时依赖范围，即测试和运行classpath有效；5、system：系统依赖范围，该依赖范围与三种classpath的关系与provided相同，但是在使用这个依赖范围时，必须通过systemPath元素显式地指定依赖文件的路径，在使用时会造成不可移植性；6、import：导入依赖范围，其实是继承父模版的依赖配置，继承依赖范围。 依赖范围（scop） 对于编译classpath有效 对于测试classpath有效 对于运行classpath有效 示例 compile Y Y Y spring-core test - Y - JUnit provided Y Y - servlet-api runtime - Y Y JDBC驱动实现 system Y Y - 类似于java的属性继承一样，Maven也具有传递性依赖，继承依赖范围关系如下，左一列为直接依赖，横一栏为间接依赖，内容表示最终依赖范围。 compile test provided runtime compile compile - - runtime test test - - test provided provided - provided provided runtime runtime - - runtime 这儿其实有一些规律：在间接依赖为compile时其他两者一致；当间接依赖为test时，不具有传递性；当间接依赖为provided时，只有provided才能传递，且最终依赖为provided；当间接依赖为runtime时，一般情况时直接依赖与最终依赖一致，除了直接依赖为compile时最终依赖为runtime。 既然有传递性依赖，以及继承等机制（这些会在后续讲到），并没有像Java一样限制只能单继承，那么必会出现像C++一样通过不同路径继承同意文件而产生冲突的情况，那么如何解决？Mave这儿需要依赖调解。第一原则是路径最近者优先；第二原则是第一声明者优先。 当然在依赖的时候，提供了optional标签来表示可选。可选依赖是不会传递的。也提供exclusions标签来排除继承时的某些依赖，可以解决在继承时快照版本依赖的不稳定性问题。 仓库在上文中讲到依赖，那么依赖后引入的包相对于其对应仓库中的路径应该是多少呢？在路径与坐标的大致对应关系为groupId/artifactId/version/artifactId-version.packaging。 对于Maven来说，仓库只分为两种：本地仓库和远程仓库。 一般情况是当我们使用依赖去引入一种构建，当Maven根据坐标寻找构建时，先会去本地查找此构建，如果本地没有这个构建，去远程仓库查找，发现则下载到本地使用（当然本地构建需要查看更新时也是需要去远程仓库查找）。 本地仓库一般在用户中本机中，默认情况下都有一个.m2/repository/的仓库目录。 远程仓库远程仓库分为中央仓库以及自己建立的私服等。一般情况下，基本每个公司都是有自己的Maven仓库的，在开发之前的环境配置时会加上一个自己公司的setting.xml文件的配置。 生命周期Maven拥有三套独立的生命周期，分别为clean、default、site。clean生命周期目标是清理项目；default是构建项目；而site生命周期目的是建立项目站点。 clean生命周期包括pre-clean、clean、post-clean。一般调用clean时会依次执行pre-clean、clean。一般命令都是执行到指定的阶段截止。 default是所有生命周期中最核心的部分。包括了许多阶段：calidate、initialize、generate-sources、process-sources、generate-resources、process-resources、compile、process-classes、generate-test-sources、process-test-sources、generate-test-resources、process-test-resources、test-compile、process-test-clasess、test、prepare-package、package、pre-integration-test、integration-test、post-integration-test、verify、install、deploy。在这个生命周期中可以看到有许多编译、测试等阶段。 而site生命周期有pre-site、site、post-site、site-deploy四个阶段。 插件个人觉得Maven中插件是非常重要的一环，可以帮助我们完成一些任务，并且与生命周期中的某个阶段绑定。 1234567891011121314151617181920212223...&lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.3&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;configuration&gt; &lt;port&gt;$&#123;web.port&#125;&lt;/port&gt; &lt;path&gt;/$&#123;project.artifactId&#125;&lt;/path&gt; &lt;uriEncoding&gt;UTF-8&lt;/uriEncoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; ... 在这段代码中使用plugin标签加入了maven-compiler-plugin以及tomcat插件，可以使得项目可编译以及不用本地的tomcat服务器。compiler的插件是内置绑定的compile阶段，不用显式申明。当然也可以自定义绑定，在配置中加入executions、execution标签配置 执行一个任务，并用phase绑定生命周期。 测试讲到插件，就不能跳过Maven的测试。测试也是使用插件来实现的，如maven-surefire-plugin插件。可以帮助我们单元测试、集成测试等。 聚合与继承聚合特性能把项目的各个模块聚合在一起构建，而继承特性能帮助抽取各模块相同的依赖和插件等配置。 所有模块组成的一个构建结构就是反应堆。单模块项目就是这个模块本身；而多模块项目则包含了各模块之间的继承和依赖关系、计算合理构建顺序。 附本文中对于许多详细知识没有作总结，只是对于常用的一些部分作了浅入的涉及。如测试、聚合与继承、以及Nexus建私服、profile、站点等知识没有解释，需要学习的可以仔细看一下《Maven实战》。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对于基础排序算法的简要总结]]></title>
    <url>%2F2017%2F04%2F24%2F%E5%AF%B9%E4%BA%8E%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E7%9A%84%E7%AE%80%E8%A6%81%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[本文主要分析排序算法中的选择排序、插入排序、希尔排序、归并排序、快速排序和堆排序，以及其部分优化方式，部分代码示例。当然快速排序算法是最快的通用排序算法，这使得其在java中的地位非凡，通常的ArrayList.sort()函数就是使用的快速排序。 在这之前，我们先声明两个方法：分别为比较大小与数据交换的方法。 123456789final static boolean less(Comparable i, Comparable j) &#123; return i.compareTo(j) &lt; 0;&#125;final static void exch(Comparable[] a, int i, int j) &#123; Comparable t = a[i]; a[i] = a[j]; a[j] = t;&#125; 在排序中我们使用Comparable[]的数组进行排序，以便兼容其他类型的数组。 选择排序快速排序是的思维是依次找到最小或最大的值，将这个值与我们所比较的值中的第一个或进行交换。这种算法的特点是：1、运行时间与输入无关，就算是输入有序运行时间也是差不多的；2、数据的移动是所有算法中最少的。 1234567891011public static void selectionSort(Comparable[] a) &#123; int N = a.length; for (int i = 0; i &lt; N; i++) &#123; int min = i; for (int j = i+1; j &lt; N; j++) &#123; if (less(a[j], a[min])) min = j; exch(a, i, min); &#125; &#125; &#125; 插入排序插入排序的基本思路是在循环中将下标i之前的元素进行比较交换（这儿是不符合比较小或比较大的条件则交换）。这种算法对于有序或者比较有序的数组时效率较高。 123456789101112131415public static void insertSort(Comparable[] a) &#123; int n = a.length; for (int i = 1; i &lt; n; i++) &#123; Comparable mi = a[i]; boolean f = false; int j = i; for (; j &gt; 0 &amp;&amp; less(mi, a[j - 1]); j--) &#123; a[j] = a[j - 1]; f = true; &#125; if (f) &#123; a[j] = mi; &#125; &#125; &#125; 在上述插入排序代码示例中，并没有每次比较交换相邻的两个元素，而是将较大的元素都向右移，也是每次循环中将比循环比较的最后一个元素的值大的元素都作右移操作，从而减少访问数组的次数。对于减少访问数组的次数，这点需要详细说明一下：对于普通的插入排序，是每次获取相邻两个元素的值进行比较交换，即每次循环都会获取2*i次数据，总的访问数组（即获取数组元素）的次数就是n*(n-1)次（n为数组的长度）；而对于优化后的插入排序，每次循环访问数组i+1次，总的访问数组(n-1)*(n+2)/2次，大约减少了一半的访问数组的次数。 而对于插入排序与选择排序的比较，主要是在数组有序或部分有序时，减少了交换的次数，从而对于部分有序或有序的数组较高。 希尔排序希尔排序的思想是使数组中的任意间隔为h的元素都是有序的。相对于插入排序改变了原来的插入的顺序。从原来的相邻的两个元素交换改成现在相邻两个增量交换的排序（增量即间隔）。通过增量递减的方式重复排序，直到增量为1，使得原数组有序。（增量序列为一组递减的且最后一个元素为1的数组。） 12345678910public static void shellSort(Comparable[] a) &#123; int N = a.length; for (int h = N / 2; h &gt;= 1; h = h / 2) &#123; for (int i = h; i &lt; N; i++) &#123; for (int j = i; j &gt;= h &amp;&amp; less(a[j], a[j - h]); j -= h) &#123; exch(a, j, j - h); &#125; &#125; &#125; &#125; 在示例中我是将增量/2得到之后的增量；当然这种增量序列不是最优的。在张连堂与张博的《希尔排序最佳增量序列研究》中做了一些分析并得到一种最优的增量序列：… 2^k -1, … 15, 7, 3, 1。 希尔排序对于之前的排序算法是对于平方级的突破，权衡了子数组的规模与有序性使得其更加高效。 归并排序归并排序分为原地归并、自顶向下、自底向上三种归并方式。但是最主要的思维也是归并，归并是将前后两端进行比较，将小的放上去，需要注意越界。而自顶向下是采用分治的思想，使用递归的方式进行归并。自底向上是采用相邻两个归并，在到相邻两组归并，刚好与自顶向下相反。 123456789101112131415161718192021222324252627282930313233343536373839404142public static class Merge &#123; private static Comparable[] aux; /*归并*/ public static void merge(Comparable[] a, int lo, int mid, int hi) &#123; int i = lo, j = mid + 1; for (int k = lo; k &lt;= hi; k++) &#123; aux[k] = a[k]; &#125; for (int k = lo; k &lt;= hi; k++) &#123; if (i &gt; mid) a[k] = aux[j++]; else if (j &gt; hi) a[k] = aux[i++]; else if (less(aux[j], aux[i])) a[k] = aux[j++]; else a[k] = aux[i++]; &#125; &#125; /*自顶向下*/ public static void mergeTopSort(Comparable[] a) &#123; aux = new Comparable[a.length]; sort(a, 0, a.length-1); &#125; private static void sort(Comparable[] a, int lo, int hi) &#123; if (hi &lt;= lo) return; int mid = lo + (hi - lo)/2; sort(a, lo, mid); sort(a, mid+1, hi); merge(a, lo, mid, hi); &#125; /*自底向上*/ public static void sort(Comparable[] a) &#123; int N = a.length; aux = new Comparable[N]; for (int sz = 1; sz &lt; N; sz = sz+sz) &#123; for (int lo = 0; lo &lt; N -sz; lo += sz+sz) &#123; merge(a, lo, lo+sz+1, Math.min(lo+sz+sz-1, N-1)); &#125; &#125; &#125; &#125; 快速排序快速排序是最常用的排序算法，采用分治的思想。将一个数组分为两个数组再排序。 切分（partition）是使用交换等方法将某个值放确切的位置，再将其左右排序切分。这个确切的值满足其左边都小于它，右边都大于它，使得在其确定后，在整个排序过程中都不会对其产生影响，其位置不会再作变化。 12345678910111213141516final static int partition(Comparable[] a, int lo, int hi) &#123; int i = lo, j = hi + 1; Comparable v = a[lo]; while (true) &#123; while (less(a[++i], v)) &#123; if (i == hi) break; &#125; while (less(v, a[--j])) &#123; if (j == lo) break; &#125; if (i &gt;= j) break; exch(a, i, j); &#125; exch(a, lo, j); return j; &#125; 而排序算法就是使用递归的方式去调用切分的方法。 123456public static void quickSort(Comparable[] a, int lo, int hi) &#123; if (hi &lt;= lo) return; int j = partition(a, lo, hi); quickSort(a, lo, j - 1); quickSort(a, j + 1, hi); &#125; 上述为标准快速排序，其在很多地方依然具有缺陷，如在切分不平衡时可能使得排序十分低效，如将{6, 5, 4, 3, 2, 1}转换成由小到大排序时就十分低效。 当然对于快速排序，先辈们依然做了许多优化的方法：1、快速排序对于小数组的排序特别慢，因此使用在数组小时以及分治到较小是采用插入排序优化；2、使用三取样切分，来解决具有大量重复数据情况。三取样切分的快速排序算法示例如下： 1234567891011121314151617public static void quick3waySort(Comparable[] a, int lo, int hi) &#123; if (hi &lt;= lo) return; int lt = lo, i = lo + 1, gt = hi; Comparable v = a[lo]; while (i &lt;= gt) &#123; int cmp = a[i].compareTo(v); if (cmp &lt; 0) &#123; exch(a, lt++, i++); &#125; else if (cmp &gt; 0) &#123; exch(a, i, gt--); &#125; else &#123; i++; &#125; &#125; quick3waySort(a, lo, lt - 1); quick3waySort(a, gt + 1, hi); &#125; 优先队列以及堆排序顾名思义，是具有优先级的队列，即对于这个队列中的数据是有序的。实现方式有很多，基于数组、链表、堆都可以实现。这儿主要介绍一下基于二叉堆的优先队列的实现，下述代码中已经十分清晰。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public static class MaxPQ&lt;Key extends Comparable&lt;Key&gt;&gt; &#123; private Key[] pq; private int N = 0; public MaxPQ(int maxN) &#123; pq = (Key[]) new Comparable[maxN + 1]; &#125; public boolean isEmpty() &#123; return N == 0; &#125; public int size() &#123; return N; &#125; private boolean less(int i, int j) &#123; return pq[i].compareTo(pq[j]) &lt; 0; &#125; private void exch(int i, int j) &#123; Key t = pq[i]; pq[i] = pq[j]; pq[j] = t; &#125; private void swim(int k) &#123; while (k &gt; 1 &amp;&amp; less(k / 2, k)) &#123; exch(k / 2, k); k /= 2; &#125; &#125; private void sink(int k) &#123; while (2 * k &lt;= N) &#123; int j = 2 * k; if (j &lt; N &amp;&amp; less(j, j + 1)) &#123; j++; &#125; if (!less(k, j)) &#123; break; &#125; exch(k, j); k = j; &#125; &#125; public void insert(Key v) &#123; pq[++N] = v; swim(N); &#125; public Key delMax() &#123; Key max = pq[1]; exch(1, N--); pq[N + 1] = null; sink(1); return max; &#125; &#125; 需要注意的是上浮swim()和下沉sink()函数，是分别在插入与删除的时候被调用使得二叉堆平衡。 而堆排序算法如下： 12345678910public static void heapSort(Comparable[] a) &#123; int n = a.length; for (int k = n/2; k &gt;= 1; k--) &#123; sink(a, k, n); &#125; while (n &gt; 1) &#123; exch(a, 1, n--); sink(a, 1, n); &#125; &#125; 这儿的sink(i,j,N)也是下沉函数，是将从j为顶开始下沉操作，使得平衡，具体实现类似于之前的优先队列的sink函数。这儿的思想是得到最大数与最后一个数交换再对前面的数组进行下沉操作，以此类推。 总结对于排序算法，我们需要分析其稳定性。在排序算法中保留重复元素的相对位置，则该算法是稳定的。对于目前的排序算法中，插入与归并排序是稳定的；而选择、希尔、快速、堆排序不是稳定的。 算法 是否稳定 是否原地排序 时间复杂度 空间复杂度 备注 选择排序 否 是 N^2 1 插入排序 是 是 介于N和N^2之间 1 取决于输入元素的排列情况 希尔排序 否 是 1 快速排序 否 是 N*logN lgN 运行效率由概率提供保证 三切分快速排序 否 是 介于N和N*logN之间 lgN 运行效率由概率提供保证，同时取决于输入元素的分布情况 归并排序 是 否 N*logN N 堆排序 否 是 N*logN 1 附本文并没有涉及所有的排序算法，还有如冒泡排序、基数排序等，需要的可以找找资料学习。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>Algo</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap 源码分析]]></title>
    <url>%2F2017%2F04%2F03%2FHashMap-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[HashMap是非常常用的键值对类型。本文主要讲述了HashMap的思维以及其重要或者常用的put，get，remove以及resize函数。 首先Java定义了java.util.Map的接口，而常用的实现类型主要有HashMap、ConcurrentHashMap、LinkedHashMap和TreeMap。对于原来常用HashTable在不强调线程安全性时可以用HashMap替代（也就是说HashMap是线程不安全的），而在线程安全的情况下用ConcurrentHashMap替代。 总体结构首先HashMap在Java1.8之后修改了其部分实现方式，将原来“数组+链表”的实现方式改为现在的“数组+链表+红黑树”的实现方式，采用红黑树的实现方式，增强了对于数据查找、删除、修改等性能，对于增加来说，应该是减慢了，但是个人觉得对于增加影响非常小。 红黑树，RBTree，平衡二叉查找树的一种，具有良好的查找性能。他有五点要求：1、任何一个节点都有颜色，黑色或者红色；2、根结点是黑色的；3、父子节点之间不能出现两个连续的红节点；4、任何一个节点向下遍历到其子孙的叶子节点，所经过的黑节点个数必须相等；5、空节点被认为是黑色的。其实现方式比较复杂，若有时间我看完其源码再做分析。 冲突的含义：是指当两个不同的键值对（key不相同）在put的时候hash(key)所得的值是相同的，他们会放到哈希桶数组的同一下标位置，形成链表或者红黑树，这种情况就是冲突。当然，在HashMap中我们要尽量的选取比较好的哈希函数来避免冲突，但是大多数情况冲突是不能完全避免的，所以要引入链表和红黑树来解决冲突。 节点首先，HashMap类中包含了多个内部类，如Node、KeySet、Values、EntrySet等，在此就不一一列举。Node是HashMap中非常重要的类型，它代表每个节点，包含（hash，key，value，next）等属性，源码如下： 123456789101112131415161718192021222324252627282930313233343536373839static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + &quot;=&quot; + value; &#125; public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125;&#125; 先来说说Node每个属性的含义，1、hash：代表存储是的哈希值，一般由hash(key)函数得出；2、key；3、value：这两个就是键和值；4、next：是指指向下一个节点的指针。 HashMap重要字段1、transient Node[] table; table表示哈希桶数组，transient表示其不参与序列化，即修饰的变量不是该对象持久化的部分。这个修饰符需要注意两点：1、只能修饰变量，本地变量不能被修饰（本地变量：局部变量）；2、静态变量（static修饰）不管有没有被修饰都不能序列化。 2、transient int size; size是指当前存储的键值对数目。 3、int threshold; threshold表示最大容纳的键值对个数，一般为threshold=length*loadFactor；length是指哈希桶数组长度，在当前键值对数目超过这个值时，哈希桶数组会扩容。 4、final float loadFactor; loadFactor，负载因子（默认或缺省为0.75）。 构造函数HashMap有4个构造函数，其一示例如下：123456789101112public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(&quot;Illegal initial capacity: &quot; + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(&quot;Illegal load factor: &quot; + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity);&#125; 其他几个构造函数是将loadFactor缺省或者将参数全部缺省，以及其拷贝构造函数。注意的是对于上述构造函数中将参数loadFactor赋值给负载因子，并将参数initialCapacity通过tableSizeFor函数操作后传给threshold，由上面所述，threshold是最大容纳的键值对个数，而initialCapacity理论上应该是初始化容量，即哈希桶数组初始化长度，而且这儿并没有初始化哈希桶数组长度，因此这儿赋值是跟其思维上不符合的，那么我们的threshold最终究竟是多少，以及在哪儿初始化了哈希桶数组长度呢？这一点，我会在后面分析put方法时讲到。 很好奇tableSizeFor函数是做了什么操作？他是在函数里面进行了一系列的移位操作，保证初始化容量为2的n次方。例如，我们new一个HashMap(11)传入的参数为11，按照之前的观点，初始化哈希桶长度应该是11，但是其进行一系列移位操作后，使得初始化容量为16。关于tableSizeFor源码如下： 123456789static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; get操作这儿的思路是非常简单的，就是通过hash(key)&amp;(table.length-1)得到对应的哈希桶数组位置，再去对应的位置查找，当然现在对应的位置可能是链表类型，也可能是RBTree类型，对于Java1.7时，是只有链表类型，因此遍历链表类型可以查找出对于的字段；而对于Java1.8添加了红黑树结构之后，就需要判断当前对应的table[j]的node是不是TreeNode，如果是则通过红黑树去查找，不是则通过链表查找。 1234567891011121314151617181920212223public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125;final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; put操作这部分相对于get操作就复杂了许多，需要注意的一点是put操作会有返回值，当该key有对应的值时，put操作会返回原来的值（至于覆盖与否，我接下来分析putVal函数参数时会讲到），当对应key不存在时则返回null。接下来，我们分为几种情况讨论put操作： 1、table为空或者table.length为0的时候。这种情况会出现在两个时候，分别是刚刚new了一个HashMap和前面操作将table删掉的情况（删除操作在后面的章节会做另外的讨论）。我们前面构造函数部分提到过，在构造的时候只是初始化了负载因子loadFactor，和将初始化哈希桶长度赋值给了最大容纳的键值对个数threshold。并没有对于哈希桶数组table做初始化，因此在这儿table是空NULL，就触发了扩容，在扩容的时候就会将threshold赋值给table的长度length，而真正的threshold在这儿赋值成length*loadFactor。这里解决了我们之前对于table在哪儿赋值以及threshold最终值的疑问。 2、一般情况。就是将key转换成对应的哈希值从而找到对应的数组下标位置，再判断该位置是否存储有数据，该数据的key是否就是我们需要put的数据的key，存储的是链表还是红黑树，将数据插入就好，当然这儿就有一个情况——当插入之后，该链表的长度（即节点数）刚好超过8，那么根据我们一般的猜想就是转换为红黑树RBTree，其实不然。这儿分为两种情况，第一种（也是最特殊的一种），当链表长度超过8的时候，但是总的哈希表容量size并没有达到MIN_TREEIFY_CAPACITY=64，这时候会出发扩容的情况（扩容一般上会降低同一点的冲突，具体情况我会在扩容一章resize的时候讲到；第二种情况就是size达到或超过64，大家众所周知的转为红黑树。 既然有链表转化为红黑树的操作，那么想必有红黑树转化为链表的操作，这个函数就是untreeify，他会在红黑树的节点数减少到6的时候（即小于等于6）将红黑树转化为链表。 123456789101112131415161718192021222324252627282930313233343536373839404142434445public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125;final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125; 注意putVal函数中后面有两个参数onlyIfAbsent和evict。onlyIfAbsent为ture的时候表示仅当该key缺省（即不存在）时才将该键值对加入HashMap。evict表示是否覆盖旧值，一般情况下evict是ture，表示你在后面put一个跟原来key一样的值时会覆盖掉原来的值，而如果是false时，则保留原来的值，也就是不覆盖，相当于put相同key的值没效果吧。 1234567891011121314151617181920final void treeifyBin(Node&lt;K,V&gt;[] tab, int hash) &#123; int n, index; Node&lt;K,V&gt; e; if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY) resize(); else if ((e = tab[index = (n - 1) &amp; hash]) != null) &#123; TreeNode&lt;K,V&gt; hd = null, tl = null; do &#123; TreeNode&lt;K,V&gt; p = replacementTreeNode(e, null); if (tl == null) hd = p; else &#123; p.prev = tl; tl.next = p; &#125; tl = p; &#125; while ((e = e.next) != null); if ((tab[index] = hd) != null) hd.treeify(tab); &#125;&#125; 这儿有个instanceof函数表示判断前者是否是后者的一个实例。例如，Result = object instanceof class; 判断object是不是class的一个实例，如果是则返回ture。 TreeNode，树节点，他是继承自Node节点的，也就是说TreeNode形成的实例既有Node的key，value等属性，重要的是他有next属性指向下一个节点，而有有TreeNode的parent，left，rigth等属性，这儿在TreeNode里面增加了pre属性来指向前一个节点，只能够在红黑树中使用。在查找HashMap中是否包含某个value的时候将所有都当作链表节点来使用，将父类与本身的属性发挥的非常不错，比如在ContainsValue函数中就没有区分是否是红黑树去查找而是直接使用其父类的next函数查找下一个依次遍历。 3、putMapEntries这个函数就是将，一个Map的所有值加入当前Map，当然需要指定evict参数。 12345678910111213141516171819final void putMapEntries(Map&lt;? extends K, ? extends V&gt; m, boolean evict) &#123; int s = m.size(); if (s &gt; 0) &#123; if (table == null) &#123; // pre-size float ft = ((float)s / loadFactor) + 1.0F; int t = ((ft &lt; (float)MAXIMUM_CAPACITY) ? (int)ft : MAXIMUM_CAPACITY); if (t &gt; threshold) threshold = tableSizeFor(t); &#125; else if (s &gt; threshold) resize(); for (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) &#123; K key = e.getKey(); V value = e.getValue(); putVal(hash(key), key, value, false, evict); &#125; &#125;&#125; 类似的有putAll函数，他就是引用了一下putMapEntries函数，区别就是默认了evict为true而已。 123public void putAll(Map&lt;? extends K, ? extends V&gt; m) &#123; putMapEntries(m, true);&#125; resize函数这部分非常重要，时HashMap重要思维的体现之处之一。首先扩容会在两种情况发生，第一种，在链表转化为红黑树的时候阐述过链表长度大于8且哈希桶数组的长度size&lt;64时会出发扩容；第二种，size&gt;threshold的时候会触发扩容（threshold=length*loadFactor）。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;&quot;rawtypes&quot;,&quot;unchecked&quot;&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; 从代码中可以看出resize函数是返回一个新的哈希桶数组，那么为什么要返回一个新的哈希桶数组呢？这点要从数组讲起，众所周知数组的长度是固定的，不能变长，那么我们怎么在HashMap中产生一个是原来长度两倍的数组呢？这儿就只能够创建一个新的数组来代替老的数组，需要将原来数组里面的变量一一填充到新的数组里面来。在Java1.7以及之前是一次将原来HashMap中的所有节点通过hash算法依次定位到新的Map中来。在Java1.8中对于老的数组同意位置的链表或红黑树中的节点填充到新的Map中做了很大的优化，使得扩容的速度快了许多。当然虽然优化了很多，但是这也是非常消耗时间成本的，因此我们在创建HashMap的时候就需要提前估计其能达到的最大容量，尽量一次性分配足够的空间，减少扩容情况。 在Java1.8中对于HashMap扩容时数据转移做了很大的优化，这儿需要讲到hash获取数组下标的方法(n-1)&amp;hash(key)。对于hash(key)方法我不做过多阐述，想要学习的看看源码再自己测试一下就明白了。而对于按位与&amp;这儿需要说明一下，比如我们的数组长度n=4，那么呢n-1就是二进制的0011，举个例子当hash(key)为2和6的二进制分别时0010和0110，（前面的一些0就不做过多书写了），他们对于n-1的&amp;后得到的0011是相同的，也就是产生冲突，就会形成链表或者红黑树。而扩容之后，n’为8，n’-1二进制为0111，hash(key)进行&amp;操作后就是0010和0110，刚好是原来下标位置和原位置下标加上原来数组长度后作为下标的位置。这儿就可以直接用原来数组长度n的二进制0100与两个hash(key)进行&amp;操作，来判断是否需要将下标位置加上n了，如果是1则加。这样就不需要对于每个节点依次去进行一次重新定位操作。 remove函数当然，跟之前的分析一样，我们都需要关注返回值，这儿返回的是value或者null，那么value是哪个value呢？就是原来我们移除的那个节点的value，当无这个节点时，那么返回null。其实这儿跟put函数一样，都是对于其基础函数的封装，这里remove函数是对于removeNode函数的封装。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public V remove(Object key) &#123; Node&lt;K,V&gt; e; return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value;&#125;final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) &#123; Node&lt;K,V&gt; node = null, e; K k; V v; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) node = p; else if ((e = p.next) != null) &#123; if (p instanceof TreeNode) node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); else &#123; do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; node = e; break; &#125; p = e; &#125; while ((e = e.next) != null); &#125; &#125; if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) &#123; if (node instanceof TreeNode) ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); else if (node == p) tab[index] = node.next; else p.next = node.next; ++modCount; --size; afterNodeRemoval(node); return node; &#125; &#125; return null;&#125; 从上面removeNode函数可以看出其返回的是一个Node类型，即返回移除的节点，除了没有对应节点时返回null，这儿有两个比较特殊的参数matchValue和movable，matchValue表示是否匹配value的值，而moveable表示是否可以移除，对于这点我有点想不太明白。在remove函数中这部分都是和value一起以默认值传出。在removeNode函数里面又有判断当为红黑树时的removeTreeNode函数，对于这个函数我不作过多分析，需要的可以自己去看一下源码。 附对于其他函数等操作等，我就不具体分析，比如contains一系列，clear函数以及一系列Set等，以及其迭代器iterator等。这些如果需要学习可以仔细看一下其源码分析。最后推荐下美团点评技术团队的《Java 8系列之重新认识HashMap》。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>map</tag>
      </tags>
  </entry>
</search>
